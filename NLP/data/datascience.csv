title,score,id,subreddit,num_comments,body
Amazon AWS Pro-Serve Data Scientist is it a good role?,2,hcxeno,datascience,2,"Hello all,

I am a Data Scientist at a Fortune 500 company, with a PhD in Electrical Engineering. For the last 5 years, I thought myself Python and Data Science and progressed a lot in that arena. I wanted some change after 5 years in the same company and wanted to explore options. Amazon AWS Pro Serve sounded interesting as you get to work with different companies. I did not want to work on a deep Machine Learning Problem on my cubicle (after corona, for now home desk :) ). I was excited about meeting new people and potentially solving data problems for different industries.

Am I making a right choice? Is Pro-serve considered to be same with, say ""Applied scientist"" role in AWS (asking in regards to: 1) career growth, 2) reputation and 3) financial) ? Is meeting new people and potentially gaining more exposure to different industries in Pro-serve a naive way of thinking? As we all know customer's behaviors can vary.

All in all I thought, exposing myself to people and industries, in the future I can perhaps even become an independent consultant, yes? Whereas If I am an applied scientist, I need to be deeply involved in ""creating the AWS tools from scratch"" vs using them in the AWS Pro-serve role.

If you have any experience with AWS Pro-serve data scientist roles, please chime in. Thanks in advance."
Code Management,1,hcv2oe,datascience,10,"This is likely a silly question... but what are some recommended methods for ensuring you can easily switch between a laptop or desktop PC and having easy access to your files, libraries, packages, etc.?

GitHub? Just transferring your environment files (how)?"
What applications of Data Science or AI are there in Education?,0,hcuo4d,datascience,1,I'm currently looking into the education technology (edtech) field and am interested in how data science and AI could be used. I've found some companies like Knewton that focus on adaptive learning. Would anyone know any other applications there are of AI in education and where I could learn more about the underlying algorithms used in such applications?
Discord/Group for aspiring data scientists?,0,hcne52,datascience,2,"I looked through the wiki and couldn't find one. Is there a group where it'll be okay to ask newbie questions on DS, libraries, tools, etc?"
Jupyter Lab supports for pandas.iplot?,0,hcj56k,datascience,1,"Saw another post the other day that bought Jupyter Lab to my attention and I thought I’d switch full time. 

My understanding is that there shouldn’t be much differences between the two, but the iplot graph didn’t show up in Lab whereas it did in notebook."
What is your favorite developping tool/IDE for python ?,0,hcit68,datascience,7,"Hello everyone ! 

I was wondering what you find the best IDE for python, and why it is, in your opinion. 

I'm asking that because I find Jupyter to be lackluster when it comes to anything bigger than a small testing script. The autocompletion almost never works for me when I'm calling packages functions or that kind of stuff and I don't remember all of them each time I run a new project. 

I really liked VSCode personally but never found the option to run code sequentially (line by line) which makes me very sad because I'm sure there's a way to do it."
Tired of Siraj Raval's plagiarism? Here's what you can do,511,hcf4i7,datascience,55,"1) Find several examples of plagiarism in his YouTube channel

2) Message the actual creators asking them to file a copyright complaint

3) If the channel receives 3 strikes it will be terminated by YouTube.

Siraj's videos with plagiarised content are still on YouTube bringing him views, subscribers, and $$$. And they're taking away views from content creators with integrity.

Edit: yes, he is still doing this, as of 2020. see e.g. https://www.reddit.com/r/MachineLearning/comments/ex2sks/d_siraj_is_still_plagiarizing/"
Best place to deploy deep learning web app?,2,hcdfp6,datascience,4,"I have a full web app ready to go that I made with Flask and HTML/Javascript. I tried to deploy it on Heroku, but they only allow files of up to 500mb and just importing TensorFlow via the requirements.txt file is already around there, not including the two 100+mb trained models I need to add. Would elastic beanstalk be a good place to deploy it? I also came across FloydHub which seems like an option. Wondering if anyone has any advice here. Thanks!"
"User claims he is a ""data scientist"" that makes 250k/year for just writing a few SQL scripts a day. Is this false?",88,hcactj,datascience,103,"Comment:

> [user 1]
I currently go into my FANG co, write a few SQL scripts, and call it a day by 4ish. Pays $250k/yr with a ton of amazing benefits. No MBA needed :)

> [user 2]
Data scientist?

This was found on a business careers related subreddit. I thought this claim was crazy and outlandish, but maybe this sub could confirm. Are data scientist jobs so lax you can casually write SQL and make 250k/year?

I was always under the impression you needed a masters/PHD in stats and had to know a whole bunch of complicated math just to even break six figures, much less 250k."
How to combine data science with data engineering?,0,hc83zi,datascience,3,"Hey everyone.

I'm about to graduate and get my masters degree next week and I have a tough decision to make. I've been working full time job for the last year in one of the biggest IT consulting companies out there as a big data intern, however my academic background is also more about analytics and statistics (i'm graduating in ""Computer Science and Econometrics"").

My main repsopnsibilites in current position are: building a star schema data warehouse (using SQL and Spark), bugfixes in existing tables, adding new source tables etc. I have never done any Kafka related stuff nor some extreamly-advanced pipelines using Spark Streaming or other tools. Most of them were quite complicated SQL queries (with over 1k lines of code). Within next 3 months the client I'm working for is going to be migrating from Hive to Snowflake and Wherscape, do you think knowing those would be benefitial to add to my resume? I would also learn some Amazon Athena and S3.

In my free time I often do kaagle competitions (just to test my skills and have some portfolio projects), prepare some ML models, try to do some predictive analysis. I really dont want to let those skills ""fade"" and develop in analytics as well.

All the technologies/languages I have worked with are: SQL, Python (more analytical python, so libraries like: numpy, seaborn, scikit-learn, pandas etc.), R (although I hate it), Scala (basic scala to understand Spark better), Spark (also pySpark), Hive (Hive-QL), Apache Ariflow (althow I know how to trigger a job and read logs, not really how to write complicated scheduling scripts), Jenkins, Git, Jira.

Now, I really have a tough decision to make. Should I stay in my current job as data engineer (with promotion to regular engineer, not an intern anymore) or look into more data science field. What do you guys think would be more lucrative within the next 5-10 years? Is there any way I could lets say, within a year or two, easily change fields from data engineering to data science? I guess I would be pretty good at data preparation and cleaning in that time. Is knowlege of those technologies mentioned above superficial in case I wanted to change? Should I learn anything specific? Also, if I decide to stay in the current position, I can take certification exams in SQL and Spark. Would it be benefitial in data science? What would be the best path to take?

Kind regards"
What to include when writing a phase 1 proposal?,1,hc80nv,datascience,2,"I am writing a proposal for a data science challenge for the first time. The proposal isn't academic in nature and it is aimed to serve as a white-paper for my idea. To keep things general the purpose of the challenge is to utilize data science skills for social good. Phase 1 proposals should only be one page in length, so should I focus more on the technicalities or on the vision? I can be very general when writing about the process, but I would like to hear what others have done in the past when trying to convey complex data science problems while focusing on the task at hand."
Do you guys use Python for regression (statistical outputs dont seem to come easily),3,hc7exd,datascience,8,"I'm trying to port some R code to python and it's just a simple logistic regression.

I managed to get the model to run in python (after I realized I needed to get\_dummies), and the model ran, but it just doesn't seem as ""simple"" as R.

For example, scikit-learn doesn't have statistical outputs, so I'm using statsmodels instead.  The model converged but I'm getting nan on some pvalues for a couple of predictors.  Also, It appears to be using the intercept as the basis of interpretation when it comes to categorical predictors?

It's all new to me, so not sure if i'm just not good at python......."
Position focuses mainly on “explaining drivers”,3,hc55m5,datascience,8,"Hey everyone,

I work as a DS for a fortune 100 company. It’s my first data science role and I’ve been here a little short of a year. We have no way of implementing models and I’ve built a few production worthy scoring engines. The company is trying to get up to speed with analytics and data science but is still behind in the curve in terms of technology and utilizing data and their data scientists.

This leads to my question. Is anyone else in a role where you are “looking for drivers” or “key factors” regularly. It seems as though this is a huge majority of the work and all people care about. “Looking for segments” or “tell stories”. It seems extremely trivial and the amount of work reducing extremely wide datasets to a selection of variables that can tell a story is a relatively big task. They’re so open ended and can tend to be misleading. This feels like more of a business analytics role (even though so many titles seem arbitrary). They’re looking to have a production ready environment by the end of this year but it seems that actually having the business utilize scoring engines is unlikely. 

Doing these segmentations or “drivers” of events is what stakeholders care about. Is this very common in data science? Am I looking at this position wrong?

Thanks."
Where to learn about best practices for End-to-End Data Analytics Process?,4,hc3vcl,datascience,5,"I'm a Technology Consultant, and while I feel like I can use many different tools (Power BI/SQL Server/R/Python etc), I don't have a ton of knowledge about the current best practices for stitching them all together to form an end-to-end productionalized enterprise process. I'd like to maybe find a course/book that touches on these higher-level aspects, if possible. I tried to look on Udemy, but they all seemed pretty specific to a particular technology."
How often do you go back to clea up your code?,2,hc30gj,datascience,8,"I'm new so maybe this'll be something that changes as i get better.
I find alot of my code to be ineffecient when i go back through it. The code works and completes the tasks, but when looking through it always looks like it could be simpler and less convoluted. 

Is this just a me thing or a feild thing that will always happen?"
How to become proficient using Docker?,22,hc070m,datascience,15,"Hey everybody! I noticed that all the cool kids in data science are leaning heavily into using Docker. I'm planning on going through the [tutorial](https://www.docker.com/play-with-docker), but was wondering if anybody here had any resources they recommend for becoming a Docker pro. Thanks!"
What PC components are a priority for speeding up predictive modelling?,0,hby6qg,datascience,14,"Hi all, i'm a data scientist working primarily with R & R Markdown and am looking at building a PC for gaming and data science work and I began to realize I know a fair amount about optimizing for gaming performance but almost nothing about what speeds up predictive modeling and other stages of a data scientists workflow.

For example:

* Is base CPU speed important? Number of cores? Threads? Cache?
* I know with R, enough RAM to fit datasets into memory and work with them isimportant, but does additional RAM beyond that help? What about RAM speed? (e.g. would 2400MHz -> 3200MHz make any difference?)
* Does the motherboard matter at all, aside from having enough space for future RAM upgrades if needed?
* Does the GPU matter if you're not doing deep learning?

I'm not working on cutting-edge stuff really but what things should I bear in mind for speeding up 'normal' data science work, e.g. data manipulation, statistical tests, visualizations, cross-validation & grid-searching (I use some boosting like xgboost & lightgbm but a lot of more standard linear/tree-based approaches)

Thanks and I hope someone can help, i'm really struggling to find information on /r/buildapc outside of the fact that GPU's are important for deep learning, which I don't really do!"
Forever a fraud ? Keep having horrific interviews and feel like I can never become a Data Scientist,343,hbxj93,datascience,133,"I have had some experience working as a machine learning engineer but if I am honest with myself, I barely did much. I am 24 with 2 years of experience. Got laid off, rightfully so.

I have been struggling with myself and I keep on preparing, studying... But the result is a loop of painful rejections. You know, the kind of rejections where the company was interested in you, set the bar reasonably not high and expected me to pass through it

&#x200B;

And yet I didn't. My profile looks good on paper but I feel like a fraud. Like someone who can try all he wants to but let's be honest, who is he kidding ? He doesn't know shit. He can't take up REAL responsibilities without having someone look over his shoulder. And even then he is lazy, mediocre.

Tried doing projects, watching videos, kaggle (that's a lie, I tried like 2 or 3 competitions that too I followed what others did)

I guess the gist of it is that I think I am a fraud. A phony. **I can have the bookish knowledge but I will forget it when I need it or would be unable to apply it.**

I'll never have what it takes to be an actual data scientist. It is just an unsophisticated fantasy.  And at the same I don't see myself doing anything else so I guess I am useless to the society\~ No one will hire me cause I can do nothing.

Just wanted to let it out after yet another disastrous interview which I knew everything about(as in, the answers to the questions), yet I messed it up. They threw a low ball and I missed my swing. Looked like a fool. & Now I am binging on the Office (TV show) to numb it up

&#x200B;

🏃‍♂️"
Another 'Am I a data scientist' question,0,hbjsrg,datascience,11,"So I'm deep in my career, which when I was hired was mostly focuses on analytics.  I.E.  Excel charting.  

As a programmer, I migrated away from excel and have a lot of automation using things like Jenkins for devops/data pipeline things and R Studio and Shiny apps to create apps for visualizing and working with data.  I do a lot of data engineering in oracle, creating repositories for internal apps and to serve to other enterprise apps outside of my department.  And lots of analysis via PLSQL queries against our database that runs our business.

I have practically no experience in Machine Learning or Neural Networks.

Most folks are classified as business analysts here.  Which is a range of people who use the gui of our business system and configure it via gui prompts, to devOps and our front and back end developers.

I tapped out of the front end game as data was my thing.  (Im way above average with my SQL and subject matter expertise of Oracle systems) And over the last year have really been learning R and Shiny apps to where we have a lot of real time dashboards and metrics to view (some on always on wall displays).

Do you think I can sell the 'Data Scientist' role to help reclassify myself here?   I.E.  Can I refer to myself in practice as a data scientist without have Deep learning/machine learning/neural network skills in my toolbox?"
Having to suddenly fill an alarming skill-gap in the area of front-end development - from Python/SQL knowledge to embedding real-time visuals on web pages using JavaScript libraries (e.g. d3.js),9,hbfva4,datascience,19,"This use-case suddenly came up at work. I can understand why this was partially delegated to me, because I'm one of the few people who works with data in our company of less than 20. 

But it brought to light a woefully lacking skillset. I'm sure there's other people in this sub who have found themselves in the position of starting from experience in mostly just Python libraries, to suddenly having to pick up some JavaScript front-end libraries for visualization purposes. Eager to hear advice/tool recommendations from people in this position."
Data science salaries in Canada?,47,hbdhxj,datascience,28,"Ranges you can find online are very broad, to the point of little value."
Random Forest with Time Series data - how to best split test & training data?,72,hbbcxa,datascience,28,"I have ~520 days with some data (visitors, weather, etc.) and some missing days (3-7 days) in between every 1-2 months.

I want to predict future visitor numbers for a few weeks in the future.

How do I best split up test & training data so that nothing leaks from test to traning? I've read that I should take ~80% of the time span for training, leave a month empty, then the rest of the days (~20%) for test?

Is there a best practice? And are the empty 3-7 days a problem?"
Agile Data Science Management,21,hb68sh,datascience,14,"Does anyone have any good books or resources on agile Data science Management. Or really just agile project management would work maybe with a focus on data.

I am trying to move my team away from a waterfall approach and adopt scrum processes. Were focusing on trying the Team Data Science Process from Microsoft But it's hard to get people on board with sprints, and stand ups, and stories when I only understand foundation and concepts. 

Is anyone currently using an agile Data science delivery method?"
What’s the deal with executives wanting chatbots?,11,hb5lzl,datascience,10,"I don’t mean this as a meme. Literally just got hit with this at work today. Their 2-3 year outlay involves implementing a full service customer facing chatbot. We have no data infrastructure, which means no historic data or anything. They have some new chat mobile app for customers to communicate through and from what I’ve gathered so far, they intend these messages to be sufficient for training after two years? I mean, yeah NLP is going to make huge advancements in that span of time, but I don’t suspect it will be “smart” enough to devise its own methods to answer any type of question about a customers account by then. I foresee a nightmare of declarative rules driving hobbled together screen scraped-key logged RPA trying to interact with our 35 year old customer transaction database. Thing isn’t even relational and doesn’t support https or other interactive protocols. I mean, our IT department keeps pulling corrupt RAM on VM host hardware that out of warranty with nothing to replace it with. They don’t have the budget and we can’t get budget for cloud instances. They have no RDBMS at all. We’re regulated too. We have to verify customer identities before account access. They call about all kinds of stuff. Oh, and we support three different spoken and written languages. There are all sorts of formalities our call center has to go through. We don’t even have menu based ID verification for call ins. It’s all done by humans talking to each other. 

Yeah, we ain’t getting full human passing customer service automatons by 2023. I hope I’m out of this dumpster fire before December. Is it that tempting to replace ones workforce with robots that they’re completely blind to the actual reality of doing it?"
What laptop is the most optimal one to get that is just enough to get anything done within data science?,11,hb4vr7,datascience,26,"If you had to work out of the office, what is the best laptop to get at the lowest price where you can still get all data science stuff done? I expect that these tasks would involve opening and processing heavy excel files, coding, visualizing data, accommodating video calls properly, and anything else I forgot to mention.

If I am correct in my assumption I would say this laptop would have at least 16GB RAM and at least an i7 processor. But correct me if I am wrong.

Also of course, this laptop should be dependable and thus durable. Do you have any suggestions?


P.S.
I am familiar with services that allow laptop customization, however this is not yet being done in my country and thus, the reason I am asking.


Edit: oh yeah, and a good screen!"
DS Online Masters,112,hb1h64,datascience,104,"I've been working as a data scientist/ml engineer for the past 5 years. I graduated with a bachelor's of mechanical engineering and managed to push my way into a full-time DS position through some online certifications and private projects.

I realized I have the bandwidth to pursue a master's but don't want to quit my job so I'm seriously considering getting an online masters to do on the side.

First question: can anyone reccomend a good online masters program related to DS?

Second question: is it even worth pursuing if I can't attend an on-campus masters at a potentially more reputable institution?

Thanks!"
Examples of data categories or metrics that shape our understanding of the concept they proxy,4,hazvk7,datascience,5,"**What standard data categories or metrics proxy a phenomenon and shape our understanding of it?**

  
I am thinking of standardized measurements or categories often used in databases/algorithms to proxy phenomena and which shape our understanding of the concept. 

  
One example would be the IQ score, which proxies intelligence and shaped our understanding of intelligence as unilaterally comparable and one-dimensional.

  
What other, **more widely used metrics** or categories can you think of that have an impact on how we understand the concept they proxy?

  
The question is a bit off-topic, but you would help me so much if you could give me some real-life examples, actually used."
"Are Q/A models, Text summarizer models and text generation models useful from an NLP application standpoint ?",2,havd3m,datascience,1,"From a NLP application stand point, I don't see much utility in Q/A models, Text summarizer models and text generation models. 

Let me elaborate case wise:

Q/A model: We all know it can never reach human level answering. One tricky question we can get to know whether it is human / chat bot.

Text summarizer : Often a lot of key sentences that form the context are ignored. Summarized yes, but at the cost of information loss. 

Text generation : We all have seen GPT2, GPT3. Honestly, the texts generated are incoherent most of the time. 

Can somebody explain whether they are useful and how?"
How do you find data science opportunities within your job ?,1,hat806,datascience,2,"Hey there,

How exactly do you spot opportunities to apply data science within your current job if you don't have a data science team yet ? Is there any mental models or checklists you keep to spot such ""data"" or ""problem"" ? 

Thanks."
Data Science: Anyone run out of projects to do in the work place?,9,haojt0,datascience,25,"I've worked a few jobs as a Data Scientist researching complex problems and finding solutions to those difficult problems for tech startups.  I'm often at the heart of if a company succeeds of fails.

However, after I'm done with those projects, I often have nothing left to do at the company.  Specifically, I do not know how else I can help out.  I'm coming to the same crossroads at the current company I'm at worrying if there will be work for me a couple of months from now.

How do you guys find projects to pitch to the company?  I'm currently in the engineering department which is separated from other departments of the company, making it hard for me to know if I can help out in sales or marketing or elsewhere.  I don't want to get laid off.  Has anyone else been in this position?  What did you do?"
"Why is Data Science considered a ""science""",159,haku70,datascience,76,"i'm a full-time data ""scientist"" and my work is basically split between SWE/Data Engineering and business analytics with some modelling thrown in. most data scientists don't do research and don't follow the scientific method. i know the job title today is basically a misnomer, but what were people thinking when they thought this kind of work resembled ""science""? what did OG data scientists do that made their work scientific?"
Important Lesson Learned: Commit and Save your Code Regularly !!!!!!!!!!,0,hahauf,datascience,20,"Every day is an opportunity to learn something new. I learned an important painful lesson today: Make sure you commit and save your code regularly. 

I was working on a project for the past week I didn''t save my progress, nor committed anything. 15 minutes before my meeting with my VP, I decided to restart my computer. My idiot self didn't click on save. Imagine my face when I couldn't find all the things I spent all last week developing.

Luckily, I had other projects to present, and we didn't make it to the part that I completely fucked up. 

SAVE and COMMIT Your code. PLEASE!!!! don't be like me. 

&#x200B;

What are some lessons you learned this week?"
Cloud/virtual CPUs for machine learning pipelines?,1,hagidj,datascience,6,"Does anyone know where I can find a powerful virtual/cloud CPU (free or low-cost) to run ipython scripts?

I checked Google Colab and Kaggle notebooks but those CPUs are even slower than my own personal $500 laptop (intel i5).

I also checked the $9.99/month Google Colab Pro but it only has GPU speed up and not more CPU power.

I'm trying to run my machine learning pipeline which does step-wise forward feature selection, cross-validation, and grid search on a large dataset. It is taking 2-3 hours to run my ML pipeline from start to finish on my own laptop right now

Any advice would be appreciated, thanks you guys!"
Can someone help explain the difference between data wrangling and data cleaning?,6,haadzq,datascience,8,"Hello all! 

I hope everyone is having a good day! I’m currently doing research on data cleaning and trying to find any set of guidelines to do it etc (if you have any good sources please link them below!). I was warned by my professor not to get data wrangling and data cleaning confused with one another, but it happened to me and now I don’t know how to UN-confuse myself! If someone can please distinguish these two concepts for me that would help a lot! Thanks so much!"
Monte Carlo (or other methods) for Ingredient Concentration Estimation,2,ha85yi,datascience,6,"Weird title but hear me out.

**THE PROBLEM**

I have a sample product that is comprised of let's say 3 ingredients, each with concentrations listed in ranges of the total product composition:

&#x200B;

|Ingredient|min concentration (%)|max concentration (%)|
|:-|:-|:-|
|x|25|50|
|y|25|50|
|z|25|50|

Now based on the concentration of each ingredient, the overall product is going to have a different toxicity profile.

If x = 50% y = 25% and z = 25%, then the product has a toxicity score of say 100.

But if x = 25%, y = 50% and z = 25%, then the product has a toxicity score of perhaps 75.

This is a real world problem (ingredients are often listed in ranges), so I guess I can assume normality of the distribution of each ingredient range (or uniformity?).

**WHAT I WANT**

I want to show a probability distribution of overall toxicity, based on some simulated concentration values. Maybe making 1000 potential ingredient ""configurations"" and then running the resulting calculations.

Python & R related solutions are ideal."
Identifying Patterns in Time Series Data With Multiple Variables,9,ha71r6,datascience,22,"I must warn before I begin that I am coming from the hard science sphere (and am trying to integrate some novel data science) so some of the things I talk about might make no sense. Please ask questions!

I have a database of \~20 variables that are collected continuously over time. This database is essentially measuring the conditions of the interplanetary magnetic field (too complex to model) which drives numerous phenomena that occur in the Earth's atmosphere, etc. These phenomena are of interest to researchers but only occur ever so often. To find these, you have to manually search years and years of data, something that is simply not too practical.

I want to develop some sort of method to take a number of instances of a phenomenon and search the continuous database for more instances. I think that this needs to be split into two tasks.

1. Discover common patterns (dips, spikes, sign changes, or even more complex ""shapes"") between the inputted instances. It will also have to discern the variables of interest because not all in the database will drive a single phenomenon. Moreover, if the program can then output these relationships (such as variables appear to drive the phenomenon) this will be of interest to users.
2. Use these relationships to search the continuous stream for more instances.

Like I mentioned, I am not very experienced in data science. Of course, I am not asking anyone here to develop this for me or anything, but it would be really helpful if someone could point me in the right direction. Eventually, I would like to develop some sort of robust methodology that can be applied to many scientific fields.

&#x200B;

Edit: A lot of people are linking great methods to detect anomalies, but this is not quite what I want. I need pattern recognition, and to be able to detect things like sign changes, not just large spikes/dips."
You probably should be using JupyterLab instead of Jupyter Notebooks,612,ha6laa,datascience,196,"[https://jupyter.org/](https://jupyter.org/)

It receives a lot less press than Jupyter Notebooks (I wasn't aware of it because everyone just talks about Notebooks), but it seems that JupyterLab is more modern, and it's installed/invoked in mostly the same way as the notebooks after installation. (just type `jupyter lab` instead of `jupyter notebook` in the CL)

A few relevant productivity features after playing with it for a bit:

* IDE-like interface, w/ persistent file browser and tabs.
* Seems faster, especially when restarting a kernel
* Dark Mode (correctly implemented)"
hard to explain in a topic...but how to model on conversion based on upgrades (when upgrades are 100% converted),1,ha6hmz,datascience,0,"so here is an example of what i'm trying to do.  suppose this is cell phones:  From a sales standpoint, theres Quotes, sales, and upgrades.

if I want to predict sales (sold/not sold), I can use my quote leads and do a model on probability of sold/not sold.  if I want to predict who upgraded their product, I can use my sold data and predict upgrade/no upgrade.

What if, I want to predict the following:  What impact does upgrades have on my conversion?  I cant model sold/not sold using upgrades because all upgrades are ""sold"".  I'm trying measure if high rate of upgrade also means high rate of conversion, etc etc"
Is statistics and the math behind data science and ML increasingly becoming less important?,0,ha6ffm,datascience,5,"I've been reading through recent career thread on this sub, namely [I'm offered a data engineer role instead of data science, should I take it?](https://www.reddit.com/r/datascience/comments/h8yjdf/im_offered_a_data_engineer_role_instead_of_data/) and [From Data Scientist to Machine Learning Engineer](https://www.reddit.com/r/datascience/comments/h9p4kl/from_data_scientist_to_machine_learning_engineer/), and it seems like there are a couple overarching themes: that nowadays, data science and ML jobs are largely about  building pipelines, deploying models and other engineering things related to building out an ML system; that the modeling is only a small part of the job. 

So is knowing all the math and statistical theory behind models becoming less important as more and more data science jobs become more engineering-focused roles? I understand that it obviously doesn't hurt to have a strong math background, and my question is NOT whether the math/stats stopped becoming important. My question is, has the emphasis and the importance of the math/stats *waned* for many data science jobs, as needs shift toward deployment or pipelines?"
Using Macbook Air for Data Analysis,0,ha1j1m,datascience,10,"With all the cloud sources like AWS and Microsoft Azure, what do you think of using a Macbook Air 2020 for data analysis? (I am an undergraduate physics student and I won't be dealing with very large datasets)

Do you have any other suggestions? (I currently use a 2012 model ASUS K56CM and a Samsung Galaxy Tab S6 with Jupyter Notebook. I can even use Tensorflow in this tablet)"
What makes a good business analyst in data science?,5,h9tdit,datascience,3,"Going to be starting as a business analyst on a newly created data science team and I was wondering what makes a good BA? We are just starting out and the industry we are in is for the most part just now dabbling with the applications outside of engineering. We are small, so just myself and a data scientist along with our manager.

Thanks!"
Things I Learned while building Machine Learning web app,39,h9q7im,datascience,20,"These past weeks I've been working on an ML web app as a side project. Being a Data Scientist, I decided to take on this project for two reasons. First, it would make for a good learning experience for the things I'm not very comfortable with like Design/Front-end and Deployment tasks. Second, as I found most of the materials lacking, I thought I could gather some useful information to write a blog post about it.

I made a web app that tracks the sentiment on twitter towards the leaders of the top political parties in Spain. It works —more or less— in real-time. The site is live here: [https://polituits.com/](https://polituits.com/)

Some things went well, others that I could have done better, and others that at this point I'm not sure haha (e.g., How much traffic would it handle?). I thought I could share those things before getting to work on the blog post.

I'll start with the **things that made my life easier:**

1. [End-to-end Machine Learning App](https://www.ahmedbesbes.com/case-studies/end-to-end-ml-app). This is a great resource. It goes through the full process of building a Machine Learning application in a realistic setting. Most of the materials you'll find out there will skip deployment or work with simple data sets. This one goes from scraping to deploying in AWS. A few days ago, I also read [this one](http://veekaybee.github.io/2020/06/09/ml-in-prod/), which I also recommend.
2. [Dash](https://plotly.com/dash/). I compared Streamlit and Dash and went with the latter for better documentation and a more significant community. The deployment part was especially painful, so proper documentation was critical to get the job done.
3. [HugginFace's Transformers](https://huggingface.co/). If you are working with NLP tasks in languages other than English, check HuggingFace's repository of community models. Furthermore, it is relatively easy to integrate into an inference service built with Pytorch/Flask.
4. [Abhishek Thakur's tutorials](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A) and [Kaggle Notebooks](https://www.kaggle.com/abhishek/notebooks) for fine-tuning BERT. Fantastic resources that saved me a lot of time. Especially when using those ideas with a pre-trained BERT in Spanish from HuggingFace's transformers.
5. More generally, I benefited from keeping the toolset simple. I used PowerPoint when I started designing the app (see the initial design [here](https://twitter.com/_dylancastillo/status/1272238506916675591)), SQLite as a database, and Python/Dash (instead of JavaScript).

Now, the **things that I wish I had done differently:**

1. Contain the scope. I started with a straightforward idea and then started adding stuff that just made my life harder. Most of the time, I think it was because I felt the app was not ""complex"" enough for publishing it.
2. Deployment. Ha! The only good thing about it's that it ""works"". Right now, it is a painfully manual process. I should have gotten to a better deployment process from the beginning. By the time I started deploying, it felt like too much work.
3. Sacrificed code quality. I wanted to ship this quickly. So the code is not DRY. It's more like CRY yourself to sleep. Refactoring is among my top priorities now.
4. Model. It's not great right now. It only gets the job done. I did not dedicate that much time to labeling data for fine-tuning the model. This is also a priority for me right now.

Finally, there are many things for which I don't know if I was following the ""best practices."" In particular, setting up NGINX and Gunicorn felt a bit *hacky*. Sooner or later, I guess I'll find out.

EDIT: Just noticed the big typo on the title. Sorry! haha"
From Data Scientist to Machine Learning Engineer,214,h9p4kl,datascience,71,"I'm currently working as a Data Scientist and would like to move full time to Machine Learning Engineer roles. What is MLEngineer's day to day like and more importantly how can I bridge the current gap. You can consider my skillset as Data Scientist specializing in Machine Learning. I used to deal with AWS, ML.

It would be great if you can provide some resources for those skills too. While my current role is like Data Analyst on steroids, my previous role was primarily ML.

One of the gaps that I identified personally is ML system design. I have never heard of it before and haven't seen any resources. It would be great if you can provide some resources for that."
Conducting a literature review - how do you guys use data science techniques to accelerate your exploration of a domain?,10,h9j7rq,datascience,3,"I am conducting a literature review right now and it occurred to me a lot of you guys must be using data science to accelerate this process e.g. using techniques to identify keywords which could help explore new areas.

So I wanted to ask:  What ways are you using data science to conduct a literature review?"
Do you sometimes wish you could do data science as a hobby rather than a job?,5,h9g8z1,datascience,3,"I'm working for an R&D tech company, and my team is developing a niche NLP product. I have developed a serious interest in NLP, but I secretly wish I could use NLP for my personal projects (of which I have plenty of ideas), rather than my job. Some of my frustrations of the latter include:

- Having to read so many badly-written papers and repos. Furthermore, I find the leaderboard chasing and the Frankenstein deep learning models quite off-putting (do we really need transformer + CNN + multi-task learning + multi-lingual model + dual-encoder evaluated on 10 different datasets without any deeper analysis within a single paper?).
- Many of the deep learning models might work well in some leaderboard, but incorporating them to our data is rife with logistical and performance issues. Worse is that most of them are just black-box models with little means to debug if they return a wrong result.
- I'm not really interested in the product that we're building so much that I'm willing to go all in with regard to the above two points. I keep day-dreaming about the NLP projects that *I* want to build and the interesting NLP papers that *I* want to read. Worse is that I'm often so burned out at work that I find little motivation to do any further work on NLP after work.

Perhaps my grievances are with the R&D nature of my job, rather than data science itself. I recently interviewed for a product-focused data scientist role at another company, and my secret wish is that I could do the more ""routine"" data science at work (think regression, clustering, etc.) and do the more cutting-edge data science as a hobby. Does anyone share similar sentiments to mine?"
Keep a Brag Document,611,h96nz8,datascience,30,"Hi everyone,

Thought I'd share some advice that has helped me so far in my Data Science career. It has to do with recording your wins at work - hope you like it!

\-----

The human brain is terrible at remembering information.

When we try to use the past to predict the future, we end up using *our memory* of the past. And our memory is extremely flawed, subject to whims and emotions.

One of the biggest consequences of this is at work.

You clock in 9-5 for days on days and then when you look back at what you did a year ago, you think “Where did all that time go?”

Even worse, if YOU can’t remember what the hell you did, how will your boss?

In an ideal world: you do a great job, your company rewards you. They’ll notice all the hard work you’re putting in. All the beautiful lines of code you’ve written.

But we don’t live in an ideal world. And the costliest mistake you can make in your career is not being proactive about recording your achievements and your little wins.

**Enter The Brag Document**

I first read about a Brag Document on [Julia Evan’s blog](https://jvns.ca/blog/brag-documents/#template).

By recording your small wins and accomplishments on a weekly basis, you accumulate concrete evidence of what you’ve achieved.

And these “wins” don’t need to be Olympic Gold Medals.

Did you help a coworker understand how to use an API? Jot it down.

Did you anticipate a nasty bug and proactively reach out about it? It goes on there.

Did you help mentor a junior employee? That’s definitely part of it.

Over time, I promise you, your brag document will do wonders for your career.

Sure - negotiating a raise or getting a promotion will become easier. In fact, come performance review time, even your boss will thank you for it. Those things are hard to write from pure memory. More on this a bit later.

But the biggest benefit of a brag document lies in identifying *what you enjoy doing*.

Your wins are likely a representation of tasks you enjoyed. And you should be very proactive about focusing on those tasks going forward.

Use your Brag Document to ruthlessly identify the tasks you want to spend more time on, as well as the tasks you don’t want to do anymore.

**The Pareto Principle**

The Pareto Principle states that 80% of the effects come from 20% of the causes.

At work, 80% of what you can feel proud about will stem from 20% of what you do. You can think of your Brag Document as representing that 20%.

Use this 20% to ask yourself questions like:

* Is there a common theme amongst this work?
* Are there topics here that I thought I didn’t actually like but turns out I do?
* How much of this work involves collaboration with other departments / teams?
* How can I do more of this work?

**Frequency**

Update your brag document on a weekly basis. You can set it as a recurring event on your calendar.

The biggest benefit of this is that it forces you to scrutinize your output on a regular basis and allows you to be proactive about focusing on the work you want to do.

Let’s say that after a few weeks of work, you genuinely have nothing to put on your brag document.

There’s a chance you had a bit of a slow period at work, but maybe you’re just stuck somewhere you don’t want to be?

**Collaborate**

Talk about your brag document with co-workers. Ask them what you think you should put on yours.

You’ll often find that they’re able to mention things you completely forgot or didn’t even seem to think about.

Remember - just because something seems easy *to you* doesn’t mean it’s easy in general. 5 minutes of work may have taken you 10 years to learn.

You should also encourage your team to keep their own brag documents. Help each other be accountable and celebrate each other’s wins. This builds a strong team culture.

**Your Manager**

You should try to share your brag document with your manager once a quarter.

It might seem **weird** or **unnatural** \- you’re basically dumping all your achievements into their lap. But this actually really makes their life easier.

If your manager ever needs to vouch for you internally, then boom - they have direct evidence they can use. If your manager needs to reshuffle workload, then they know what you’re good at and what you can improve on.

Even better, you and your manager should go through your brag document together.

Tell them what you want to do more of. Tell them what you wish was on there more.

You’ll both be able to identify areas in which you’re doing a great job and also areas in which your manager perhaps wants you to focus on more.

Another aspect that’s helpful here is with goal setting - your manager and you likely work together anyway to determine quarterly goals.

You should use your brag document to help you identify what type of goals you need to be hitting. Very often, we will achieve goals and then think “Wait..what was the point again?”

By using your brag document to set goals, you’ll be much more likely to be working towards something that you find rewarding.

**Ending thoughts**

Once you start getting in the habit of using a brag document, operating without one will feel like doing your work in the dark.

Over time, you’ll develop a much clearer picture of the type of work that you want to focus on for your career.

If you liked this post, feel free to check out the whole article with nice illustrations [here](https://www.careerfair.io/reviews/howtobragatwork). I give [practical career advice](https://www.careerfair.io/) for tech professionals through a newsletter, would love it if you checked it out :)"
How much demand is there for Rstudio Trainer?,6,h96e3t,datascience,4,"I saw that R Studio was certifying people to become R studio trainers.

Can anyone speak to the demand of this as a side business? I would mostly be interested in running workshops on evenings/weekends. What kind of demand can one expect? I know it's hard to answer  this question backed by data so please feel free to share anecdotes, stories and opinions."
Laptop for a Data Science Program,0,h92wj9,datascience,8,"I’m starting a masters in data science program this year. My personal laptop is on its last legs so I’m looking to replace it before I start the program. I used to be a Mac person but have drifted away from Macs because my work laptops for the last 4 years have been windows/Linux machines. 90% of my work is done in the cloud so it’s really just a terminal but I’d like something decent still if I end up doing anything local like simulation work. 

My requirements are 16 gb ram,  nice ish screen, great keyboard, and maybe able to play a few light steam games. Right now my top choice is the  ThinkPad X1 Carbon Gen 7 (14”) laptop. It’s last gen model But I’m looking at the model on sale for $1499.99. They seems to be having big sales right now. Anything else I should look for at that price. There are so many options out there just not sure how to narrow it down.

https://www.lenovo.com/us/en/laptops/thinkpad/thinkpad-x1/X1-Carbon-Gen-7/p/22TP2TXX17G"
Data Preprocessing Technologies Question,0,h924uy,datascience,1,"Hey folks,

I'm working on a small dataset of audio wav files (about 8000 new audio files a day). There's a set of preprocessing and augmentation tasks that we perform on top of each of these audio files which in total take about 10s per audio file (we're using librosa for our audio processing tasks).   


Would like to make this applicable as a general discussion but with the following added notes

\- Assume that obtaining additional compute resources (on-premise or on the cloud) is not a problem 

\- Preprocessing must happen when all new files are collected and not as they are obtained

&#x200B;

What would be a reasonable set of technologies to use for a Data Pipeline in this scenario with the goal of reducing the total preprocessing time to under an hour (currently sitting at around 22 hours)?  


Thanks!"
Analysts Committing Data Science Fraud,32,h90bpz,datascience,21,"Has anyone had this discussion before? Is there a field threshold for what would be considered fraud? Sure, some people make mistakes and the empirical method always allows for correction, but what about people working in the field who are literal hucksters? Does anyone have examples besides mine below?

I’m talking about the likes of Siraj Raval, or worse, the nobodies at small to medium firms who fakes their way into roles and have no qualifications or backgrounds.

Example, an analyst where I work said this to me and firmly believes it, “statistics is just for making the data look good, the way you want.” When I heard that my jaw dropped. Here is a person working as a data analyst who believes all statistics is meant for it manipulating data to make it look “good.” I’ve also witnessed this analyst, in a presentation to management, display a bar chart with manipulated bins to make them rise along side another series, and then claim correlation! Also, they’ve used that word when comparing two separate pie charts! Manipulating bins to hold different ranges in this manner is surely fraud. Leaning on “correlation” for every chart you produce is just negligent. 

How does someone like that get into a role? The person who is their manager doesn’t know anything beyond that data science is the hottest thing and he needs one in his department."
"I'm offered a data engineer role instead of data science, should I take it?",198,h8yjdf,datascience,94,"I am searching for a data science role but got offered a data engineer role. As I understanding, there is little modeling in this role, but I get exposure to AWS, noSQL databases, and ""deploying"" the models. 

Should I take it to gain experience that may transfer over to a data science role later? Because i feel i might be in a long wait to find a data scientist position. (I'm currently employed, but I'm in a different field than data analytics, and I want to get in data analytics).

&#x200B;

thanks"
Tensorflow vs. Tensorflow 2.0 vs. Pytorch,96,h8smv7,datascience,25," I just finished an introductory data science course and now I am looking to get into deep learning. Is there any point learning TensorFlow or should I skip it and learn 2.0? Also, what's the difference between TensorFlow and Pytorch? I know TensorFlow is preferred in the industry whereas PyTorch is preferred in academia, but is it worth learning both if I prefer to go to industry? I am very confused, please provide some clarity. Thanks in advance!"
Weekly Entering & Transitioning Thread | 14 Jun 2020 - 21 Jun 2020,4,h8skw3,datascience,141,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Anyone have an idea how they made those old AIM chat bots?,85,h8n6mi,datascience,19,"I remember a couple, like one was ""AustinPowers"" (in promotion of the movie), and the bot would respond so impressively well. I'm curious what methods they used to make them."
what's the benefit of doing data science on the command line?,0,h8jql3,datascience,8,"I've read a few articles here and there about the benefit of doing data science on the command line.  I'm fairly new to this, but my impression is that they are talking about data cleaning, exploring and even running the models just on the command line.

Does anyone do this and can someone explain to me the benefit.  My use case for data science is building the models (more for exploratory analysis, trying to understand business impacts), but I dont push it into production or anything, so i'm trying to understand if this is something I should consider"
How do you make use of CLTV?,2,h8dmfq,datascience,4,"By CLTV I mean customer life time value.

I recently started a project to profile our customers. Essentially I'm trying to segment them based on behavior as well as create CLTV around each customer.

This is the second time I encounter this type of project and much similar to the last time, I don't have a good use case for segmentation and CLTV, other than looking pretty on the report.

In logic, high value customers should get better service, but in practice we don't differentiate customers because they all receive the best service we could (or try to) offer. And if we hope to identify potential high CLTV, then we run into the chicken-and-egg thing. Is it because we go the extra mile that turn a customer into high CLTV?

So I'm just curious if anyone also does CLTV and customer segmentation and what the use case for them would be."
Anyone working in conservation / wildlife?,67,h8bz3b,datascience,25,What inspired you to work with animals and how did DS play a role?
TIME’s “Superforecasters”... See if you can make it through without an eye-roll,4,h883pd,datascience,24,
"Does any data scientist here have an unusual job? Scientific research, weird company...",12,h832dt,datascience,12,
Data Science Career Paths,4,h7yo4o,datascience,9,"I am just getting into a data science researcher position after graduation from a maths and cs degree. Just wanted to know what the career paths usually look like for a data science guy when he reaches 40 or 50. Do you move into consultancy/management then? Or just move out of data science to software engineering? 

I ask this as several people burnout due to coding and generally get upgraded positions in terms of time and money. 

I would also love getting some advice to build a stronger career. Taking advantage of the Covid situation to learn the math behind GAN’s and VAE’s right now. Thanks!"
What technical skills did you have when you first became a data scientist?,228,h7w3av,datascience,126,
Any great textbooks/resources on Time Series Analysis for Python?,25,h7ufun,datascience,20,"I will be working at a HFT firm in August out of undergrad as a data scientist and want to prepare myself by studying Time Series Analysis. The company uses python pretty unanimously and it is also my preferred language, so it would be helpful to have a textbook or some sort of resource that teaches both the theoretical fundamentals of Time Series Analysis as well as implementation using Python.

Is there anything out there like this? As far as math/stats goes, although im decent at math, i'd prefer a book that isn't too advanced. If there isn't a great resource out there, would there be a good one for R that I can use? More concerned with the theoretical steps than the programming since I can always google which libraries to use.

&#x200B;

P.S. I took intro and intermediate level stats courses (and was a TA for intermediate stats) as well as practical Linear Algebra and probability courses. Unfortunately none of these covered much Time Series material other than some basic stuff like DW tests, ACF, patterns (cyclical, seasonal), etc;"
"Python + Matplotlib + Numpy + Pandas, but why Pandas?",5,h7oir9,datascience,31,"I'm in the process of building a python training program for some non-software engineers. I can make a really solid case for why they should learn Python + Numpy +Matplotlib, but I'm having a really hard time making the case for Pandas.

What are some killer features of the Pandas library that aren't easily achieved with python, matplotlib, and numpy?"
NLP Methodology,3,h7lhgw,datascience,6," Hi all, hope everyone is doing well. 

I've tinkered with data science for quite some time and encountered methodologies such as [SEMMA](https://documentation.sas.com/?docsetId=emref&docsetTarget=n061bzurmej4j3n1jnj8bbjjm1a2.htm&docsetVersion=14.3&locale=en) or [CRISP-DM](https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome) for data mining projects. However, I'm curious as to whether NLP-specific methodologies exist. My Google-Fu doesn't seem to reveal anything of the sort. I was hoping to pick your guys' brains on this. Do you know of anything relevant here?

And if NLP-specific methodologies doesn't exist, why is that? Is the field simply to broad for it?

Side note: Working on an NLP project, I was asked to describe the ""conceptual framework"", which apparently means ""concepts of relevance to research problem data analytics methods and techniques"". What the frick does that really mean?

Thanks for reading! Also posted in r/LanguageTechnology without much traction."
How is your experience with Vim \ Neovim??,0,h7gna8,datascience,10,For past 2 week i am using Neovim for data analysis and frankly i love using it due to its extensive configurable nature.  With Neovim i am able to use terminal emulator within my editor. What are your thoughts on vim for data science? Also suggest some good plugins from data science perspective.
You've just been given a dataset with 500k records and 50+ columns to build a predictive model by the end of the day. What mental checklist do you go through to build a model as quickly and accurately as possible?,589,h7dtrq,datascience,206,"Let's skip basic data cleaning (e.g.,  handling missing data, removing duplicates, doing type conversions,  standardizing values, etc.).   I'm more curious about what steps you follow to try to get useful insights from data as quickly as possible.  A few guiding questions I thought of:

* Do you have a mental or physical checklist that you follow?  If so, what's on it?

* What corners do you cut to try to get a quicker answer?

* What kind of exploratory data analysis is essential to your process?"
I got a data science internship! But I have no guidance,16,h7a5mz,datascience,11,"Hey all (: I'm a non english speaker college student who needs some help

Since february I'm working at a big company as an intern in a brand new data team focused on analysing data to identify suspicious behaviour in user accounts and devices. We spent a few months searching and configuring some tools to help us (Jupyter, Spark, AWS EMR...) and finally we made progress and have a good set of tools and some data (soon even more)! But the problem is: actually, we have little idea of ​​what we're doing.

&#x200B;

The ""data science"" people of the team are me and other intern. We have two backend developers and one data analytics who is learning DS too. It's amazing how the company gives almost total freedom to teams to build products and invest time on new ideas , including our, and I'm very grateful that my team trust and support yours interns to build something good, we even did some cool analysis recently, but the fact of we have no guidance or reference inside the company is very scary sometimes.

&#x200B;

I have little knowledge about Data Science/Analysis/Engineering, most from a few courses (like ""Machine Learning"" by Andrew N.g.) and some college subjects. I'm really liking the company, the area, my team and the opportunity to build something, so my questions are:

Has anyone been in a similar situation here? What resources would you recommend to improve skills and become a self taught data scientist/analyst and start thinking as one? Any tips or advices? Or small and simple projects using data you made at your company to inspire us?

&#x200B;

Thanks in advance :D"
[as a mentee] How to get the most out of a mentoring conversation,4,h78wsg,datascience,5,"Hi all! I am a new data scientist (< 1 YOE) who recently started a new role where I am the only data scientist on a team of devs/PMs … yes, I realized quickly the challenges working in isolation. Fortunately, I am at a company with many data scientists on other teams, so the isolation is not 100%.

I’ve already had helpful conversations where these data scientists \[outside my team\] share answers to questions like “what does your role look like”, “what’s something you knew when you first started” and other such broad topics. But these are one-time questions, and I am wondering how to maintain the relationship. **Specifically, are there more incisive topics that make sense to discuss over weeks/months? By make sense, I mean 1) enjoyable & organic for an experienced data scientist to share and 2) beneficial to a newbie data scientist?**

Put another way, the conversations I’ve had in this role are either 1) super technical (“maybe change the X hyperparameter”) or 2) super high level “I wish I had known X when I started”. I wonder if there are topics that are at an in-between level of technicality that feel natural for both mentor & mentee to talk about.

***I was thinking*** I could ask them to talk a bit about their current project, e.g. what kinds of data they rely on / what techniques have been most useful, surprises and pain points, etc. But I don't know if that is too much of an imposition, particularly since I'm not a team member and don't necessarily have full context of the problems they are solving (nor can I help them in return).

edited for formatting/clarity and to add: I realize I'm basically asking ""how do I talk?!"" but I am coming to learn that that's not such an obvious skill!"
Navigating Temporal vs. fixed data - interesting problem,3,h77p8s,datascience,3,"I have a dataset with counts of unique users per organization that use a product. The dataset spans \~4 years and is broken up by month/year. 

I want to calculate the % penetration (i.e. out of the total # of employees at an organization, what % use the product in a given month). Ultimately it would roll up to an analysis thats examines different points in time (i.e. 6 months after onboarding) and gives a % penetration number. 

This is an interesting problem because obviously headcounts for companies change over time. I was wondering if anyone has any interesting suggestions for how to navigate this? For headcount data I'm using data from Crunchbase, but again that's static in time and especially with corona that can change drastically."
Would you use a remote service to manage your human labeling / data prep?,4,h14ies,datascience,6,"I've been working with a group of younger folks who, due to COVID-19, want to transition from their current careers to data science. A lot of them have basic business/coding skills but don't have the full data science background or experience with tools like R, Jupiter, etc.   


My own background is in data science (Masters in math + 10 years in ML roles). I'd love to help them out by introducing them to building data sets, the realities of actually applying tech to business problems, then transitioning them to building models. 

&#x200B;

Would you use a service where we can provide you with human labelling and management of your data sets? You pay a fee (similar to a VA) but we also provide job training to these folks. Of course, if they're really good you can even hire them directly.

&#x200B;

Feedback would be immensely appreciated."
how much face-to-face interaction vs. coding do you get at work?,2,h0zwvg,datascience,2,"Hi. COVID-19 aside, how much of your job is spent talking to colleagues compared to coding by yourself (or doing something else)?

I'm doing SQL grunt work and light data engineering, about two years since I changed careers (I'm in my 40s). It's fine for now. But even when we were working in the office, I had little face-to-face interaction with people. All the marketing analysts we work with/for are much more cheery and friendly with each other. I just spend a lot of time working on code by myself. 

I don't regret any career choices - just realizing that next year when I look for a new gig, I need to take this into account. 

So I'm asking how much face time you get, and what industry are you in? I'm in the marketing department of a big corporation, which I know for sure I will leave."
Autoregressive model with an exogenous variable?,2,h0thd1,datascience,11,"Before I start, I should say I’m an engineer rather than a data scientist, so please excuse any ignorance on my part.

I’ve got a univariate time series - a bunch of physical measurements which describe the performance of a machine I’m working with. This data has a cyclical pattern. What I’ve seen is that the measurements are generally high during the middle of the day and low at night. Given my understanding of the equipment, I believe that the data is influenced by both the ambient temperature (it’s outside) and by its internal state or past performance. I’ve looked at PACF and ACF which supports the latter.

What I want to do is build a model which will estimate its performance at t0 given measurements at t-1 ... t-n and the ambient temperate at t0. That way, if the estimated performance is way out of whack from its actual measured performance, I know something unusual is happening and I can schedule a maintenance inspection.

A plain old AR model might be sufficient, but that doesn’t take into account temperature. I’m thinking about training an LSTM model, but that seems like overkill. Are there any other models I ought to consider? Some other way I can use temperature data to improve the estimate I’d get from an AR model?"
How or What do you model for in an inherently unpredictable field?,1,h0iefy,datascience,4,"Hello my fellow data science professionals, I hope you all are keeping safe and doing well.

So a bit of background to the question, one of my close friend runs a business which operates in the event & entertainment industry.
He is a vendor that provides a niche service for large format events & activations. let's call this service A for the sake of this post.

Service A requires a lot of equipment and people who are skilled in operating that equipment. He has his own large inventory of equipment but once in a while, he gets an event with a large scope, wherein to be able to provide that service, he has to purchase more inventory, which might be used immediately or can remain with him for a long time.
He has employees hired to manage and deliver the service, but again if the scope of an event is large, he hires freelance manpower to execute and provide the said service.  

As a nature of the industry itself, everything is need-based. the way it usually works is:
A client (can be corporate or a wealthy private client) sends out a brief of what he/they intend to celebrate or organize an event -> This brief usually goes out to few event management companies -> these companies propose a plan/theme/budget -> client approves it/negotiates on a budget -> event happens.

Now, the event management companies can approach my friend for service A, either during the proposal phase or after the proposal is approved in which case they have already factored in a service A in their proposal and budgeted a certain amount for it.
Each approach by the event company is considered as an incoming inquiry for hiring his services.

My friend approached me if I can help him out in some way using data science. I have been thinking about but cannot figure out a an idea to model for. Whatever I do I want to ensure that it helps his bottom line. As you can imagine, the current pandemic has destroyed the industry and his business altogether, and since he has some time, he asked me for my help in gathering some insights which will enable him to tweak his processes for the future.

I thought of modeling for his handling of inquiries, wherein I can glean some insight into the probability of an inquiry turning into a business which helps him focus his resources on something which has more probability of generating revenue, but again he and his business are blind to what is going on at the event manager side, he only sees what comes to him and he keeps track of it.

There are other aspects of his business where I believe something can be done, for example, Inventory management & analysis, optimizing operational manpower (he uses inhouse and freelance manpower for his business), but these do not directly help in bottom line, they will help indirectly in a long term and I'm not discounting it, it's just not a priority for him.

So basically what I'm asking is, has anyone modeled for a business that is inherently unpredictable like stock markets and what would you even start looking at which will translate into the bottom line for the company. 

Any and all ideas are welcome."
Building analytics dashboard as a web app or use softwares such as Tableau or Power BI?,2,h0i4u5,datascience,19,"I am well versed in web development, so building a web dashboard won't be that difficult for me. But what technology is more used in the industry, do people use tableau or power bi to build dashboards or implement them from scratch on a web app.

Ps: the dashboard I'm building includes few KPIs and a sale forecasting part that uses a tensorflow trained model."
PhD by publication?,13,h0hrme,datascience,24,"I've seen people talk about ""PhD by publication"" or ""by published work"" - essentially a PhD that is awarded for a body of works published in peer-reviewed journals, instead of one thesis. You can read a better explanation than I could write here: [https://www.findaphd.com/advice/phd-types/phd-by-publication.aspx](https://www.findaphd.com/advice/phd-types/phd-by-publication.aspx)

Anyway, I see this most often discussed in Arts/Humanities/Social Sciences. Do such degrees exist for Data Science or any of the tangential fields?

EDIT for context: I'm an MSc Data Science student, and I've decided to drop out of my programme. I've been miserable the entire 16 years of classroom education I've received, but it recently got way too bad due to how my department handled the COVID crisis.

The thing is that while I hate the education part of academia, I do want to do research. I already have one publication under my belt, which came from my Bachelor thesis. For now, my plan is to work in the field 0.6FTE and do research in my spare time - a PhD by publication would be a way for that to culminate in a PhD for me, without forcing me into a soul-crushing classroom."
Forecasting seasonally with alternative averages other than monthly.,1,h0hpnt,datascience,1,"Im working on a forecasting model dealing with call center data that is seasonal with about a years work of data. So far I've seen the data has a Coefficient of Variation (COV) of 25% across my monthly and weekly. I'm trying for precision so I want something lower. When I do ""day of the week"" averages, Mondays averaged with Mondays and Tuesdays averaged with Tuesdays..(etc) the COV drops to 11 - 15% now while I know COV isn't the be all end all and has a lot of assumptions caked into its use. I'm not familiar with a method to translate these with seasonal factors that are based on periods of time not in the daily form. 

Directionality is important. But if I have a clear significants issue I would like to know too. 

Anyone have any thoughts on how to achieve this or recommendations on alternatives that would yield more accurate results?"
How to support remote DS internships?,163,h0h3p0,datascience,44,"I’m looking to try bringing on a pair of DS/ML interns for this summer-fall. We’re a remote first company so as a whole we’re pretty comfortable working in an asynchronous fashion but internships are an entirely different can of worms. Has anyone here brought on remote interns this summer and if so, any words of advice or things that are/aren’t working? Know of any remote internship write-ups similar to GitLab’s remote work guide? Would really love to give some students the opportunity at an internship/results boost, but also don’t want to set them up for a terrible experience."
"Dashboard. Do you hate it or love it? Is it useful, or a simple data dump?",5,h0acw5,datascience,8,Thank you for your time and for sharing your experience visualizing data for engineers and business folks.
Judging the feasibility of potential projects in a company?,1,h091ug,datascience,4,"Hey in my company we are currently trying to figure out which possible project to tackle next. What are some good questions to ask the ones who proposed the ideas in order judge the feasibility of a possible project? 

Some things I've gathered so far:

## Can It Generate Revenue?

## Can You Use Existing, Proven Technology?

## Is there enough support available by domain experts?

## Cost of data acquisition

- How hard is it to acquire data?

- How expensive is data labeling?

- How much data will be needed?

## Cost of wrong predictions

- How frequently does the system need to be right to be useful?

## Availability of good published work about similar problems

- Has the problem been reduced to practice?

- Is there sufficient literature on the problem?

## Computational resources available both for training and inference

- Will the model be deployed in a resource-constrained environment?"
Have you ever considered leaving the industry?,47,h03s6t,datascience,55,"I'm on my second job out of college making 160k not counting equity, etc. It's a rebranded data analyst job.

It feels too early in my career to feel burnt out, but I cannot overstate how bored I am. So much of the work is ""investigate why this metric moved in this direction"". It's not only incredibly boring, it's unrewarding: after hours or days of slicing the same data a dozen different ways, we rarely unearth an explanation, anyway. 

I'm tired of ad hoc analyses, but I don't want to go back to school for a master's to learn and/or be considered for ML jobs, either. It doesn't interest me.

I hear people talk about loving data visualization, or enjoying investigating and telling a story with data, and while I believe them, it's also kinda incomprehensible to me at this point.

**Have you ever felt burnt out? And/or have you ever considered leaving the industry?** 

What's stopping me is the thought of walking away from a (currently) successful career trajectory. I am unhappy, but I'm also aware that I'm privileged and may not be aware of the realities of other jobs. I would be very curious to hear how other people have weighed their options when considering leaving this industry (even if their desire to leave was motivated by something other than dissatisfaction)."
Early Career Data Scientist Pain Points,315,h01j32,datascience,77,"I think I am having a mild panic now that I've landed my dream role as a data scientist. I felt like I was entering the job market as a strong candidate (engineering undergrad, analytics masters, 3 years work experience as a data analyst-y job, multiple data scientist interviews + offers). 

It's been just over a month in my new role in a new company. I'm the only data scientist in the organization, so I have no support and don't know if I'm doing things as I should, causing rework when I find a silly error. I feel like I'm missing out on valuable experience learning from a senior and am scared issues will come back to bite me when my models are put in production. I don't like feeling so lost and and I feel like I'm floundering. Any advice for an early career data scientist and how long do you think it will take for this feeling to go away?"
Need help on applying data science/visualisation to profit and loss statements/ finance statements in general,2,h01f27,datascience,4,"College student here who is at an internship now working for a large company. This company is in the midst of transitioning into a more ""data driven approach"" and I was hired as an intern to aid in that. They do not have a data science team and most only have a vague idea of what they hope ""data science"" can acheive for them but not any practical applications.

 I am attached to a sales manager and tasked with identifying ways that I can help her with her job such as creating visualisations or improving her workflow. The issue is that the data she is working with is mostly financial statements or profit and loss statements that have been prepared for her, consisting of tens of rows of values such as ""revenue from food"", ""cost of salary"", ""cost of utitilities"", ""cost from bonuses"" etc. Her job is therefore to look through these numbers and identify points that can be improved on such as questioning why costs are rising even though revenue has fallen, or why there is still a cost for tv subscription when the restaurant has been doing delivery only. My experience is in data cleaning and visualisation in R and python. I am struggling to even read in the data that has been formatted to be in this format, and to visualise data that has so many variables that have to be looked at in such great detail.

 Any help would be appreciated!"
"I'm not a data science, but I have been tasked with someone data related and I'm really hoping to get an idea on where to start - hoping you all can give me a hint.",2,h00b5j,datascience,10,"Hi all, I'm not even confident I can formulate and summarize my task objective, but I'll try.

I""m a software engineer who works on a very complicated custom enterprise software.  This software literally does a million different things in a business of 100 very complex business functions.

Currently, we are totally inundated with 'help desk tickets' that come in.  Software developers complain they need more staff, but managers demand metrics.  The developers find it near impossible to find any pattern or trend in the tickets because each on is so unique.

Nonetheless, management demands we go through the exercise.  I have no idea where to start.  How to categorize the tickets.  How to find the theme or the trend or anything.   


I need to make a pattern that is meaningful, obliviously, but no idea where to start.  It's kind of a ridiculous request, but I have to take a stab at it. 

So I guess my question is.  Is there a body of knowledge someone could point me towards?  Perhaps definition or a term that is going to assist me in building a structure?  I understand this may be a crap shoot and my question may be absurd, but thanks for your time!"
Basic resources data scientists need to be effective,63,gzvvco,datascience,21,"1. Flexible training and development environment 

2. Access to standard and emerging frameworks

3. Clear pathway to deployment

1) because development is key and some training tasks are lightweight while others require increased resources, 2) because frameworks for analytics, ML, and DL are important, and 3) because minimizing pain of deployments is good for everyone.

What  other basic resources would you data scientists need to be effective?"
Identifying and masking personally identifiable information - any solutions/products similar to Microsoft's Presidio?,0,gzt9s2,datascience,2,"I'm working on a project with partners that require their data to be masked of any personally identifiable information before they're willing to allow analysis. These data are primarily long form texts that may include mentions of names, addresses, etc. that need to be procedurally detected and replaced (e.g. ""Brian"" becomes ""<name>"").

[Microsoft's Presidio](https://github.com/microsoft/presidio) seems to be a fantastic option, but I'm trying to find other solutions to weigh them for this specific application. Does anyone know of similar solutions/products I should consider? I get the sense that Amazon's Macie is similar, but that seems to be for tagging documents rather than masking text within those documents."
"How do you measure experience, pain points customers have in interactions with customer care?",83,gzlr90,datascience,23,"I am working on a pet project, where I am trying to find scope of improvement in services of a telecom company and also the customer care interactions. For a start, I have picked all interactions on relation to changing rate plan. Customers can use any channel to change their plan - web, app, call care support, chat with an agent, visit store etc. I am looking for a way to measure pain in their journey while changing plans - how much time did it take to browse plans and make a choice, was the app experience so bad that the customer had to call care center, were there any wrong expectations set or miscommunication that made the customer call back care after the change (issues with billing, device etc)

One way I thought made sense would be to use CSAT score, find correlation with features like time spent, number of calls or visits, number of times channels was switched, and try to come up with a way to quantify the pain experienced in each step. 


Let me know your thoughts on this, does the above approach makes sense? Is there a better way to do this?


Thanks a lot in advance!!!"
Disconnect between course algorithms and industry work in Machine learning,47,gzlg6z,datascience,22,"I  am having a very difficult time in being able to connect the algorithms  we learned and implemented in school and solving practical problems at  work, mostly because the data in the industry is too noisy and  convoluted. But even if the data is better, in general, things taught in  school now seem to be really basic and worthless in comparison to the  level of difficulty in the industry.

After  having struggled for almost 8-9 months now, I turn to Reddit to seek  guidance from fellow community members on this topic. Can you guide me  on how to be able to handle messy data, apply and scale algorithms to  varied datasets and really build models based on the data statistics?"
How do you cluster time series data?,26,gzjvyl,datascience,10,"If anyone has examples in python that would be great! I'm looking to use k-means as a start, but am unsure as to how to get time series data (in a pandas dataframe) in a state that can be accepted by a clustering algorithm"
Recommendations to practice coding with R,14,gzd84g,datascience,18,"Im currently a Business Analytics student in college and I’m interested in getting better at R. I’ve taken a data management class which delved into R, so I am somewhat comfortable with ggplot and dplyr verbs. 

Any resources you guys would recommend for getting better at R, specifically for data analysis and predictive analytics. Thanks!"
The Future: Value in Data Science Beyond Models in Production,21,gzcirb,datascience,11,"Hello everyone,

I've seen variations of the question ""What is the future of data science?"" asked before, but I think mine is unique enough that it would make for a good discussion in its own post. It's based on a 2020 RStudio Conference presentation mentioned in some other posts, called ""[Value in Data Science Beyond Models in Production](https://rstudio.com/resources/rstudioconf-2020/value-in-data-science-beyond-models-in-production/)"".

In the presentation, the speaker makes the case for why Data Scientists should focus their efforts on providing value through things ***other than*** deploying machine learning to production. As an aside, I think the definition of ""Data Scientist"" he is using is more of a Decision Scientist. The gist of his message is:

* Machine Learning Engineers are likely going to take the ML work that Data Scientists currently do, and will create off-the-shelf ML tools (e.g. AutoML), hence decreasing the need for Data Scientists to do ML.
* Data Engineers are already better than Data Scientists at cleaning data, building pipelines, and warehousing, and so this part of the data science process will be owned by Data Engineers.
* What work does that leave for Data Scientists? What the speaker describes sounds like the work of a Product Analyst:
   * Business Intelligence-type work (metric design, measurement, goal-setting, creating self-service data tools)
   * A small amount of ad-hoc ML modeling
   * Inform business strategy / product design based on data analysis
   * Experimentation
   * The human side of data work - ethics and communication

Here are some questions that the presentation raised for me:

* Do you think his prediction is accurate?
* Will the work of tomorrow’s Data Scientist be more like today's Product Analyst?
* Do you think his prediction is only true of the tech industry, or does it apply to all industries?"
"Does anyone have experience with the R ""stream"" package?",2,gz9gdm,datascience,0,"Using it for two-phase clustering but can't for the life of me figure out how to export the cluster results... I just want the cluster label next to the values for each observation. 

There's a save function but when I export all my cluster values show ""NA""."
Walk me through your DS Stack - ML DevOps,0,gz0xyp,datascience,4,"Dear Data Magicians

'tis the time. Show me your DS Stack! Our field is going through rapid transitions, many of these focused on operationalization (yes it is a word). In a sense, how do we jump from the '*guy in the basement who comes up with cool models*' to '*well oiled machinery that spits out and maintains awesome models*'. 

Let's standardise the responses somewhat, then I'll collect the responses as much as I can at the end of this main post. 

I'd like people to simply list the technology they use at their firm. Some of us may use experiment tracking, others do not. Some may require high-frequent updates, others do not, and so forth.

Please add a link to the technology you refer to :-)

&#x200B;

|Technology|Purpose|Open Source/Closed Source|Pricing|Comment|
|:-|:-|:-|:-|:-|
|[weights and biases](https://wandb.com/)|Experiment tracking and documentation|Closed source|Free (personal), 35/user, and 175/user (corp)|Really solid piece of software. Good support for most ML frameworks|
|[Data Version Control](https://dvc.org)|Data versioning|Open Source|Free|We use it in particular for Deep Learning|
|[AWS SageMaker](https://aws.amazon.com/sagemaker/)|Serving and training|Open Source (somewhat)|Depends on the tier (min. 0.08$/hr)|Not really great for custom models|

&#x200B;

**Tech. challenges I've yet to find a solution for:**

* How to best manage models that read/write from DBs best way possible?
* Efficient ways to automatically run tests on X independent separate ML models
* Best way to store and access (large) flat files

**Curious to try or work with**

* Kubeflow
* MLflow
* GCP vs AWS vs Azure vs Bluemix - Pros/Cons?

**Best advice**

* If you don't have one already - Design a standardised best practices handbook for your team. You should have a template for a DL project, as well as smaller ML projects. The template should be designed in a way that allows for easy reproducibility and productisation (See previous post I've written [here](https://www.reddit.com/r/datascience/comments/gw8z13/do_you_code_in_object_oriented_way_in_python_when/fsu2p8p?utm_source=share&utm_medium=web2x))
* The rest of your organisation is not necessarily interested in what you are interested in. **Do not focus on mathematical rigor but business objectives.** 
* **Fail fast:** If you cannot get some value relating to the business objective out of the data, post cleaning of course, move on. Summarise findings and what you think is needed to achieve the sought after business objective (Additional data / Other data / Qualitative analysis - Shadow a worker in a function), hypothesise on the reasons for why the relation is not there. Ie. Maybe customers are price insensitive? Maybe they churn due to factors we do not have in the dataset?"
Miss hire for the current role,1,gyy3n0,datascience,5,"I'm working as a data scientist in AWS for the past few months. I have my interest and background in Machine Learning but the role seems like an analytics role. 

Given how fast paced AWS is, I'm lagging behind to catch up. The role needs a lot of SQL expertise, while I know SQL it was mostly for querying and creating data for ML needs, but not for analytics all together. 

I don't know what to do. I'm getting super anxious."
Useless tutorials and blog post will NOT improve your CV but WILL waste our time,970,gyv6to,datascience,149,"I see everywhere an inflation of data science blog posts, Medium posts, Linkedin posts which are adding literally ZERO value to everybody in the field. If you think we need another explanation of why p-values are important, or how to read a CSV file in Pandas, you are wrong and you are wasting your and my time. Walk me through a nasty dataset cleaning process. Show me an end to end project of yours. Enlighten me with that new, weird, just-out-of-the-Academic-press new kind of Neural Network. But showing me how to make a line plot in Matplotlib? Thanks, there are 5000 tutorials out there for that. If you are doing this, and hoping that your reputation will improve as a consequence (and maybe your chances of getting hired) you are doing yourself a terrible service. Stop the noise, do ONE really new and impressive thing and you will have: (1) actually added value and (2) started to make a name for yourself out there. Thanks for watching."
"Users of R , what kind of jobs do you automate ?",98,gyrxi1,datascience,58,"With no intentions of igniting the argument between R and python , users of R what’s jobs have you automated using what tools and on what platforms ?"
Tips on Converting Colleagues to Scala from Pyspark?,0,gykqyt,datascience,7,"I've been a huge proponent of Pyspark, but lately I've been working with very large datasets and have realized how much of a boon Scala really is.

95% of my data science org continues to use pyspark, while 100% of the data engineers we work with use scala.

I'd like to mount a campaign to slowly convert my colleagues to Scala. I'm thinking of writing internal libraries to help automate certain workloads (i.e. loading datasets, transforming them, A/B testing frameworks, etc.), bringing in outside trainers, and having office hours to help transition more folks to scala.

Any other tips to help transition the org to Scala? I don't want to be one of four data scientists writing Scala because inevitably some manager will tell me to conform and write pyspark instead. Or I'll have colleagues that will ask me to convert my scala code to pyspark (even though they are brain-dead simple to convert)"
Books on Mathematical Modelling Thinking and Simulation,21,gyfp4x,datascience,5,"Hi guys - I have been doing a lot of machine learning in my job as a data scientist, but am interested in becoming a more holistic mathematical modeller and recommend non-ML solutions?  My dream is to be able to look at a problem and be able to find the optimal solution balancing model fit with practical aspects e.g. training time and quality data availability.  I am particularly getting interested in the area of simulation as an oppotive.

I was wondering if anyone had any recommendations on:

1. Books on general mathematical modelling thinking
2. Introductory simulation books
3.  Other techniques to explore"
Weekly Entering & Transitioning Thread | 07 Jun 2020 - 14 Jun 2020,5,gyb2ph,datascience,163,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Apache airflow,1,gy9ff2,datascience,1,"Hi,

I'm considering using airflow for my ML pipeline on AWS, and I have some questions about basic setup (perhaps noobish). 

I would prefer a serverless setup, but that seems out of the question in the cloud, since you have to host an airflow server?

The airflow server seems like a bit of an overkill, and I'm unsure how to control costs, scaling, python environments and memory/cpu/gpu requirements to each pipeline step?

Alternatively I thought about using it as 'command station', where the ML pipeline just delegates pipeline tasks to fargate and lambda functions - this seems nice, because I can get all the flexibility that I want using those other services, while keeping the server small.  


The reason I want to use airflow is of course because it seems awesome, and I would like to have that overview over the pipes etc. I could just setup a bunch of lambdas/containers, but I would never know if anything had failed.  


Much appreciated!"
"Users of Python, what kind of jobs do you automate?",323,gy92pt,datascience,134,
Audible suggestions?,5,gy6mcr,datascience,8,I just got Audible and was wondering if any of you had some data science/analysis related recommendations from there that you enjoyed.
Comparing Round 1 vs Round 2 analysis submission,3,gy5p5w,datascience,3,"Hi All

I am an engineer who does a lot of analytics in my company particular around budget and plans. I receive inputs and data, determine a methodology, assumptions etc. Conduct the analysis but often have 2 or 3 rounds of submission and I have to explain each time why things change and the differences.

Does anyone have any tips in how to do this?

For example, I was rushed to do analysis and submitted something, received new data and redid my analysis and my superiors ask me why it is different. Do I just say different data or should I be analysing why different and keeping logs?

Thanks in advance"
Any Data science books that one can read without needing a computer or pen & paper?,197,gxwntt,datascience,46,"I'm trying to transition into Data Science (I'm a software engineer). I spend most of my free time learning DS and ML, doing own projects, reading textbooks, coding etc.

But I would also really like a book I can read without having to sit by a computer/notepad to follow along with code/math. Maybe a book about how to think about data science/data/analytics.

I spend 1 hour before sleep sitting in a sofa, reading books. Just want a book I can read without needing to constantly switch to a computer to test out code / do math.

Suggestions?

**Edit: Big thanks! My ""future reading list"" has enough material for a years worth of reading now I think :)**"
Macbook or Windows for data science?,8,gxufr6,datascience,19,"I'm about to purchase a new laptop soon and I wonder if I should get a Macbook or a Windows PC (and install Ubuntu)?

I heard a lot of companies provide you with a work laptop so I wonder if it's even worth it spend a lot on a personal laptop.

My goal is to have the best tool for data analytics and maybe some software engineering down the road.

thanks"
IDE for Data Science,3,gxfpim,datascience,19,"Hi guys,

I have been working in the data area as a Data Analyst and have always used jupyter lab to do my analyses. I'm trying to learn more about data engineering and I see that almost every tutorial I see people use other tools for code like IDE.

Why don't they usually use IDE for Data Analysis or Data Science?

Thanks for your help!"
Would it be foolish for me to turn down a (non-data) Tesla internship?,0,gxa6ex,datascience,6,"My undergrad and professional background is in industrial engineering/supply chain but I started grad school for data science last fall. I have always loved stats and programming which is what drew me to IE but felt like I wasn’t able to get roles that were analytical *enough* for my liking. 

This week I was able to secure two offers for summer internships (after weeks of anxious scrambling but that’s another story). One of them is Tesla. While obviously not a part of FAANG, I definitely perceive Tesla as at or just below that level. The only “issue” is that it’s not really an analytical role, it’s very supply chain oriented (like my background) with just one project with one of their analytics teams (which was a post-offer request from me). So like best-case scenario, the role is like 20-25% analytics, and the rest is similar to experience I already have. 

All I’ll say about the other offer is it’s a place that’s reputable but nowhere near the level of Tesla, and that the role’s primary function is about data management and analysis, more what I was hoping for. 

As someone who’s trying to break into the tech industry, is it foolish of me to turn down a summer at Tesla, even if the role is not very techy? It *feels* like it would open doors for me just on name alone. Or am I overevaluating the worth of such a role, and would make more sense to take the other role that’s more in the tech wheelhouse skillset-wise?"
How does Anaconda manage libraries ?,2,gx73yb,datascience,16,"So i am fairly new to Data science and  i have been using python 3.7 with atom and downloading the packages through pip command .

I want to try using anaconda and my main doubt is that if i should download the libraries like numpy,pandas again?

I heard that things like Tensor flow work on old version of python and in the anaconda download it says that V3.7 is being downloaded. So how is that managed?

And how does jupyter notebook work,like does it depend on the libraries you have in your computer (do i need pandas installed to use it in the notebook)?"
"As a part time data scientist (also working on my doctorate) who's been doing this for 10+ years, I'm starting to feel a bit like a dinosaur and my job has become 90% fluff and people management. What resources do you guys use to stay relevant and what new and cool things have you been using?",385,gx5iww,datascience,40,"I realize this is a very broad question but I'm legitimately curious what else others are using to learn, code, and analyze data these days. 

I'm working towards a doctorate simultaneously so I've been spending more time learning about the theory behind things and how to assess statistical significance. I spend anywhere from 10 minutes to an hour browsing through google and cyber security blogs every day and I tend to come up with 90% fluff. 

Every once in a while I stumble across something major and amazing (Hello GANS!) but I can't seem to find some good reliable resources to stay up to date on things when I'm mostly not using the latest and greatest every day. So good people of reddit - what do you find the best resources?"
What are the major problems big tech companies are trying to solve?,10,gx2bg2,datascience,25,"From my understanding, data science is basically the practice of using data to solve problems. My question is, from a high-level perspective, what are the sorts of problems that big tech companies are trying to solve, and can anyone recommend a reference/ textbook that explores this subject in detail?

Thank you."
How many of you work as data scientists but have a degree in something else than Data Science?,3,gx24xs,datascience,26,"Interested in knowing what path some of you took that don't have a B.Sc./M.Sc. in data science, what were the challenges, was the degree somewhat related or entirely different, etc."
Professional Data Scientists: How do you track your experiments?,4,gx04es,datascience,5,"Hi everybody,  
I need some collective knowledge on collaborative data science. Mainly what I am looking for is to get a better overview over my teams experiments / training of models.  


Our current state:  
We are currently training NN for Computer Vision using jupyter notebooks, csv files for labels and operation systems directories to store the images. People execute their notebooks and they sometimes get errors because someone else is currently training on that gpu (of which we have 2).

  
So what am I looking for?  
1. A data store for our datasets with some kind of data lineage. (Can be solved by postgres or what ever. Fair enough.)  
2. Provisioning of some kind of execution queue so that people can queue up their notebooks and have the results 24h later.  
3. A multi tenant experiment store (like model db, ml flow -- but I would like it to have support for multiple users).  
4. The possibility to review and comment on experiments so that we can assist and teach each other. Similar to how gitlab handles pull / merge requests.  
5. OpenSource.  
6. Optional: self-hostable for free.   


Multi Tenancy is a must for me. We need open discussions on approaches to Data Science / ML Problems. So is open source -- mainly for the same reason.   


Technologies I looked into but am very happy about for comments:  
Kubeflow, OpenShit/OpenDataHub, Mlflow, VertaAi/modelDb  


I have a long list of tools, currently I try to deploy pachyderm to take a look at it. Meanwhile I would be happy about your views, suggestions.  


Best wishes"
What combinations of colors have you found work best for plotting data? Obviously yellow on a white background doesn't work so well...,0,gwzrm1,datascience,8,
Jack-of-all-trades,34,gwz8s9,datascience,17,"As a Data Scientist, is it better to know multiple coding languages to an adequate level (i.e a jack-of-all-trades, but master of none) or to have a really in-depth knowledge of a single language?

I'm thinking in terms of job opportunities, the quality/salary of those opportunities and in general.

(Edit: typo)"
How respected are statisticians in the government?,15,gwvnfx,datascience,14,"I was recently offered a statistician (GS-12) role. I recently finished my master's degree and have had a bit of trouble landing a new job, even with a couple years experience.

The work sounds interesting, but I've been told government workers aren't really well respected/have a really bad reputation. My plan would be to stick with this position (since it's in the government and relatively stable I'd imagine) until the economy is better, but would I have trouble transferring back to the private industry due to the reputation of government workers? Not sure if statisticians have that same reputation...

Poking around on LinkedIn, it looks like most who work in the government stay in the government..."
"Professional data scientists: did you overcome the feeling of never knowing enough? If so, how?",183,gwt750,datascience,60,"Hello!

I'm a junior data scientist, been working in the field for about a year after getting a professional master in this topic.

I work for a small startup, which means that I have no mentor and I have to figure out shit on my own, as well as deal with everything that is data related (not just data science, but also engineering, ETL and what not).

It's fun and challenging, but also at times very frustrating, because I have this constant feeling of *never knowing enough,* and given the complexity and depth of this field, and the pace at which it develops, it is really overwhelming.

Also, coming from a business / economics background, my math and stats skills are not exactly razor sharp.  
I compensate by being a massive nerd, so I learn stuff quickly, but that's about it.

Advice?"
Book Hunting,1,gwml6j,datascience,4,"Hello people of reddit! I am Stella and this is my first post \^\_\^

So I am about to finish a Master's program from university on computational intelligence and I want to go deeper since I decided to take this seriously as a career scenario. I have a bachelor in Physics with a specialization on Astrophysics so research is the main area that I will go hunting for a job.

So I am between 2 books( both from O'reilly Publishing company ):

1. **Python Data Science Handbook: Tools and Techniques for Developers** by Wes Mckinney
2. **Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems** by Aurelien Geron

Is anyone familiar with either the books themselves/ Publishing company / authors that has something to add because this is a new area for me and I looking for feedback.

Do you have any book/tutorials recommendations?

Cheers"
Career advice as my coop comes to a close,2,gwmj5h,datascience,2,"Background:  
Hey guys, long time lurker first time poster so please bare with me. I am currently a  sophomore student at UTD who is majoring in ITS , who will be completing his fist professional level job in August. I have been working at American Airlines as a junior Data analyst for what will be 8 months in August. and as its quickly approaching, my concern for life post coop are growing.  Before getting this coop, I could barely support myself financially and so I have been making the most of my coop income by paying off debt, but as I look at what I was making pre coop I am realizing that my debt reduction rate at the moment still wont reduce my monthly expenses enough to were I will be able to sustain myself.   


Question: 

While working at AA, I learned python, machine learning, sql, and neural networks for the most part and I am wanting to know given the pandemic and my financial situation how do I best prepare myself now so that I have a fighting chance to make a transition from AA to another job in my field?  What should I be focusing my extra time on so that when the coop ends i can land preferably a part time jr data analyst position or something similar?"
What is in your model check list?,9,gwiue7,datascience,6,"What are some of the things you do after fitting a model (i.e. regression or classification)? To understand the types of decisions it’s making, understand if it’s biased or overfitting, etc.? 

This is a pretty broad question but I’m looking to create a checklist of things that should be done ensure you have a “good model” 

Things like:

*Check the correlation between variables (heatmaps, VIF, etc.)

*Check the feature importance’s/model coefficients 

*Use SHAP values / charts to understand the directionality of model features 

*Plot the drop-off in accuracy when eliminating features (either through backward elimination or pruning the most important features) 

*Plotting interaction terms between your variables 

*Checking the model performance for different encoding strategies (one-hot, target encoding, etc) 

*Plotting performance by different subregions in your data  

*Compare different algorithms for performance"
My thoughts on the data science job hunt during COVID-19,393,gwibmc,datascience,142,"Some background: I have 6 years of DS experience, 2 masters degrees, and spent a few years as a data analyst as well. Laid off from a smaller company in the midwest due to COVID-19 cutbacks.

&#x200B;

1. **""Data scientist"" is turning into a blanket term. So is ""data analyst"".** So many of the jobs I've looked at truly want a data engineer/DBA but ask for a data scientist. Or want a data scientist but ask for an entry level data analyst. Expand your search terms, but read the job description to figure out what the company really wants. This changes every time I'm on the job market even in my short tenure as a data scientist. When did ""Machine Learning Engineer"" become so big??
2. **On that note: ""Senior"" vs ""Lead"" vs ""Entry Level""**...the difference to me is huge, but most companies seem to be pretty flexible with what they're posting. Some entry level jobs have been open to changing to senior level, some lead/manager level would be fine with senior. If you like a job but are weary about the experience required, just ask the hiring manager/recruiter that posted it.
3. **Every company has a different way of testing your knowledge.** So far I've taken a data science timed assessment (no outside resources), completed a take-home assessment (48 hours and a dataset), and presented a past project for 30 minutes, all for different companies. Be prepared for just about anything, but use how they test you as a clue into their culture. For me, I love the take-home tests and presentations because they give me a chance to show what I know without as much of the pressure.
4. **Companies are starting to open back up.** Many job postings were taken down from March-May, but as of today the number of openings is expanding rapidly. Region may be a big factor. The companies I have interviewed with have stuck to either all virtual, or majority virtual with one in-person interview with masks and social distancing.

&#x200B;

Best of luck to everyone in their job search!"
How do I interpret this learning curve? Is this a case of high bias or high variance?,2,gwfjie,datascience,2,"Hi All,

I am working on a problem of binary classification. With a pretty small data set (100 observations, 21 features, and 70-30 target split)

Using cross-validation I found LogisticRegression (with liblinear and l1 penalty) to work best, giving my high AUC score (my metric of focus for the project). Please note that l1 penalty shrank all of the features except for 2.

I plotted the learning curve to understand how to proceed next. Here is the plot - https://i.imgur.com/Vm224zi.png

My problem is I am not able to interpret this plot. Is this a case of high bias or high variance? And why so?

Note: Y-axis denotes AUC Score

Here is the code I used to get the learning curve params (if it helps) - 


```
train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(penalty='l1', solver = 'liblinear'), 
                                                        X, y, cv=10, shuffle=True
                                                        , scoring='roc_auc'
                                                       )
```

Please Help"
Interesting R packages for experienced users,5,gwf2fw,datascience,11,"Hi, I want to compile a small list (for personal use) of interesting R packages that are worth checking out. I've been using R for many years and know most of the usual stuff (caret, tidyverse, packrat, ggplot, data.table,...), so I'd like to find packages that could help with more high-level concerns of a project, so to speak (say, reproducibility, iteration speed,..). For example I didn't know [Drake](https://books.ropensci.org/drake/) until recently, and I thought it was an interesting thing to try. I hope this makes sense, and thanks in advance for any suggestion."
ML within Cyber Security,4,gwf0yf,datascience,4,Does anyone work in machine learning in the cyber security domain? I am curious about opportunities in it. I know that ML is used heavily in CS but just curious about insider info from people working in the industry.
ML.NET community,5,gwczhn,datascience,1,"Hello guys!  
I just created space for people interested in ML.NET library, I encourage you to join there!

[https://www.reddit.com/r/ml\_dotnet/](https://www.reddit.com/r/ml_dotnet/)"
What work you are actually doing when your title is data scientist?,5,gwapzk,datascience,14,"I wonder what work are people actually doing under the data scientist title?

For me, I am doing a spectrum of technical-related data activties such as data cleaning, data pipeline building, data analysis, ML modelling, and data-driven company's internal improvement. I realized that in other companies, some DS mostly do ML modelling, some are doing data product building, and some are doing entirely data cleaning. It depends on how company sees the benefit of data people.

I begin to feel that data scientist is an umbrella term for everything data-related.

So I am wondering what actual work you are doing with this title?

Maybe my goal with this thread is to crowdsource information on how company is utilizing data-savvy people and what data related activities that a company is having."
Is the job market really fucked ?,18,gwa6nt,datascience,11,"Context : I’m an international student in the United States currently looking for an entry level job in data science. Due to covid-19 and it’s impact on the economy, I’ve been told by my batch mates and seniors who have graduated that it’s difficult/almost impossible to get a full time job right now. I’ll graduate next month after which I have till November/ December to get a job which offers sponsorship. Just want to know how much has hiring been affected in these circumstances for data science positions (data scientist, data analyst, business analyst, business intelligence analyst, risk analyst)"
Do you code in Object Oriented way in Python when doing data analytics?,272,gw8z13,datascience,150,"I just never got into the habit of writing object oriented code for data science, nor do I see a need. What's your thought?

The reason I'm asking is because someone asked to see my code for a data science role, and I'm starting to doubt myself. I might fix up my code a bit, and wants to hear some advice on what to watch out for.

thanks

PS: do you know where I can look at some good coding examples in data science?"
Why don't job postings ask for Data management / analytics degrees?,31,gw84jk,datascience,41,"This may be a silly question, but I notice that a lot of job postings are asking for ""Bachelor’s Degree or equivalent in Math, Information Systems, Computer Science, Engineering or related field "". 

All this time, I've been assuming that the Data management / Data analytics degree that I'm working on obtaining will fall into the ""Or related field"" category, but I'm asking this question, because I don't want to assume. 

Does anyone here have any insight on this? 

Do any of you have this particular degree?

If not, what are your opinions on this degree? (I'm working on getting this degree from WGU.)"
Importance of domain expertise to career growth,9,gw84ce,datascience,5,"How important is it to develop domain expertise? I'm struggling a bit right now because I've focused my past efforts on gaining general knowledge (e.g. universal time series forecasting strategies) instead of domain knowledge. As a result, I feel more like a consultant at times. What do you think are the career advantages/disadvantages to this?"
Does anyone use or came across weighted least square or robust regression in their work?,2,gw7wxe,datascience,7,"I am wondering if anyone use technique like Weighted Least Square or robust regression in their work. How does these models stack up against tree-based model, regularized model, or other ml model?

&#x200B;

I also posted the question in stackexchange.

[https://stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-re](https://stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-re)"
Experiments with infrequently updating metrics,3,gw38m8,datascience,3,"I'm trying to run an experiment, and the lag time to measure the impact of the experiment is about 4 months.  Has anyone come across this problem?"
Advice in B2B Sales Analysis,7,gw2pg1,datascience,10," I work in a B2B sales organization and our Director of Sales wants me to find the commonalities between the companies that each sales rep has had success selling to. I have data where each observation is a company the sales rep tried to sell to (opportunity), the characteristics (qual. and quant.) of the company, and the outcome (won/lost). Below are a few ideas I had on tackling this question, but I am wondering how you would approach this. 

1. Use a factor analysis method on the won opportunities for a sales rep and analyze the axes with low explanation of variance. Would this essentially tell me what makes these companies the same, as opposed to different? 

2. Use logistic regression with all the opportunities and analyze the significant variables that increase the probability of winning."
Spyder IDE Markdown,29,gw0ql9,datascience,16," Anybody have a way to create markdowns within Spyder IDE? Most reporting I've done in the past is in R using RMarkdown, knitr, etc and have not had the need to use Spyder for creating a markdown report before. I looked into spyder-reports and am not sure if that is still functioning. Any suggestions would be appreciated!"
How to evaluate a model performance after deploying into production?,15,gvzaik,datascience,16,"How do we evaluate the model performance after it is deployed? If it was normal prediction model, we could evaluate based on the actual outcome. However if there is outside interference to change the outcome of that model, how can we evaluate it? When I talk about outside interference. I mean someone takes some action so that that prediction doesn’t occur. Eg we are predicting if an apple will rot, if the prediction is greater than 60% we do something so that the apple will not rot. How can we measure the model performance? How can we know if the prediction was correct?"
How do you approach ML/ DS problem?,4,gvwo3j,datascience,4,"Hi folks! I am currently working as a Software Engineer in a Reporting/Analysis team using SAP BO and SQL. I am trying to get a job as a data scientist and had applied to a bunch of companies and did attend interview in a few. In the last interview which I gave, the interviewer asked me the above question, and I couldn't say anything which was able to convince him.

I have taken a bunch of MOOC courses and had worked on common UCI datasets. I have recently started with Kaggle as well (trying the basic one's right now). I know I have to improve a lot, but this question keeps on pondering me, as the interviewer was okay with me working with iris dataset as I am fresher with less than 1 year of full-time experience. He just wanted to know my answer to the above question. I tried thinking and giving a generalized answer but he wasn't impressed and asked how did you solve iris problem. Having watched n number of tutorials, the bias kicked in and I just said that I need to do EDA, understand the relationship between parameters and then go about solving the problem by applying, any of the many Classification algorithm, which I had done.

But he wasn't having it and this got me thinking that in the real-world you won't be given a dataset to work with, forget about proper expectation/requirement. And you cannot waste/invest a lot of time doing EDA as the client is looking for a working model and not a bunch of graphs and visualizations, so how to actually approach a ML/DS problem?

Can some of the folks working in the field describe to me, as how would have you answered the above question and typical tasks or problem statement you get during your job and your thought process in approaching the task.

thanks for your time, much appreciated :)"
How to proceed after the cross-validation step?,6,gvrll8,datascience,12,"Hi All,

I am pretty new to data science so pardon me if this is a silly question. 

So I am working on a binary classification problem and found out that Logistic Regression works best for my dataset based on 10 fold cross-validation accuracy score.  (Mean acc = 93.5%)


Now, I want to put a model into production to actually make some kind of prediction on future incoming data. 

Which model do I put into production? When I split my data into training and test and train the model it gives me different accuracy each time. I understand why that is happening. But when it comes to deploying this Logistic Regression model, what do i do?"
Frameworks to assess impact of models,1,gvr8p3,datascience,7,"Hello everyone, this is a little spot where I've learned a lot. After a few searches I could not find something that could help me learn about how to assess quantitatively the impact of a model.

Do you have any literature/video/article suggestions that I could put my attention to?


Thank you so much for your time."
Agile/scum is... the worst?,378,gvlcie,datascience,124,"I feel micromanaged and like I am expected to do analysis like an engineer churns out code. Daily stand ups, retros, bleh. There is also a sharp divide between ""product owners"" and worker bees who execute someone else's vision, so all my time is accounted for. No room to scope/source new projects at all.

What I love about analytics/data science and where my true value lies is defining problems and creatively working with stakeholders to solve them.

Does anyone have any recommendations about industries/companies/job titles to explore that give data scientists the scope to come up with new projects and where there isn't a strong product owner/technical divide?

Edit: Wow data people. Thanks for the responses! Been really interesting to read the diverging opinions and advice. My takeaway is that there can be a time and a place for these tools and perhaps the explanatory variable is management and company culture. Personally, I will try to be the change in my org that makes these processes work better. Thanks for enlightening me and breaking me out of my mental local minimum."
OpenAI – Learning Dexterity End-to-End - Experiment Report,1,gvgc0f,datascience,1,"Today OpenAI published a Weights & Biases Report ([here](https://app.wandb.ai/openai/published-work/Learning-Dexterity-End-to-End--VmlldzoxMTUyMDQ)) on some recent work done by the Robotics team at OpenAI where they trained a policy to manipulate objects with a robotic hand in an end-to-end manner. Specifically, they solved the block reorientation task from our 2018 release ""[Learning Dexterity](https://openai.com/blog/learning-dexterity/)"" using a policy with image inputs rather than training separate vision and policy models (as in the original release).

In the report they describe their experimental process in general and then detail the findings of this specific work. In particular, they contrast the use of Behavioral Cloning and Reinforcement Learning for this task, and ablate several aspects of our setup including model architecture, batch size, etc.

Alex and I happy to discuss this and answer any questions about it."
How to best calculate uplift from web traffic data?,7,gveu5l,datascience,2,"Did someone already build a model (not necessariliy DS but plain DA/calculations) to get Uplift value from marketing campaigns (e.g. TV) onto web traffic in Corona times and can talk about a bit about it?

I see a lot of spikes and a mismatching baseline due to increased Corona online shopping and wonder how I can calculate a new, good fitting baseline?"
"So many people disappointed with their jobs. You need to manage your expectations, especially if you're very junior.",661,gv3i57,datascience,102,"&#x200B;

I keep seeing threads on this forum about how disappointed so many people are with their data science jobs.

&#x200B;

I think expectations need to be managed, in any line of work:

1. **Seniority / juniority**:  When you start as a medical doctor, you won't start by diagnosing Dr. House-like rare, life-threatening conditions straight away. If you join a law firm, you won't start by passionately and single-handedly defending your clients in court like in a John Grisham book. If you join Goldman Sachs as a graduate, you won't start by managing multi-billion trades and investments straight away. **Any job has a certain amount of grunt work, which is greater at the very beginning of your career**. The world is full of bright kids disappointed with their first jobs, wondering: ""did I really study 3/4/5 years to change the colours of a PowerPoint slide?"".
2. **Importance within the organisation**: this varies wildly from place to place but, generally, regardless of the guff HR says, in many organisations there is a clear difference in the food chain between the functions which are seen as generating revenues and those which are seen as support functions. In many places, the sales team (or equivalent) brings home the money, and everyone else is seen as a support function. You don't need to argue with me that this is shortsighted: you need to understand that this attitude is common, need to do your homework on what the culture is like before joining a company, and make your decisions accordingly.
3. **(related to #2): what is the background of the senior people?** If you are a data scientist in a company where most senior executives have some kind of technical background, you are more likely to be appreciated than in a company where the senior guys (it's almost always guys...) are all salespeople who go into sensory shutdown the moment you mention anything more complicated than the times tables.
4. **what are the real needs of the business?** Even in the most enlightened organisation, with the most technical sensible competent open-minded etc etc executives, **there will be more need for boring work than for exciting, cutting-edge work**. For every person that must do proper R&D and brand-new, cutting edge models processes technologies etc, there will need to be many more people that must manage and maintain the existing processes and models, which is important even if less interesting"
Do less Data Science,256,guuer4,datascience,38,"That's why we're all here, right? 

I'd like to share with you a nice little story. I've recently been working on a difficult scoring problem that determined a rank from numerous features. There were numerous issues: which features were most important, did it make sense to have so many features, do we condense them, do we take the mean and so on. I had been working on this problem for weeks, and after numerous measurements, reports, reading and testing, I conked out -- I gave up. 

Man, Data Science was done for me; I was so over it. I started talking more with my colleagues in different departments, primarily in PR. I just felt like doing something else for a few days. I asked one of my colleagues in PR, ""so, what would you do if you had to rank X, Y, and Z?"" ""Hmm... I'm not so sure, I think I would be more interested in Z than X, why is X even necessary?"" She was right. Statistically, X was absolutely necessary in many of my modes. My boss thought this was the key to solving our problem, why would she think it's unnecessary? It turns out... as Data Scientists, we weren't the ones using the product. My colleague -- bless her soul -- is exactly our target audience. We were so in solutions mode, we forgot to just think about the problem and WHOM it concerns. 

I decided to take a walk and put pen to paper. I even asked the barista at the local cafe. It was so obvious. 

We were solving the WRONG problem the whole time -- well, at least we weren't making it any easier for ourselves.

To all of the great DS minds out there, sometimes we need to stop and reset. 

Problems are realised in different ways; it's our job as Data Scientists to understand who the realisation is for. 

Now, I'd love to know what your experiences were and how simplicity overcame complexity?"
Exponential functions and optimisation,3,gusf6x,datascience,2,"Help with expotential functions

Hey guys,

I have a problem with expotentially rising weighting of allocations. I have a given:

total number of assets --> total
maximum allocation(in weights) --> max = .15
minimum allocation (in weights) -> min = 1/total/2
My goal is that the algortihm gives the first asset the maximum --> P(1|max),
The y value should be expotentially decreasing but should not be lower than min.
And the sum of weights should be close as possible to 1.
How can I accomplish that ?
--> I looked into scipy curve fitting, but I do not know how to apply it"
Data Science Ethic Issues Suggestions,1,gur7t8,datascience,8,"I'm in a data science ethics course over the summer. In a few weeks I'll be giving a 3-5 minute presentation that is supposed to serve as an overview on a data science ethics issue. I know that data science touches a lot of large, overarching domains such as privacy concerns, but I was hoping to find something specific and unique since many other people will be giving presentations as well. For example, in class we read through an article by [Propublica about machine bias in court sentencing](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing). 

Googling ""data science ethics topics"" seems to be a recipe for somewhat mundane articles that are overly broad. 

I'll happily take any suggestions anyone is offering or resources on where to look for topics such as this. 

Thank you."
Real World Data Collection,10,gumw43,datascience,15,"Hi, I am a recent college grad and I majored in data science so I have taken my fair share of courses and projects in machine learning and statistics. However, most, if not all of the projects I do in school and even the personal projects I work on the data is very readily available and in decent shape where I just need to do some cleaning and manipulation of the data.

Currently, I am working on a project where I am trying to process emails and build a type of importance algorithm based on the contents/data of the email.

The emails contain sensitive information and the preliminary dataset I have been testing on (very small size, <100 emails) has any sensitive info redacted which is fine. But when I get to the point where I will need tens of thousands of emails it is extremely impractical to redact each one.

I was wondering if anyone has any ideas of ways to build a model that either doesn't use the contents of the emails, or a way to deal with the sensitive information problem.

Thanks."
At what point do you stop with a clustering problem?,120,gumr3u,datascience,50,"Hey guys, 

So we’re looking to cluster our social demographic data. I’m pretty new to clustering validation and when to say, “this is good enough.” 

We have no pre labeled data to test our clusters,  only silhouette scores of ~ 0.65

At what point do I stop optimizing clustering problems, or is it subjective? 

For some background on the problem: 
We aim to label the data into 5~6 clusters (domain knowledge from my boss suggests in theory there should be 5~6 categories. Will discuss with him more), 

We wish to use the data to synthesize new data. I’m not too sure how we will achieve this, maybe a variational Autoencoder, or we simply find the closest centroid for data of our choice and sample from the centroid (this is the added restriction that our data is distributed in different ways as we are working with real estate data)

Given the problem, I’d say it’s important we have very clearly defined clusters, but
I’m just getting my head in a real knot knowing when it’s good enough, and my boss has said it’s entirely up to me. 

Thanks guys!"
How to avoid non-technical errors and bugs ?,1,gufkqn,datascience,8,"Dear data-scientists,

**How do you guys prevent non-technical errors and bugs ?**

&#x200B;

I work as a data-scientist in a junior position. My typical workflow consist of the following steps :

 1) the client gives us a problem 

2) think about proper methodology 

3) gather the data necessary to solve the problem 

4) apply some statistical procedures to solve the problem (generally a model) 

5) build a report to send to the client (this report must follow the company's format and standards).

One aspect where I notice I am having difficulties or improvement are in what I will call the non-technical or non-statistical aspects of the workflow above. That is suppose you gather the right data and think about the proper methodology to solve the problem, but then how can I prevent errors on the coding and reporting, for instance:

\- you have the right methodology, but when you are coding the model you assign a wrong variable in the code in some step and then the results are not valid ( for instance you have x\_train and x\_test and you mistakenly do m = x\_test / 2 instead of m = x\_train / 2).

\- on the reporting stage, you exported the wrong results.

These are just examples.

Then you send your report and under scrutiny from your managers or revising things to answer additional questions you find this errors. Then it looks unprofessional to say that the initial results were wrong and you will have to update it. It may not inspire much confidence in your results in the future.

It has been hard for me to find ways to improve in this aspect because these types of errors are hard to predict. When you are coding you are already doing what you think it is correct. Given the time frames we have, it is also unfeasible to double check every single line of code. Also, the problems are generally very diverse in nature, so it is not like you can just adopt an automated or semi-automated methodology that you can work upon and improve, many things you have to build from scratch every time you receive a new project.

&#x200B;

**How do you guys prevent this type of errors ?**

&#x200B;

Thanks in advance."
How do you manage credentials/passwords for your data pipelines/ETL jobs?,27,gue1fu,datascience,6,"Hello, first time system architect here. Or rather, I'm just the most experienced dev so [they gave me the reins over the project architecture](https://i.imgur.com/43eedLE.jpg).

Anyway, we're building a data analytics platform and just finished our first pipeline that ETLs from a DB into our data warehouse. We were provided a read only account for that DB and initially, we saved the username and password in a gitignored credentials.ini file that we would manually copy paste during deployment.

We're about to start our second pipeline which will involve another DB and another set of credentials and it's becoming apparent that our project will eventually contain all the (read only) keys to the kingdom. We've switched to saving the credentials in a keepass vault (.kdbx) which is checked into our repository while manually copying the keyfile.

I understand that if we want these pipelines to be automated, those credentials are going to need to be accessible from within the system so really, I'm just wondering if there's a better way to manage the storage/deploying of them within our project.

We're using Python btw"
Does anybody know how to share the google colab document so people can run the notebook but cannot see the actual code?,3,guafw0,datascience,8,"I am trying to share the google colab document (that contains my data-visualization project) with friends so they can run the code but not actually see the code, because I don't want them to copy the code. How do I do this?"
Is there a website/platform where you can sell/buy datasets for ML?,8,gu9lym,datascience,8,"I was thinking if there is a supply/demand enough for such a platform (where you can buy/sell) to exist. There is a ton of demand, but are there enough people willing to supply?  


Here the data providers can be organizations, or the people generating data themselves."
What would be some good datasets to explore for identifying systemic/institutionalized racism?,0,gu99p1,datascience,5,"This post is not meant to be a statement of political belief or discussion about current events, necessarily. That being said, current events have led me to wonder: what can the data science community do to identify instances of systemic racial bias? What if you could apply the spirit of a fault detection model to a sociological/demographic/economic-related dataset?

Anyone aware of any datasets (or even bounds for what would constitute a useful dataset) with this goal in mind?

I'm not asserting that you can just throw code, models, and data at a deeply rooted social issue and expect it to magically resolve - just that maybe there are some opportunities here."
Tableau software,7,gu2zys,datascience,10,"Hey there, 

Anyone know of a way to get a free limited version of Tableau for personal use and self-study?"
Does anyone else that has been doing data science for a while find it incredibly boring?,309,gu2raf,datascience,96,"I'm 5 years into my data science career and at my third job and I just find it incredibly boring and tedious and am thinking of leaving the field and moving into a software engineering role just to do something new.  I found it interesting in the beginning when I was learning new things but now it just seems like pretty much 95% of all data science work falls into moving data around, cleaning data, build a model by calling some outside machine learning library, or trying to explain things to business people.  I imagine there are some data science jobs out there where the work is interesting but they seem incredibly rare.  Have I just gotten unlucky in the jobs I've had or do other people who have been in the field for a while feel the same way as me?"
What are good resources to learn about AWS project scoping and management?,3,gu1jdh,datascience,0,"There are a huge number of options and architectures available for AWS. Although the individual instance types and services are described well by the AWS informational resources, I'm having a hard time finding good resources on how to actually combine them to build a reliable and cost-effective infrastructure for a given project. Are there any good resources for learning about AWS project scoping and project management?"
Who are you?,3,gu1iqk,datascience,8,"I'm really interested in getting an idea of who is a part of this community and where they are right now.

[View Poll](https://www.reddit.com/poll/gu1iqk)"
What do you look for/wish to see in a public data set?,1,gu0wp1,datascience,0,"I'm putting together a data set of \~100k randomly played games of a two-player board game. The games are stored as JSON files with each board state and the turns that were made throughout, as well as which player won the game. 

So far I've split the files in to two folders (one for wins by the first player, other folder for wins by the second player), and written a [README.md](https://README.md) describing the structure of the JSON files and info on how the games were generated.

What are some things you would wish to see included in a data set like this that I might be overlooking?"
What Stats/IT journals or magazines do you regularly read?,2,gu090a,datascience,5,"Full disclosure: I used to like Medium, but nowadays I think not all of their content is necessarily very high quality (or maybe it's just me who matured in the past two years). I'd love to find something similar like Nature is in the natural sciences, although I realize DS is probably too small of a field at the moment to produce a comparably popular *and* high quality journal."
Any data science centered Slack workspaces in English you recommend?,0,gtzaeo,datascience,0,
How DS has helped you with your career?,1,gtye56,datascience,0,"This is more to the folks that are not necessarily in a DS role, but do DS in their day-to-day tasks; care to share experiences, stories or even anecdotes seeing how DS helped you with your career?

For me, I was interested in Game theory (and wanted to be a bit more ""politically"" involved in the company that I was working with e.g. showing my ability to be more precise in my articulation, and get upper management approvals); I developed a somewhat simple descriptive model, a small dashboard and analytics during a critical phase of the company and did a presentation; to this day I was known to be ""unique"" in my abilities to articulate facts, which got the attention of my higher ups!

How about you guys?"
Weekly Entering & Transitioning Thread | 31 May 2020 - 07 Jun 2020,9,gtxvnc,datascience,123,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
I got the chance to interview a Data Scientist at Uber on their Shared Rides Team!,436,gtv2c9,datascience,40,"Hey guys -

Had the opportunity to interview a Data Scientist at Uber on their Shared Rides Team. Thought I'd share some of it here, in case you find it helpful :)

**What do you do & where do you work?**

My name is Divyansh Agarwal and I am a data scientist at Uber in San Francisco. I’m working on  the Shared Rides business, and work on building products that grow the business. Some of my work also involves optimizing the efficiency of Uber’s ride sharing marketplace by improving graph optimization algorithms for rider-driver matching, and evaluating their performance via experimentation and simulations.

**When did you first become interested in Data Science?**

So, I had an interest in machine learning and predictive analytics before going into university. I wrote about it in my college essays as well.

But I was also interested in software engineering and fields like security. What really made me truly interested in data science was taking [Data 8](http://data8.org/) at UC Berkeley. I really liked the fact that you could use statistics to extract insights from data and provide value - and although I had always been aware of this, I only realized then how powerful statistics could be and how computing facilitates all of this.

After that, I started doing a bunch of projects, some internships, and got involved in research.

**When applying for jobs, was it hard to choose between going for a software engineering role as opposed to a data science role?**

Not really - I was always set on data science once I got into it. I used software engineering more as a backup, because given my CS background it would have been easy to get a software job if I just prepped hard for their interviews.

It’s actually harder to get a data science job out of undergrad. This is because there’s a general bias towards people with graduate degrees and people with a lot of experience. So you need to have either of both - either you need to have a lot of work experience, or you need to have a PHD.

So that’s why I built experience through doing projects, research, internships, etc.

For Data Science, there’s no real standardized process when it comes to interviewing - it varies a lot from company to company (this is in contrast to software engineering where using websites like LeetCode can get you ready for almost all jobs).

So I had to spend a lot of time prepping for each specific company I interviewed with - at every stage of the process - and this ended up taking a lot of time.

**When applying to Uber, did you have projects in mind you wanted to work on? How much did you know about the company?**

After my sophomore year of college, I was invited for this intern open house at Uber. That’s when I met some of the team across rides, security, and eats. I spoke to this guy on the marketplace team and another guy on the maps team, I was really interested in those teams.

What’s really cool about the marketplace team specifically is that it’s at the intersection of computer science, economics, optimization, statistics, and there’s a lot of hard & interesting problems that can be solved from an algorithmic perspective.

So after this event I attended, I knew that I wanted to be on the marketplace team at Uber. So during my senior year recruiting, I reached out to someone on the marketplace team, and they were interested in me, so that’s how I started interviewing at Uber.

**What is your team responsible for and why is this work critical to Uber’s business?**

I’m on the Shared Rides team (which is a part of Marketplace Dynamics). The core of building new shared rides products and features come from [matching improvements](https://marketplace.uber.com/matching) or UI and experience improvements. So either tweaking these algorithms, designing & analyzing experiments, understanding how users are responding to new product features - these are all very important and central to Uber’s business.

What are some challenges (both technical and non-technical) your team faces?

The biggest challenge for our team (and I think this is true for any consumer internet product) is building something that people actually like that meets your business objectives. Because everytime you change something with the product, one metric might become worse and the other might become better.

It’s also really hard to figure out what users really want and what they really like. This involves a lot of UX research, as well as experimentation. This stuff is really challenging. Here’s another example:

So, there’s an optimization & efficiency side of Shared Rides - there’s always a tension between the two. If I make something more optimal, it might hurt the experience. If I make the experience better, we have to give some leeway on the optimization side of things. So that’s this underlying technical tension that’s always there.

On the product side, as I had already mentioned, it just comes down to building something users really want. So we have designers and UX researchers who are embedded within shared rides, as well as marketing folks, and I have to work cross functionally with these guys to problem solve on a daily basis.

**You interned at Quora before Uber - can you tell me differences between both companies and how that affected your work?**

So Quora was a very small company - there were only 230 people or so when I was working there (two years ago). There were fewer layers of management, it was easier to know people across the company - for example I even got the chance to speak with the CEO on a couple of occasions. There was also less bureaucracy I guess.

At Uber, since it’s a bigger company, sometimes if you want to build something you might need to get buy-in from another team, there’s more bureaucracy, there’s more layers between you and executive management.

Like at Quora, I knew the Head of Data Science very well, but at Uber I can’t imagine doing that currently (given I’ve just begun my career).

At a bigger company like Uber though, you’re working on projects that have bigger scope, bigger impact on the world, and you work with a lot more people. I’m also more specialized within my role here at Uber - at Quora I could have had more flexibility in terms of what I wanted to work on. At Uber, I’m on a very specific team, in a very specific role, working on a very specific part of the product. This has significant advantages: We’re working on specialized problems that are really challenging, and I’m surrounded by people who have been thinking deeply about these problems for a while are are super passionate about these problems. There’s some incredible learning to be had there.

Finally, in a smaller company it’s also a lot easier to hang out with your teammates - Quora for instance had organized clubs (poker, badminton etc) across the board that made it really easy to meet people in different teams. At Uber, that’s much harder to do, but you meet an equivalent amount of people within your own team, since teams are much larger at Uber.

**What advice would you give to someone looking to become a Data Scientist (either a career changer or a college student)?**

Data science roles are defined very differently based on the team, company, size, role you’re working on. For instance, even Uber Data Science can vary greatly across teams - for example, I work on the Shared Rides / Matching team, which is mostly Operations Research, which is a field about optimization. And I didn’t even study Operations Research in college. The important thing to understand is that different teams have different scopes. For instance, the pricing team does a lot of machine learning. Some other teams are trying to understand user experience. So having a strong base is really important, because at companies like Uber, there’s many directions you could go in.

In the Data Science industry overall, there’s broadly three tracks:

1. Algorithms (building models, doing ML)
2. Inference (understanding causality)
3. Analytics (building dashboards, writing SQL, reporting metrics, analyzing simple A/Bs)

Most of the Data Science jobs involve Analytics or Inference.

At Quora, they were mostly on the inference side of things. They were trying to understand product opportunities, trends in user behavior, and see if new product features were impactful.

On Uber, on my team at least, I’m more focused on building algorithms.

So in terms of advice: you need to focus on what you’re actually interested in (within the domains listed above). Of course, there’s going to be work that’s a mix of both, but knowing which topics interest you will help you map out and identify which companies you want to work for.

Everything is going to be very team and company specific, so don’t look at titles, but actually look at what the role is, talk to people on the team, and do your research.

Stats theory is also important, but on the job you’re not really going to be actively using theory too much. What really matters is understanding and gaining intuition. For example, I didn’t study a lot of Operations Research in college, but I took a bunch of Machine Learning and Algorithms classes in college which helped me build intuition for how Operations Research works, since the field is about optimization - which is what Machine Learning and Algorithms are about.

The purpose of theory is to build intuition and understand things.

**Hope you guys liked the interview! If you did, feel free to check out more interviews at** [CareerFair](https://www.careerfair.io/reviews/datascientist).

I'm planning on interviewing more data scientists across a wide range of companies - let me know if you have any specific questions you'd like me to ask them :)"
Themes/Templates for plotly dash,2,gttm8e,datascience,1,I have to build a dashboard for one of my work projects. I have choosen dash as my choice. I was wondering if there are any themes/templates that I can use as the base and build on top of it. THe main reason is that I am not that good with CSS and this can help me design something that has good look and feel.
Industry working professionals: What do you use to maintain different versions of models ?,8,gtt0sq,datascience,9,"I am working on a certain prediction based project. I now have 3-4 models and around 2-3 varients of each models (different hyperparameters, minor changes in architecture etc). Currently I am making a seperate folder for each model, sub folder for each of it's variant and maintaining a report (basically a summary table) of accuracy of models and other meta details. I realised that this approach is not scalable. What system/approach do you use to tackle this and reduce your stress in maintaining model versions ?"
Future of Data science?,2,gtrro4,datascience,11,"I've been reading about what the future will hold for Data science, and some of the stuff is bleak. I keep hearing that AI will replace the need for real data science work and that data engineers are more important. I wanted to see what you guys think."
Clustering analysis for curves?,3,gtqxbu,datascience,14,Working on a project where I'm doing some curve fitting. Wondering if there's an easy way to group many separate results based on similarity? Either on a visual plotting of the curves themselves or on the underlying values (list of 100 numbers). Working in python but also know R if that's a better fit for this task.
EDA revisited,1,gtjczf,datascience,4,"As we know, EDA (Exploratory Data Analysis) is a very common procedure in the field. We use it mainly to find inconsistencies in the data, to uncover simple patterns that could alter our perceptions of what we are dealing with and to build insightful visualizations. I think we can all agree how this type of information can be critical. What I would like to do here, and I hope you bear with me, is to question what seems to me a overly optimistic application of this technique.

So, a little context. I've been working on a small consultant startup that leverage data science techniques to serve our costumers. As you can probably guess, most of our services involve helping our clients make sense of their data and extract useful information that can maximize their profits. 

In the project I'm in, for 3 months we have been doing EDA and communicating our results through Power Point presentations. Although sometimes we could find something that was potentially interesting, this experience left me questioning the value of EDA when applied in isolation. 

To explicit my argument, let's go through an example: suppose I have a database with 20 variables and my goal is to find ""something interesting"". What we usually do is trying to find correlations between these variables (be it in form of graphs of statistical tests). Suppose that I find a positive correlation between X and Y, though. What is this really saying to me? How is this accounting for confounding variables and how much variance is it capturing? My bosses don't seem to me very concerned with these questions and usually think the finding of a correlation is already an insightful thing to communicate. 

I have been trying to argument with them that no analysis could be detached from previsibility. If this variable is correlated with the outcome, but it isn't helping to predict it, then why are we so focused on it? My concerns are usually met with the same answers: ""it is important to visualize what is happening"", ""we are still exploring our data"". 

This makes me think that my approach (predictability in the first place) is kind of unusual in the field? It appears to me that EDA has became a branch of data science that is not connecting very well with everything and is becoming embedded in some other kind of rules? 

I would love to hear your opinions about it."
Interview at Amazon for Data Scientist Role -- how to prepare?,278,gthgfw,datascience,120,"I am currently a Lead Data Scientist at a large defense contractor, primarily applying data science solutions to business-facing homerooms. Think supply chain, business management, etc. 

A few highlights about me...

* Very strong SQL skills, and I have done a large amount of data ETL
* Moderately strong Python skills
* Top 1% on Stack Overflow (I answer a lot of SQL and Python questions, also ask some)
* Nearly 10 internal Trade Secrets awarded to products I have built
* B.S. in Information Technology, I am graduating in August with my M.S. in Computer Science w/ an AI concentration from Hopkins
* About 3.5 years of work experience out of undergrad, two internships at Defense contractors before that
* Also have security related certifications (Security+)
* I mentor both the cybersecurity and AI clubs for my high school (along with a few other alumni)

I was contacted on LinkedIn by a recruiter. I have never really had an intention of working at FAANG organizations. From what I have read both on Reddit and elsewhere, the ""work 7 days a week"" and high pressure culture doesn't fit what I am really looking for. However, the recruiter mentioned almost 60% more than I make now, so that was enticing.

I feel technically sound -- but I definitely don't know how succinctly I could give an answer to some technical questions. I've looked at:

 [https://towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9](https://towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9) 

 [https://towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6](https://towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6) 

 [https://www.reddit.com/r/datascience/comments/dn5uxq/amazon\_data\_scienceml\_interview\_questions/](https://www.reddit.com/r/datascience/comments/dn5uxq/amazon_data_scienceml_interview_questions/) 

Are these good resources? Should I be prepared to write an algorithm from scratch? Would it be easier things, like kmeans, or am I expected to code backprop from scratch? I've done these things from scratch before, but I used reference material... I am nervous about not being able to demonstrate my skills because of being too focused on providing these overly technical answers.

Any advice is appreciated!

Edit: Wow! This blew up. I certainly was not expecting this much feedback, and certainly not so much kindness. As a somewhat new graduate ( < 5 years) who is still figuring out their own self confidence, getting to share a little bit of my background and my fears moving forward with you all has been cathartic, not to mention the sheer volume of incredibly useful feedback I have gotten. I am going to think some thing through tomorrow, and I'll be sure to update this post. If I go along with the interview, which I think i will based on this feedback, ill be sure to create an update post to let you all know what happened!"
How do you answer behavioral based tech questions if you work in a calm job environment?,7,gtgcj4,datascience,14,"I feel my situation is a little unique. Work as the only data scientist for my company and pretty much any recommendation I put forward goes through without any push back from management. There are no conflicts etc as I'm the only data scientist and my manager is really chill so no tight deadlines and issues with management either.

My issue is that now that I'm looking to move to another company, the interviews require you to answer behavioral questions but with a technical aspect to it. I just don't know how to answer conflict or deadline or last minute change questions in a technical manner because I've never faced such situations at my current job. I don't know if i would be answering incorrectly in an over simplistic manner would be too simple of an example for the tech recruiter.

At this point i sort of have to come up with fake scenarios around my work to make it seem like there were conflicts and tight deadlines

Does anyone have any suggestions on how to frame my answers or create such scenarios that seem behavioral based but also technically challenging. Like what exactly do I talk about.. pvalues?? Feature selection?"
Data management books for data scientists?,150,gtbase,datascience,18,"Interested in learning more about the whole data ecosystem and wondering if anyone has book recommendations on: data warehousing, data engineering & data management."
Anyone use their home rigs for work?,1,gt8yac,datascience,4,"Just built a PC that blows my work computer out of the water in terms of computing power and speed, and it got me thinking about how much more productive I could be if I was able to run some of my heavier scripts/tools from work on it. My company has pretty tight InfoSec, but I do have a soft token for VPN on my personal phone, so I do know they do allow personal devices to be used in that capacity. 

I'm curious if anyone out there has done something like this before? Or maybe the takeaway is I should just request a more powerful work computer.

Thanks!"
K-Means vs vector quantization,5,gt7wv3,datascience,2,"Howdy,

So, everyone knows about K-Means as a form of general clustering algorithm. Vector quantization is similarly centroid based, but rather uses a feed forward network to generate that Veroni styled segregation pattern via a (for lack of a better phrase) loser takes all output.

Is there any significant difference in these two algorithms? They seem like they would both have similar results; they both use random starting states, and rely on small adjustments potentially locking them in local minima. It seems like the only real difference is that k means is simpler, more efficient, and more direct."
How fast paced is data science work?,111,gt3j7l,datascience,39,"Doing a data science boot camp thing rn ( before graduate school) and I’m finding the pace a bit fast. Kinda normal for a boot camp to be fast paced but it makes me wonder if  the actual work actually go at this pace. I like having room to breathe and lots and lots of time to really mull over a difficult problem, like an academic might have. I always enjoyed that aspect of university. Does your  average data scientist get that kinda time to devote to just thinking."
Worst example of data stupidity you have seen?,103,gsqs45,datascience,78,"**It's Friday, lets vent!**

Will share my story but heavily changed to protect the guilty.  

I work(ed) in a safety field where people die based on decisions. We risk rate things, and use our limited resources to prioritise what we need to fix. For arguments sake, I have put this in the context of safety of vehicles.

Someone in another department came up with a subjective but otherwise understandable way of risk rating. Things  like 

* if there are seatbelts, subtract 1
* add the number of accidents in the last year
* if there is speed monitoring, subtract 1
* if no licence is required, add 2
* subtract 1 for every time they have been inspected  


As you can see, some of these were real numbers, some ordinal, some categorical and so on.

These numbers are added to give a final ""risk"" score for a vehicle. So far, so dodgy.

However, this total ""number"" was then ranked, and then multiplied by the number of passengers to give an overall value, which was then multiplied by the amount of safety dollars we had to spend to work out what we should do.

Needless to say, my mood quickly went from appalled to ""holy shit we need to never let anyone outside the organisation see how we do this..."""
"Just sitting around, waiting for my data to load...",0,gsnbun,datascience,6,What’s your favorite ETL tool?
Well today was a depressing day for data science at work. What can I do better?,380,gsn5lz,datascience,269,"I work as an Analytics Manager and normally I don't really share with my colleagues the in depth details of my work because nobody is technical. They just know I use SQL and Python to spit out a report and that's all they really understand.

Recently I had an opportunity to do something interesting where I had a very skewed data set and was asked to make sense of it. I thought applying a log transformation to normalize the data as the distribution was extremely skewed and thought it would make the data easier to interpret and I was happy with the results.

My colleagues wanted to know how I arrived at my conclusion for my recommendation so I walked them through the process. I provided a high level overview, but they really wanted to get into the nitty gritty of exactly HOW I got to where I got. Again, I normally don't like to do this because they tend ask very detailed questions like ""Can you explain exactly how this works so I can understand?"" and it gets tough to explain certain things (e.g., I would say something like ""I got this raw data from the API"" but then it's followed up by a question like ""What is an API and why didn't you just use the vendor's dashboard? Why doesn't the vendor's interface provide the data? Why do you have to go through this step?"").

Well anyway I was explaining my logic and really tip toed around the stats by really trying to say essentially that I applied some logic that would more even distribute the data. I stupidly said the word ""log"" and it was over. Their faces froze for a good 10 seconds before someone spoke.

""I'm sorry..but what? What is log? Why do you need this log? I'm really confused. How am I suppose to explain this to the SVP? Can you just change it so you're indexing off the median or mean? This doesn't make any sense.""

I'm dead.

So guys, how do you avoid getting away with having to explain things by  not using technical jargon? I mean like I said, I normally just show people the output of my report and I don't get too many in depth questions about it, but when people really pry, it gets tough. I don't know how to avoid saying ""I ran a regression model"" because it freaks people out and they get upset because they don't understand it and want me to do something that is easier to interpret. It's already frustrating that they think I'm over complicating things by using Python instead of Excel, but I can at least tell them certain things like Excel can't handle 1+ million rows and they can understand that.

EDIT: Hey all, appreciate all you feedback, both positive and negative. I think it's all constructive. There's a lot of replies in this thread so it's hard to answer everyone's questions. Some of you ask the same things and I do answer them, but you might have to dig through the comments to find it. In any case, let me post some frequently asked ones:

1) Did you use graphs and visuals?

Answer: I did. I actually stayed away from using the word log at first and just showed them a histogram of what the data looked like before the log transform and then after the log transform. What followed up was ""How did you do this? What did you use to index the numbers?"" And that's when I mentioned I used a log transformation.

2) How did you explain what a log transform was?

Answer: I didn't directly explain it in math terms. I described it in the form of an analogy or comparable example. This is what I said: 

""Imagine we were looking at salaries for a company. Most people for example will make a salary between something like $40 - 100k right? Well what if the top execs in the company make like $10 million dollars. Now imagine you tried to index using the mean? Wouldn't the mean say the average employee at this company makes a salary of $1 million dollars or something? That's not right. Basically, a log transformation would keep everyone's differences in consideration, but minimize the importance of some of those execs who are not entirely representative of the rest of the company. That way you can better see the difference in salary among every worker and not have your vision obscured by some of these execs who are throwing off that balance. ""

Unfortunately, this proved to be even more confusing and my colleagues really zoned in on exactly what a log was and how it's calculated and it was tough to navigate from there.

3) What is SVP?

Answer: It stands for Senior Vice President. It basically is a reference to our execs."
How easy or hard is to deploy Dash dashboard on a custom server?,6,gsgtzn,datascience,6,"I am exploring Dash at the moment a and finding it very interesting.

My question is: How easy or hard is to deploy Dash on custom Linux server?"
Convention on Multiple Imputation for ML models?,6,gsgcup,datascience,6,"Hi guys, I'm trying to build a binary outcome classifier for a dataset and I'm kind of stumped by a particular feature in the data which have \~20% of its values missing in both the training and testing sets. This feature has about a r=0.077 correlation with the outcome (measured from observed data in the training set).

I'm looking to do Multiple Imputation on the missing values and I gather that I basically need to do the following:

1. Choose a single imputation method with a random component (regression with random error term, regression with bootstrap samples, etc.), impute missing values x times to get x separate datasets
2. Do my analysis (build an ML model) x times to get x different sets of results (model parameters)
3. Average the results to get 1 set of model parameters

I was wondering if it would be okay if I just did step 1 and averaged the missing values into 1 complete dataset? I ask because this seems like it may not be worth the hassle for something with only a r=0.077 with the outcome, and coupled with missing values in other features I would end up with a lot of models if I chose this approach. Is there a better way to do this? Also how would this approach work from a testing point of view? Would I just impute multiple testing sets and take a majority vote of the predictions?"
Data scientist going back to school for CS,47,gsg5eh,datascience,23,"I have been a data scientist / data engineer for about 2 years with only a BA in Economics. I have always wanted to learn more on the CS side and recently decided to take night classes at the local community college. I start my first class (Programming fundamentals I) which will be taught using C++. I am pretty proficient in R and Python for modeling and ETL, but I don't have any experience with lower level languages. 

I'm super excited, and I want to know if anyone has any advice about what to focus on in my class? 

Will C++ be useful as a data scientist/engineer?

I plan on taking Programmin fundamentals II and III next. They are offered in C++ or Java. Should I pick one over the other?

My ultimate goal is to get into Georgia Tech's OMSCS program while at the same time learning valuable skills for my job"
Mulesoft vs rhapsody,1,gsd55l,datascience,1,"Hi!
I’m on a project team, aimed at determining best integration and API platforms. We’ve spoken a lot about DataStage (internally), but less about Rhapsody and mulesoft. 

Can anyone share a brief pro/con of the two? Or maybe when you would choose one over the other (other than cost and worker capacity)?"
[D] What is the tool stack of ML teams at startups? + intel from 41 companies,104,gsbtwn,datascience,12,
Python library to make data visualization less autistic,0,gs4irw,datascience,15,"I've used matlab but now I mainly use python 3. Matlabs plotting is complete utter garbage and I will never understand the logic behind it, I hate it with all my heart. Matplotlib in python 3 is a little bit better, but it still seems unnecessarily confusing, despite changing tick label sizes hundreds of times I always have to google it.

Is there a simple python library that can handle all the common charts patterns, outputting them aesthetically with selectable color schemes and font sizes that are fucking readable by default?"
Deploy Machine Learning Pipeline on Google Kubernetes Engine,2,gryp8p,datascience,1," Are you a data scientist and you haven't deployed machine learning model yet  .... then this one is for you ☟  

Our latest medium post is a step-by-step beginner’s guide to containerize and deploy machine learning pipeline on Google Kubernetes Engine.  

If you have never heard about containerization, docker and Kubernetes before, no problem - this is what this tutorial is all about. In this tutorial you will learn:  

✔ What is a Container, What is Docker, What is Kubernetes, and What is Google Kubernetes Engine? 

✔ Build a Docker image and upload it on Google Container Registry (GCR). 

✔ Create clusters and deploy a machine learning pipeline with Flask app as a web service. 

✔ See a web app in action that uses a trained machine learning pipeline to predict on new data points in real-time. 

[https://medium.com/@moez\_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b](https://medium.com/@moez_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b)"
How do you keep your useful / reusable codes?,2,gryhrf,datascience,4,"I am creating a ""tool box"" that is pretty much a big google colab file with useful codes, this way my basic projects would be more modulated and easily implanted, but not sure if i am doing it the best way, so thought you guys may be doing something like this."
Have you found PLS regression useful?,1,grxxp1,datascience,7,"Conceptually, it seems to me that partial least squares regression should be excellent in some situations. However, ISLR states ""...it often performs no better than ridge regression or PCR (principle component regression)"" and that ""...the overall benefit of PLS relative to PCR is a wash"". Applied Predictive Modelling, on the other hand, describes PLS in a much more positive light. I was hoping someone might be able to speak from experience as to whether they have found PLS to significantly outperform other methods or not."
"I know it’s a weird question but, What do you think it would be like to be a data scientist at pornhub?",404,grvwzg,datascience,168,"I’ve seen some of the visualizations showing different viewing patterns by state and it makes me wonder
- What’s working there like
- How’s the pay (I could see it either being really good or really bad
- how rich is their dataset

As one of the most viewed sites on the internet they must have some data science types working there"
How to deal with images with text noise?,2,grttya,datascience,1,"I have a dataset of images collected from google and bing images (scraped). basically I want to classify these images into binary classes (positive, negative). Images that contain a text originally from the image (a photo of contract) should be classified positive (there are some other cases where the image also should be positive but my problem is with the textual images). I'm facing a problem that many negative images have text and caption that's add on the photo like a website address or logo (not original from the image). I'm afraid these images could hurt the model performance, in this case, what should I do? It doesn't make sense to through away useful images because of tiny text added on them. And could that actually hurt the model or the model would be able to capture the actual pattern from the dataset?

Thanks"
Masters Degree or Old Stressful Job,34,grq9ik,datascience,53,"Hello all, I got laid off from a Data Quality Assurance job due to covid at the beginning of April, and I was accepted into an applied data science masters program at USC (University of Southern California) during this time off. The pay was good at the job, but I was extremely stressed out and didn’t receive overtime on days I would work extra. I was only there for 3 months, and now they’re asking me to come back. Do you think I should pursue a masters (2 year program) at $70K tuition or accept the offer again which pays 75k?

Background: I graduated in January of 2019 and have about 1.5 years of data ANALYST experience under my belt so far.

Thanks in advance!

Edit: I should also note that this is without FAFSA considered as I haven’t received notice yet. 
I have experience in Power BI, SQL, Python, and Excel which are all fine for data analyst roles, but my question would be is experience enough to get me from an analyst position to a scientist position?
The USC program focuses on Machine Learning and Webscraping, as well as Hadoop/MapReduce/Spark. 
I have a bachelors in Business Analytics if that matters.
Appreciate the input from everyone so far as well"
Cookiecutter projects,6,grp93m,datascience,6,"I am trying to develop my first DS project using cookiecutter but I am having hard time understanding its bits and pieces.

If anyone knows or have developed any actual DS projects developed using it or any other template, please share links. it will be easier to understand the whole process. Thank you"
Alternative approaches to ARIMA for Time Series prediction (No Neural Networks),31,gro5w8,datascience,28,"Hi everyone,

I have data on three years of weekly sales for a market, plus some information about brands, promos etc . Researching about Time Series analysis, I came about ARIMA and SAIRMA models, which seems to be the standard approach for this type of data analysis and forecast.

I was wondering, is it ARIMA also the only or best option? Is it possible to use also some other algorithms that may turn out to be more effective? If so, what would you suggest?

Thank you"
Cloud permissions for Data Scientists - anyone happy with their company's setup?,81,grmbms,datascience,48,"A recurring issue I've had to deal with in my career has been IT governance and the ability of myself (or my teams) to be able to use or test out cloud functionality independently (i.e., not needing IT to set everything up for my first).

For those in companies with tight permission policies:

1. How is your access to cloud resources set up?
   1. Are you able to spin up compute resources by yourself (e.g., EC2)?
   2. Are you able to connect these compute resources to production DBs, or are you only able to create these in dev environments/connect to test/backup DBs?
2. Are you happy with it?

EDIT for clarification:

* I am not advocating against IT governance - I think it certainly has a purpose and just giving users ""God privileges"" as u/lacompacida so eloquently referred to is not the answer. What I am interested in is how others (companies) are managing the tradeoff between cybersecurity risks and data scientist's autonomy.
* For example, I think u/SlightBerry brings up what seems like a valid stance - users should be able to deploy resources as needed, and security should be handled not by overseeing what users are spinning up, but by making sure that whatever they spin up is isolated enough not to generate issues. I certainly have questions regarding that setup, but clearly there is a balance between giving any joe shmoe complete access to prod vs. requiring even your most senior DS to open a ticket to get a compute instance stood up."
How do you approach game balancing as a data scientist?,6,grgc0e,datascience,5,"Data scientists who play competitive video games(e.g. moba, autochess, hearthstone), how would you model the problem of game balancing? Most stat websites(hsreplay.net, op.gg, etc) focus on winrates only. How do you quantify ideas like strategy diversity, comeback potential, interactivity/counterplay, skill cap/floor, learning curve, etc?"
How deep is your statistics knowledge?,269,gr8jz1,datascience,121,"I work a lot with ""heavy"" statisticians (mostly bio-statisticians). They typically get involve after we do all the data engineering and NLP part. Their knowledge of stats of course overshadows that of my team, which brings me to the question - what is the value of a data scientist without such knowledge?

It's true that we do all the heavy work, but the statisticians are the ones making the calls about the study design, scrutinize the results etc. 

It makes my teammate feel like low-skilled workers in the whole process, and they fear that they will be easily replaceable. 

What do you think?"
Looking for a graph algorithm (with possible implementation) for social network,0,gr77qh,datascience,6,"I'm looking for a graph algorithm with a ""know each other"" functionality. A general input will be total number of people (50-100) and a closeness rating of 1 to 4 associated. So for example, person A knows person B and their closeness rating is 1 (meaning they are unfamiliar to each other). Person A knows C (with a closeness rating of 4 - familiar) and B knows C (with a closeness rating of 4 - familiar). Therefore, A and B are unfamiliar, but C is their mutual friend."
Is it possible to predict a specific date for a customer's next transaction (with some margin of error) ?,4,gqshph,datascience,13,"I have a dataset of bill payment transactions of our customers with a period of over 1 year and some features like paid amount, transaction date, bill type (power, internet, etc.). At first, I was able to build a classification model from this data to classify whether a customer has a bill payment transaction in the next  7 days (\*), but now my boss wants to go a step further: Could you predict a specific date per customer with a reliable margin of error? (\*\*) I'm not sure how one would reformulate and approach this 'new' problem, and how one would backtest/validate the model (what would be the metrics, etc.). Any pointers or ideas would be appreciated.

Edit: I did do some feature engineering in order to fit a gradient boosting into the data for (\*) and came up with some aggregated features (per customer) including:

\- recency 

\- frequency

\- customer age (time from first transaction to the end of the studied period)

\- statistics of the bill amount (mean, median, kurtosis, min, max, etc.)

\- statistics of the day difference between bill payments

\- Mode of bill types

\- Counts of each bill type, normalised

One thing that confuses me a bit: There are some customers with zero day differences, meaning they paid 2 or more bills in 1 day. I don't know if it will affect the model for (\*), and potentially (\*\*). Should those cases be counted as 1 'compound' bill payment?"
Best Online Accredited Course You've Taken?,0,gqodbt,datascience,2,"I have $8k of company cash every year to spend on accredited courses (aka no coursera/Edx).

What are some good courses you've taken?"
XKCD : Confidence Interval,595,gqns9k,datascience,26,
Does anyone else not like R until they actually use it?,5,gqj6f8,datascience,45,"I have always been in this ambivalence phase with R software: I like what it can do, but I hate R. 

Is it just me?"
Seeking Advice: Building a PC For Data Science Work,16,gqhzwk,datascience,20,"I'm curious if anyone here has any experience building a PC for work? I've been reading online and some say to have a lot of PCIe lanes while others say it's not important. Same thing regarding dual GPUs, getting a threadripper CPU, and more.

I primarily do cluster analysis, random forests, and regression, but I want to expand my skills in deep learning. I have been working on an RNN for the past 6 months and plan on trying my hand at computer vision. I'm still just learning and working with relatively small datasets, so I don't need a crazy powerful machine."
Strategies for processing .csv files over 1 million rows long (~200 MB .csv files),146,gqgpwo,datascience,133,"At my job, I am juggling keeping our development pace going for the project I'm assigned to while making improvements to our workflow.

I figured out that you can dump a .csv file of a waveform from an [oscilloscope](https://en.wikipedia.org/wiki/Oscilloscope), and it is over a million rows. Python is too slow, because I only have access to a dual core 4 GB machine (I am thinking about writing a persuasive letter about getting a cheap 16 GB ram machine with secure, local-only remote access for the entire engineering team, probably either a quad core Intel or Ryzen 3600) so I was wondering what would be best:

*Learn some [R lang](https://www.r-project.org/) basics? C++ was the first thing that came to mind because I figured I could just declare 300-400 MB of memory, placing the whole .csv file in 200 and the rest of the program in 100-200? [This is the second link that comes up for me when I google ""C++ .csv"".](https://www.gormanalysis.com/blog/reading-and-writing-csv-files-with-cpp/) Admittedly, he has a point. I am about using the right tool for a job.

*Learn [Postgres](https://www.postgresqltutorial.com/import-csv-file-into-posgresql-table/)? I like the idea of having an excuse to put a database on my resume and then interfacing it with my tried-and-true Python or C++. 

*Go with my first instinct and [do it in C++ anyways](https://github.com/ben-strasser/fast-cpp-csv-parser)? I already use python at work and I'm wondering if a tool featuring a C++ parser as the back-end and something like [pysimplegui](https://pysimplegui.readthedocs.io/en/latest/) as the front end could be a game-changer at my job."
"Remember that humans pour energy into the tools we use - Michael Waskom: ""I had been planning on working this afternoon to implement a new feature I am excited about. Then a data science influencer tweeted about how seaborn sucks...""",279,gpwpgw,datascience,88,
Anyone working on Sports Analytics?,261,gpvq28,datascience,74,"I have interested in sports analytics since a few years ago, but now I want to start learning it. That is why I ask you for advice on how to start with sports analytics (readings, courses, public datasets) and any career advice you can provide. Also, for those who are working on it, could you please tell me how did you start on this and what are the tasks you developed in a daily basis regarding SA."
Episode #262 Build a career in data science,3,gpvdy2,datascience,4,
Any ideas how I could find freelancing data science clients outside freelancing platforms?,32,gppx26,datascience,29,"Really don't want to be bound to freelancing platforms such as Upwork/Freelancer.com but still want to find project opportunities in data science, any ideas how?"
Weekly Entering & Transitioning Thread | 24 May 2020 - 31 May 2020,13,gpojpv,datascience,172,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
How to determine the one optimal decision threshold across multiple predictive models,6,gpibk8,datascience,2," 

I am currently wanting to construct predictive models to identify patients who may have a misdiagnosis of a certain disease. However, the issue is that I have multiple databases and I do not want to combine the data into one set, so I need to create predictive models for each database. On top of that, I wanted to use different model approaches and use the most accurate model.  

I'm currently facing the problem of determining a way to identify the optimal decision threshold to categorize the results of the predictive model as having been misdiagnosed (p=1) or not having been misdiagnosed (p=0). I've read about how we can use Youden's Index to determine the optimal cutoff for a model, but since I'll have multiple models for each of the database, would it make sense to use the SAME cuttoff across all the models and databases or have one for each database (but keep it consistent for each model within the database)? I'm a bit lost on what the best approach is. I haven't been able to find papers that provide detail on how they determine optimal decision thresholds when they have multiple models

P.S. I've read about how you can use the cost of each result (i.e., TP, TN, FP, FN) to determine the threshold, but these values are unknown for my disease of interest. 

Sorry about the long post, and thank you for your help in advance!"
Is it worth investing time learning data science if I only want to freelance part-time?,1,gpbvz0,datascience,10,"I'm not looking to pursue a career in it, at least not for the time being. Yet, as I have time to spare during this lockdown and have a great interest in mathematics, I thought I might as well try to learn it."
Plackett-Luce Latent Variable Modeling issues,2,gpaskw,datascience,2,"So I'm wondering if anyone else has had this issue before. I'm using a Plackett-Luce Latent Variable model to determine rankings based on sets of ranked data. In my dataset, the problem is occasionally the typical top 5 ranked elements (""winners"") could drop to near bottom as some anomaly. In the new updated rankings, the low ranked elements that ""beat"" the winners  immediately skyrocket to the top, even though the drops are clearly anomalies. Does anyone know of strategies to counteract this? Besides just arbitrarily picking this anomalies and excluding them from the rankings, I'm not sure if there's some form of ""smoothing"" I can do to not rapidly adjust the rankings for each set. It seems like just a single anomaly has a massive effect on the rankings, when it probably shouldn't."
What is up with this subreddit. A plea for help,496,gp98rt,datascience,130,"Why are 99% of the posts here about jobs or up-skilling? Please stop

I want something like ycombinator where the latest developments in technology and research are posted. Library updates, hot takes. Where there are discussions about statistics, machine learning, etc. 

I post insights here but I can't do it alone. 

I've reported nearly every post on the front page for: not being in the sticky thread, treating /r/datascience as a homework helper or crowd-sourced google. 

This sub is just overrun by college students."
Which experiment tracking tools do you recommend?,1,gp0jfd,datascience,4,"I’m looking for a tool to keep track of experiments and I’m wondering if anyone has good experience with any tools out there? Ideally I’m looking something that

- uses an api so that I can just log parameters or metrics during my experimental runs
- has a decent UI where I can manually add parameters and add notes on experiments
- provides some simple comparisons between experiments."
Is anyone here into marketing analytics? How did you get into it? What are the skills needed?,123,gp0ctd,datascience,51,"Edit: Thanks to the person who gave this gold but I would much rather prefer that you donate the amount to a cause/charity you support. Thanks!

Edit 2: Thanks to everyone who answered! All the responses were very insightful."
Data Scientists who aren't doing ML: what kind of statistical work do you do?,318,gomivv,datascience,147,I'm curious to hear about data science in a context that's outside of machine learning or predictive algorithms since they are not as talked about. I've heard time-series is pretty popular in finance companies (unsurprisingly) and survival analysis in some insurance companies. I'd love to hear more about how different types of statistics are being used in data science these days!
Tips for presenting a personal project via video conferencing,2,gokeht,datascience,12,"Wondering if anyone who’s had to remotely present a personal project as part of a technical interview would be willing to share:  
1. technologies used for presentation
2. general outline of presentation (slides first, then live demo?)
3. general tips & tricks

The specific video conferencing service is irrelevant. You’re obviously going to be sharing your screen.

EDIT: the interviewers are data scientists themselves and will presumably be fairly familiar with most technical concepts in my project."
"Successful people that studied DS, and now are in leadership",8,gohc84,datascience,10,"I saw a lot of folks that are in top management or leading financial institutions (such as banks) having MBAs, ACCA, and such, and I've always wondered if you've seen top management or successful folks having degrees or postgrads in DS?

I think it will great to see those who have studied the field putting the field into practice, especially in leadership!"
"Please excuse the cliched, Imposter Syndrome post. I still get anxiety when performing basic arithmetic although I can comprehend and explain complex concepts, e.g how a NN works. I feel like there is such a big gap in my math background. Am I alone?",133,godbf1,datascience,54,"I have been practicing with a mental math app however, I still feel anxious dealing with basic operations like multiplying and subtraction. I think I have gotten my self into a negative self fulfilling prophecy. 

Does any one have any suggestions how I can overcome this incompetence/insecurity?

I’m concerned when I get into industry everyone will see me as an outlier."
How important is title?,6,go4arp,datascience,14,"Would you consider it a ""step down"" to go from Data Scientist to Senior Analyst/Product Analyst?"
Interesting article (with a click bait-y name) Don’t Democratize Data Science,112,go2joo,datascience,89,
Deploying machine learning models at scale,20,gnynqo,datascience,14,"I have experience with deploying API end points for internal apps that get maybe a hundred or so requests a day.

How does it differ from a large applications with for example hundreds of thousands a request a day, what do I need to consider?"
Making exploratory Jupyter notebooks more production friendly,9,gnyn98,datascience,16,"Hello,

I've been hearing polarising opinions on using using Jupyter notebooks in production. My read is that people generally agree on notebooks being useful for exploratory analysis, but the path from there to production seems very vague and very different for different workflows.

Here is what I've found quite useful for my team, made of data analysts, data scientists and me as production engineer. We start from notebooks and gradually end up with code in .py files. It usually involves a hybrid setup of Jupyter web UI and VsCode connected remotely to SageMaker machine, opening the same dir notebooks are in.

There is not quantitative data to back it up, but I feel it didn't decrease the iteration speed and it definitely avoids a lot of ""translation"" from what they write into production code.

What are your thoughts on this?

Do you do something similar?

Is your data setup so complex that it's almost impossible to move from notebook to the production code?

How do you iterate on products where the initial exploration is needed?

How do you make sure there is no loss in the ""translation process""?

Lots of questions, I know :)."
Data Science in a Restaurant?,288,gnpe2e,datascience,50,"Hi everyone, 

I work as a cook at a seafood restaurant and feel like this gives me a unique opportunity to collect some data on how much food we cook/waste a day. I would like to complete a project that predicts how much food we will sell at certain times on different days of the week, is this doable? The restaurant throws out a lot of each night, and I feel like completing a project like this could help solve this problem by predicting how much food needs to be cooked within the last hour of being open and it would also look great on a resume. Do you all have any tips on data collection or models to use? Thanks!"
Keeping statistical knowledge fresh?,25,gnlelq,datascience,29,"How do you keep your statistical knowledge fresh and not get rusty?

I haven't come across many jobs in which you need to explain *why* a model does what it does, either because they're happy when it works or they glaze over the moment you mention anything remotely technical. But you're expected to know it all in an interview if you change jobs."
What is the model used in Forward and Backward feature selection?,5,gnhv8i,datascience,5,"I have this doubt regarding feature selection chapter in ISLR. In the forward and backward subset selection procedure, the textbook says ""the best model is selected"". 

So what is the ""model""? Is it a linear regression model? Polynomial regression model? What is the model using which the best subset of features are evaluated?

&#x200B;

PS. Sorry if this is a really dumb question, I am new to Data Science and started off with some online courses reading ISLR."
What are some bad coding practice you've noticed among Data Scientists?,268,gnetpw,datascience,205,
Book or online training about structuring UI/UX for data products?,3,gncbsc,datascience,0,I'm looking to improve my understanding of how to structure the UI/UX for my data products. I too often find myself using just intuition to decide whether to build a report or dashboard and how to structure whatever product I choose. I'm never quite sure how to determine how many visualizations to include in my dashboards or how often to update them. How do good data analysts assess the needs and abilities of their audience? When should you add some flashiness to your products to encourage adoption and when should you stick with something sparse and boring? Is there a good reference or training for these questions?
For my next laptop should i buy a mac or windows for data science and analytics ?,3,gnbsqz,datascience,13,"Do all libraries run on a mac/linux with nvidia graphics card ? 

what laptop do you recommend that would last for years with at least 64gb RAM ? 

Can I run Excel and PowerBi on Linux/Mac OS ? 

Thank you"
"Offer suggestion, data scientist in Amsterdam",12,gn9eu6,datascience,7,"I’m posting this here hoping the Data Scientists working in AMS could help me gauge whether this is a good offer.

I have 2 years experience as a DS leading projects in ML & cloud architecting. I interviewed for a Senior DS role at a listed tech company. They instead offered me a medior DS role: 67k base + 10% bonus + 18k RSU(annually, can vest 25% per year). So in total the package is worth of 78k. The work content will be recommender systems and NLP. The interview went really well and I could tell that they wanted me. I also liked the interviewers who seems open and friendly.

Do you guys think 67k base+10%+18k RSUs is a fair package for a med-DS role in Amsterdam?"
Best ML platforms for a non-technical startup owner,2,gn5ddq,datascience,18,"Hi guys,

Just a quick one. What are the best drag and drop (or other user friendly) ML or Deep Learning platforms available in the market? 

I know of  Data Robot and Dataiku. What is your view of these and are there others? 

For context. I'm a startup owner (no technical data science background) and am looking to quickly create and integrate some predictive models into the platform we are developing. 

First prize would be to develop our own algorithms and analytics platform, but that will take time, so wanted to explore alternatives using existing platforms.

All thoughts and feedback appreciated!"
A foolproof way to shrink deep learning models,226,gn4vkx,datascience,22,
Physical & mood data interpretation,3,gmykak,datascience,9,"I have been collecting data for the past couple of months, that includes my daily mood, activities I performed, physical activity (steps, calories and such) as well as sleep.
I already curated my mood dataset (by that I mean I made it readable and interpretable) and will proceed with the physical one relatively soon. 

I've been struggling to define what kind of insights I want to get out of it, outside of the simple correlation between mood, physical activity and sleep. 
Would anyone with a bit of experience be interested in looking at the data and pointing me in the right direction? Or even working with me on offering a similar service to others if it ends up providing any kind of value?
Let me know and I can share more details!"
Clustering a large dataset in python (sklearn),9,gmx51a,datascience,17,"I'm trying to cluster a rather large data set (~400k samples, somewhere between 20-30 features). The features are mostly continuous, although there are some discrete/categorical variables.

Because of the mixed data types, I'm not sure if k-means is what I want to use. I tried running a DBSCAN but after it was running for what seemed like forever I gave up.

What clustering algorithm is recommended for such a large number of samples? What would give me a reasonable run time, while also dealing with the fact that I don't just have continuous, numerical data?

For an idea of the data I have, it's basically information about customers. I have number of accounts (discrete variable), account status (e.g, Gold, Platinum, etc. this is my cateogorical) and then some other things like age/how long they've been a customer, how much they've spent etc. (continuous variables)."
What are some techniques to improve contextual accuracy of semantic search engine using BERT?,2,gmubil,datascience,5,"I am implementing a semantic search engine using BERT (using cosine distance) To a certain extend the method is able to find out sentences in a high level context. However when it comes narrowed down context of the sentence, it gives several issues.

Example: If my search term is ""Wrong Product"", the search engine might match with sentences like ""I bought a washing machine but it was defective"".

I understand that the fixes to these is always finding some equilibrium and live with minor errors.

However if there are any rules, techniques which has improved your semantic search implementation accuracy please do share."
Get Use Out of Exponential Probability Distribution,7,gmscll,datascience,10,"Hello fellow data people. I was recently working with a dataset I had cleaned up and filtered. Machine learning (Tensorflow, custum, Microsoft Azure), trend functions (linear, exponential, etc.), and a bunch of other forecasting techniques had terrible results (yes, I tried using autoregressive inputs). I then plotted the frequency distribution of the outputs of the dataset, only to find out that it is an exponential probability distribution. Basically, there's 8 billion 0s, 3 billion 1s, 1.5 billion 2s (they're count values). I was wondering what useful forecasting can even be done when a dataset looks like this. Honestly, I can't even imagine any useful summary statistics (like, ""Oh, great! I have a 90% chance of it being less than 2""). This is like the third dataset I've had that looks like this and I'm always lost when I get them (I've done hackathons in the past that have had this same problem). Any help would be appreciated."
"Rules for sharing machine learning content of all kinds or ""What that tool should have done.""",0,gmq9ss,datascience,3,"So there have been a couple of posts about content sharing done wrong:  [https://www.reddit.com/r/datascience/comments/gmirks/my\_apologies\_from\_a\_data\_science\_company\_stole\_my/](https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/) 

See what I did there? I posted a link with a bit of an explanation. That's fine. If you want to know more, you have to go to their content on their site. We all do that in our social media feeds. Putting all their content on my site so readers don't need to go to theirs is theft. It doesn't matter if I put the attribution somewhere with the post. No permission=theft.

When another site wants to repost something I've written, they send me a message and ask for permission. That's been the way it is done for the eight years I have been writing. With a site like KDNuggets, I am always good with giving them the OK and not asking for compensation. Some major outlets will ask me to rebuild a post to appeal to their target audience. They have millions of readers. I do that for free too.

I have worked with consulting companies. They want content to drive people to their site as a form of organic marketing. It's usually pretty fluffy, buzzword bingo type posts. I get paid for that. If someone is advertising their services on the site, they are making money off that site and you should too.

I have worked with companies that make products. They want technical content to explain how to use their product in the real world. Again, they use that content to market their products. I get paid for that and you should too.

In the research world, works are cited. There can be a longer quotation from the original work which will have the primary authors' names next to it. Supporting works without quotes will be linked to at the end of the research paper. That's fine. Copy paste research, paraphrasing, releasing implementations as original works, all of that is plagiarism. That gets you blacklisted.

I have posted content that was very close to someone else's. They posted first. I issued an apology and a link to their content. It happens. The right response is to put your hand up and say, ""I messed up. I must have seen their post and that triggered mine."" No excuses. I felt like garbage for doing it.

Hopefully that helps. If you have any questions about re-purposing content, let me know."
Data scientist offer in Amsterdam,0,gmpbam,datascience,7,"I’m posting this here hoping the Data Scientists working in AMS could help me gauge whether this is a good offer.

I have a CS bachelor and DS master (cum laude for both) with 2 years experience in ML & cloud architecting. I interviewed for a Senior DS role at a tech company. They instead offered me a medior DS role: 65k base + 10% bonus + 18k RSU(annually, can vest 25% per year). I managed to negotiate the base to 67k. So in total the package is worth of 78k. The work content will be recommender systems and NLP. The interview went really well and I could tell that they wanted me. I also liked the interviewers who seems open and friendly.

I initially tried to negotiate a 10% raise on the base which I then lowered to 5% during negotiation (cause they said 10% would lead to a senior role) but eventually they come back with a 3% instead.

Do you guys think this is a fair package for a med-DS role in Amsterdam?"
Do people still post on Medium these days?,0,gmp0mt,datascience,2,"I remember a couple of years ago Medium was filled with articles on data science, but these days I don’t see as many (probably because of the paywall update). Do people still use Medium to publish data science articles? What do you think is a good platform for someone who wants to post?"
"My Apologies - From ""A Data Science company stole my gf's ML project and reposted it as their own. What do I do?""",419,gmirks,datascience,134,"**Dean Hoffman from the thread** ""[A ""Data Science"" company stole my gf's ML project and reposted it as their own. What do I do?](https://www.reddit.com/r/datascience/comments/glfdmm/a_data_science_company_stole_my_gfs_ml_project/)**"" responded. He authorised me to repost his response. Here it is:**

""Under no circumstances should someone claim credit for someone else's work. I was involved in litigation against Google for something similar over 10 years ago.

[https://docs.justia.com/cases/federal/district-courts/california/cacdce/2:2004cv09484/167815/776](https://docs.justia.com/cases/federal/district-courts/california/cacdce/2:2004cv09484/167815/776)

RSS feed readers ingest content and republish it with credit to the author. This step gives the author added exposure, like how radio stations offer musicians free advertising to sell their music.

Examples of news aggregators include Google News, Drudge Report, Huffington Post, Fark, Zero Hedge, Newslookup, Newsvine, World News (WN) Network and Daily Beast, where the aggregation is entirely automatic

I see that the automated algorithm was incorrectly listing the admin as the author on some of the articles, but there was no intent to deceive. If you look, you will see that EVERY ITEM had the ""ORIGINAL SOURCE"" listed at the bottom of EACH ARTICLE, and that linked to the ORIGINAL AUTHOR. One more time: If you look, you will see that EVERY ITEM had the ""ORIGINAL SOURCE"" listed at the bottom of each piece that then linked to the ORIGINAL AUTHOR.

There was no intent to claim ownership. If so, it was a pretty hair-brained try, but I apologize to anyone who feels deserving.

Since I have no financial gain from this site, and no good deed goes unpunished, I decided to take it down. I don't need the aggravation to share useful content and authors if the reward is getting attacked.

I am an awarding winning researcher, as published in at least two national magazines. I don't need anybody else's credibility.

Many articles picked up by the RSS feeds I would be embarrassed to publish under my name.

I am confident that NOBODY, with a clue about data science, thought someone was writing hundreds of articles a week. Especially when posting the ORIGINAL SOURCE, and it links to the ORIGINAL AUTHOR at the bottom of each piece! Seriously!? SERIOUSLY!!!?

I've not made a penny from the site, nor have I ever tried (or wanted to). It was built as a news aggregator to promote the work of others and create a place to stay up to date without navigating to hundreds of sources (yes hundreds). That IS what news aggregators do! I received many thank you notes from authors happy to have extra exposure.

I apologize for my oversite in the way the aggregation algorithm posted. In hindsight, I wish the ""Original Source and Author"" link was on the top rather than the bottom (besides a few other items). I assure you my intent was genuinely excellent; I was trying to give those interested a convenient news aggregation a resource.

I don't create excuses, but please, it is sophomoric to jump from unintentional RSS feed read result to first-degree murder.

Trust me; if anybody worth their weight in Data Science thought you or anybody else got fooled by something so obvious, they would likely think you were in the wrong profession. I asked my 7th-grade daughter to read a few articles and then decipher who the source and author were, and she had NO PROBLEM correctly identifying them (hint, it was not me). I'm pretty sure you can relax.

Again, look at all the ORIGINAL SOURCES and AUTHORS linked to in every case.

I will use the site for personal purposes to save my own time; it got built as my individual RSS reader; I will return it to that.

I apologize to those authors and readers that were happy I had put in the work to create the content aggregation location and add more exposure to others' work. (with zero pay to me)

If you intended to be disruptive, trolling, punitive, and silencing, congratulations, job well done, not worth my time anymore. Honestly, I was getting a little tired of putting in the work anyway. Feel free to navigate the hundreds of sources on your own (yes hundreds); it should only take you 10 or 12 hours a day. Once again, my apologies for my failed try at providing you time-saving value and exposure. Site is down, time-saving, content aggregating, author visibility-enhancing site is no longer available.

Maybe you will enjoy these guys news aggregation: [https://news.google.com/search?q=Artificial%20Intelligence&hl=en-US&gl=US&ceid=US%3Aen](https://news.google.com/search?q=Artificial%20Intelligence&hl=en-US&gl=US&ceid=US%3Aen)"""
Where did the term deep learning come from and how did it get associated with artificial intelligent approaches to machine learning?,26,gm3yh7,datascience,19,"As this NGram link below from google suggests, the recent use of “deep learning” has skyrocketed. Curiously, though, it was used at times well into the past. Anyone aware of how this term got adopted for use in machine learning?

https://books.google.com/ngrams/graph?content=Deep+learning&year_start=1800&year_end=2008&corpus=15&smoothing=3&share=&direct_url=t1%3B%2CDeep%20learning%3B%2Cc0"
"A ""Data Science"" company stole my gf's ML project and reposted it as their own. What do I do?",1438,glfdmm,datascience,91,"Dean Hoffman responds: [https://www.reddit.com/r/datascience/comments/gmirks/my\_apologies\_from\_a\_data\_science\_company\_stole\_my/](https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/)

Hi,

My girlfriend is a 22 year old university student passionate about data science, and she just posted my first article on Medium using Machine-Learning (that took her months of research and coding to put together). Her post only has about 500 views, but to her surprise today a reddit user called [**Dean-Hoffman**](https://www.reddit.com/user/Dean-Hoffman/) **posted a link to his own data science company where he copy-pasted her article.** He didn't contact her about reposting it, didn't give her proper credit and **ridiculously added a ""Contact Data Scientist"" at the end with his name on it**. On the article, he clearly stated he is the author in multiple locations. This is the ""Data Science"" company that links from the article on his website: [https://www.actionablelabs.com/](https://www.actionablelabs.com/)

Apparently the guy Dean Hoffman is the ""founder"" of the company and refers to himself on the About Us as **""offering the highest commitment to excellence, personal integrity, and business ethics.""**

Update: Hey, this is the girlfriend that wrote the article. First of all, thank you all that made the time to reply, research and help me find answers. It's really appreciated.  So far, this is what we know about this person (or people):

\- This website has been stealing hundreds, if not thousands, of data science projects and articles from legitimate data scientists and writers.

\- The stolen content website in definitely bot-operated as the owner posts dozens of articles a day, completely copy+paste, mainly from Medium, TechCrunch and Towards Data Science.

\- It's confirmed that Dean-Hoffman from the Linkedin that links from his company (Actionable Labs) is a real person and the same Dean-Hoffman that is stealing content and running a data company.

\- If you go on his linkedin, under ""Data Scientist - Pennsylvania Department of General Services"" you will find that he mentions ""Actionable Insights"" (the stolen content website) in one of his experiences. Completely absurd.

UPDATE 2: Medium and TDS unfortunately can't do much for me individually as the authors are the ones who own the rights to the articles. TDS will try to reach out to the owner and ask them to take the posts down. I hope they see that their whole website is being copied, which would most likely infringe their TOS.

Please don't comment anything that contains the words ""copyright"", ""infringement"" or related words on her article as it may trigger keyword algorithms that delete copyrighted articles posted to Medium (and thus could have her article deleted). Thank you!

This is his post on reddit: [https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai\_and\_real\_state\_predicting\_rental\_prices\_in/](https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai_and_real_state_predicting_rental_prices_in/)

This is the article he stole from her: [https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/](https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/)

This is her article, posted on Medium, which has very strict plagiarism protections posted on April 24th: [https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc](https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc)"
Weekly Entering & Transitioning Thread | 17 May 2020 - 24 May 2020,9,gle83b,datascience,175,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
"If you are making a machine learning algorithm that takes place over a period of time, would you make the test data the most recent year or is it a better idea to use test data from every year?",45,glclxb,datascience,23,"For example you have a dataset from the years 2015-2019. Would you have the training data be 2015-2018, and the test data be 2019. Or, you could use training data from every year, and the test data would be small chunks each year."
"I've heard people say that data science is becoming closer to software engineering. Is this true, and if so, what are the reasons behind this trend?",4,gla11f,datascience,11,"I've heard from numerous people that data science problems are starting to become software engineering problems. Is this true? And if so, what are the reasons behind this morph into engineering?"
What's R good for?,0,gl9mzz,datascience,48,"I can't figure out what's the great advantage of R over Python. 

R is a single-use language, Python can be used on way more things than just data science. 

Plotting is not harder in Python. 

Libraries are also not a problem in Python. In fact I'd say being a general purpose language, there's way more libraries for way more uses for Python than R. 

Is it the build-in datasets? But I don't care about iris flowers, I have my own problem to solve. And even if I do care, I can easily download it from the internet. 

So what's the reason why should anyone spend time learning R? I don't get it."
Data Science Journals,29,gl6lpa,datascience,15,"Hi everyone,

I'm working on a paper with a few people and we are almost ready to publish. None of us have published anything before and we are wondering what are some good journals to publish in.

Our topic is about using machine learning to help end homelessness.

So far we have found 2 journals that we are considering :

Journal of Urban Economics - Elsevier 
Journal of Machine Learning - Springer

Should we be looking at sociology journals or data science?

Any advice would be greatly appreciated.

Thanks!"
What kind of data science do you perform? Analytical [A] or Building/ML [B]? Which is more in demand?,0,gl41nk,datascience,7,"As the title says, what kind are you, and which do you see being more in demand?"
Advice? I like Time Series but don't have experience in it (just in other stuff),107,gl1uen,datascience,29,"TLDR; DS working at a bank with images/nlp but having an affair with Time Series (I love this). Haven't found a job on that (so no experience) and recently found a position at the current workplace involved with Risk (might not have ts either). Seeking for advice. 

Hello everyone! 

I'm a DS working at an important Bank in my country. Here I've been dealing with solving problems with unstructured data, like videos, images and text. It's being interesting, but I feel quite unsatisfied. I mean, I studied economics and I'm doing a MSc in Statistics. I love time series in a theoretical way, since I can't find a job that works with them. 

I thought that working at a bank would be cool and have some forecast related projects I could work on... but I couldn't work on any.  

You see in my department there are many areas for data analysis, but not for data modeling, except mine and other. The other area makes churn models, and sometimes recommendation systems. 

I feel I'm taking a wrong path for my future. I have no finance related experience (images, text?) Neither time series Modelling experience (aside from the theoretical one). 

I want to change and I recently found a position at the bank that deals with Risk and I think I might go for it (it's no time series related, but is bank related).  But my boss and the director of the area I work on don't want me to move. They say they really like my work, and that we have many projects we can work on, particularly since my area is gaining a lot of credibility. 

I don't know what to do. I'm not sure if the position in Risk involves modelling and predicting as much as I'd like, or if it will just be analyzing and giving back raw numbers. 

Should I stay and keep looking for TS related jobs, or change to the Risk to gain insights and learn from the bank duties and may find place for forecasting? Should I just take this, grow in this side and hope to find something in the future? 

I'm very confused. And I think that this decision could impact my future, my happiness and many things in my life."
What setup should I use for matching and monitoring this project?,0,gktz5p,datascience,3,"I need to establish a framework for formatting, matching and tracking changes to a dataset that can only be accessed through a CSV-file. I know how to do that using Excel and VBA, but I was wondering if there isn't a better way.

The problems goes:

1. The goal is to gather a weekly COMPANY : SHARES summary (could be limited to 30 pre-selected companies).
2. Twice a year I get a COMPANY : FUND overview.
3. I can pull an extensive dataset (around 54k obs) structured as FUND : SHARES, but the dataset FUND-string often also includes a lot of noise, such as the company address, company name, telephone etc.
4. To aggregate COMPANY : SHARES, I thus need to match COMPANY : FUND by scanning through the dataset FUND string and match with keywords relating to each specific company (such as a fund name, or the company's own name).
5. Because of the bad quality of the dataset, I will need to manually look at the results of the sorting to adjust the keywords for faulty matches, e.g. a new fund has been attributed because it matched with the company name keyword, but the string also includes some info which makes it clear that it shouldn't have been matched here so I include a non-match keyword filter it out from being matched with that company. This is unfortunate, but bearable as a total of \~200 funds are matched if the number of companies are limited to 30.

I know how to do streamline most of this process with some hassle using Excel Power Query for formatting and importing the CSV, VBA for for matching the data and a Pivot Table for creating a summary. I also know some Python and have SQL experience. I see how SQL would ease the sorting, but I would still need to manually download and format the CSV before feeding it into, say, MS Access. It would be so nice with a setup where I could more easily set the company match/don't-match keywords, see exactly which rows has been matched per company from the dataset, adjust keywords and re-run, and maybe even point out new matches that wasn't there last time it was run.

I would be very grateful for any tips or ideas."
"Dealing with ""conditional"" features",9,gktrxo,datascience,25,"I ran in to this problem trying to build a model to predict loan defaulters using credit history features. A few of the features are of the format ""number of months since X"" where X could be the borrower's last late payment, last account of a particular type opened, etc. Some of these seem like they could be strong features, but have many missing values (with good reason). For instance, ""months since last delinquency"" feature only applies to those borrowers which have a delinquency on their record. Imputing a value of 0 would imply those with no delinquencies are the same as those with an extremely recent delinquency, and imputing a very large value (say 9999) just doesn't sit right with me. My only other idea was to introduce an ordinal feature instead of a numeric one, binning delinquency recency by say ""never"", ""<1 year"", ""1-2 years"", ""3-4 years"" etc. The issue I have with that is I would be deciding the cut off points at the expense of granularity, while it may be better to let the module ""learn"" those cutoff points.

&#x200B;

&#x200B;

Any insights would be greatly appreciated. Thank you lots :)"
"Git and huge code generated files. How do you deal with big, constantly changing files?",1,gkprqy,datascience,6,"So let's say I have some code that postprocesses some big, computationally expensive output (say a pretty picture). Now I'm trying to make an open source project fit for github that can be shared...

How do you deal with tracking giant, constantly changing files? If you keep them in the git repo your repo becomes huge. If you keep them out of the repo, well, these files are extremely expensive to generate. 

How can you share this data without keeping track of its unneeded history?"
Data Science Association Membership as a Gift,0,gkia5h,datascience,3,"My mother is a data scientist for the school district where she assist in coordinating and analyzing standardized testing for K-12, identifies students that may need extra resources and coordinates powerschool; her birthday is coming up and I wanted to pay for her to join some kind of data science association for a year. I'm familiar with psychiatric, pharmaceutical, and otherwise medical associations, but know next to nothing about the data science community. Does anyone have suggestions for organizations to investigate or other places to look/ask around?

I'd like it to provide benefit to her and her career beyond being something cool she did once, but am not sure where to look. I've seen a couple that seem to be focused on research and ethics, but I'm not sure if there are organizations that would apply more directly to her field. Id like to make it a one time investment over the summer and not have to pay for any further benefit from the organisation as im currently in college and only have disposable income in the summer. Thank you for anyone that shares thier knowledge or spends time to help me!"
Turing.jl vs Stan in Julia?,2,gkg186,datascience,1,"I'm having a few days off so I want to spend the time learning Julia. I'm working mostly in R and Python, and my work involved a lot of Bayesian stuffs which I usually use either Stan or PyMC3 for. Recently I've been playing around with Julia, and I've heard a lot of praises for Turing.jl for probabilistic programming. I wonder if anyone here ever used it? What are some pros and cons against, say, Stan or PyMC3?"
RBMs for clustering ?,1,gkcz9w,datascience,0,One of my colleague suggested to use RBMs for clustering. My question is isn't it a bit of overkill when I have a mixture of binary and continuous data and also not all the variables will have a gaussian distribution. Isn't something like K-prototype a simpler and more intuitive solution. Please correct me if I am wrong.
How to have a career where I'm not using BI tools?,26,gkam51,datascience,11,"Am I the only one who hates using Business Intelligence tools? Something about the interface...and all the clicking...and the ""hidden"" options that only appear in a certain ""context"", ugh.

In contrast, I love using a programming language to express my analytical ideas. I find it easier to get into a good ""flow."" The statements come naturally to me, and I can spend hours coding without losing focus.

How can I move forward in my career towards a goal of only developing data products with code? I'm learning Python, am fairly adept at SQL, and have used R for a number of years.

My group is heavily invested in a BI tool ( and are fairly advanced at it ). I'm scared to quit my job during this pandemic, but geez I would love duties that did not include reformatting old reports."
"How do you organise your data science projects? Code, data, learnings.",150,gk9ggo,datascience,28,"Coming from the engineering field where the main artefacts of work are source code and production systems, I sometimes feel a bit short in processes around organising and saving the work my team does.

I've noticed there are several types of projects:

* once off data analysis
* exploration that leads to a feature shipped in a product
* explorations that never get shipped
* data analysis for debugging purposes. Let's say we run an A/B test and want to figure out whether we set it up correctly. We won't really share results outside of the team.

I guess different project will possibly get different answers, but let's kick off with these questions:

* where do you store the sidecar data? We store the code on GitHub, but don't want to package the data with the code (security/compliance reasons)
* do you make all your explorations reproducible? For example, a piece of code calls the warehouse. Do you store the snapshot of the data somewhere so you know exactly what was analysed?
* do you store all analysis you perform? For example, exec asks you for some numbers for a PPT
* do you keep track of different experiments? What do you use for that? Notion/Confluence/Gdocs/something ML specific?

&#x200B;

Cheers!"
Request: One day a week when all career questions are banned,128,gk4alt,datascience,40,
NBA Data Science Project ideas,4,gjy5ub,datascience,20," 

Hey guys, I'm a huge fan of the nba and there are some ideas I have for projects for data science/analysis related to the nba. I'd love to know your feedback on these ideas or if you guys have any ideas of your own, please share as well.

1. Does homecourt affect a team's chances of winning a game? I wanna see how homecourt affects a team's chances of winning a game, and predict the chance each hometeam has of winning a game. I believe it comes down to skill more than whether a team is the home team or not.
2. Predicting a team's chances of winning the nba draft lottery. Ik that have a worse record gives you a higher chance of winning the lottery, and thus, you get more ping pong balls in the draw. But what would be other features or factors that affect a team's chances of landing the number one pick in the draft?
3. Predicting an nba player's aav salary. I wanna see how durability, the more games you play, winshares, ppg, points allowed per game, three point percentage, and apg would affect a free agent's chances of getting more money in their next contract"
Data Analyst vs Product Analyst,6,gjv1bn,datascience,4,What’s the difference? Does Product Analyst require more product/overall industry experience?
Great communities for Data science and related in addition to this one?,0,gjlhag,datascience,10,I left my job just before the lockdown. I'm struggling without daily intelligent interactions. I've found a number of good subreddits including this one for work stuff. Where else can I find the quality OC?
Job Prospects: Data Engineering vs Data Scientist,168,gjd820,datascience,183,"In my area, I'm noticing 5 to 1 more Data Engineering job postings. Anybody else noticing the same in their neck of the woods? If so, curious what you're thoughts are on why DE's seem to be more in demand."
Does anyone in digital marketing have recommendations on Location/Store data vendors?,3,gj4687,datascience,2,"We're looking to link Google Adwords/FB other digital marketing platforms to in-store visits and are in the preliminary steps of scoping vendors. The basic requirements are GDPR and CCPA compliance, geographic span includes US, EMEA (mostly Britain and EU), and APAC (mostly just Japan), API to programmatically pull the data.

Other than that, we're pretty open.   


Has anyone worked with Factual/Foursquare, PlaceIQ, GroundTruth, Location Sciences, Cuebiq, X-Mode, SafeGraph, or any other location data vendor? Any general feedback or thoughts on the subject of marketing with data location?"
Data Science related apparel?,2,gj3i6j,datascience,16,"I'm looking for some subtle apparel. I saw a hat that had the Hadoop logo on it, and that's definitely not subtle. Maybe a statistical equation / function? Any ideas welcomed."
How to Document Data,8,giz5ve,datascience,2,"Hey I'm on the hunt for tools that make data documentation easier. We have very heterogeneous datasets. Some of them are in a database other datasets are in a folder structure. Data types range from geographical data to images of documents. 

I'm looking for a tool that monitors if a new data set is added (if a new table or column or folder is added for example) and creates an job that it needs to be documented. It should also give an overview of which data sets are not yet documented. And it would be neat if I can create reports of data that is available.

how can this be solved?"
How did you land your current data science job?,142,gilzd7,datascience,84,"1. Did you apply online through online job boards (Linkedin, Glassdoor, Indeed) or through networking?
2. Did you do a coding test or take home assignment?

Your replies will help me with my job search thanks!"
Tattoos?,0,gibw47,datascience,18,"I know that results may vary, but in general, what is the average office expectation / attitude towards tattoos? Now that I can afford them, I want a lot. Unsure about attitudes towards them however. My current office wouldn’t care, but if I were to change in the future, what should I expect?"
"[MEME Monday] Coming to a LinkedIn feed near you: ""The Data Whisperer.""",0,gi0ywu,datascience,0,"&#x200B;

[https://imgur.com/a/FP5NPY2](https://imgur.com/a/FP5NPY2)"
Lead Scoring Approaches,1,ghw1eu,datascience,3,"I'm working on a problem to quantify marketing actions into a lead score. The goal is to understand when to pass a contact to the sales team. My original approach was to focus on data from the last 6 months and aggregate features such as time spent, webinar views count, etc... This approach is working fine, as a way to improve it I'm trying to implement time into consideration. For example a webinar viewed today is more valuable than an webinar viewed 5 months ago.

I'm looking into implementing some kind of exponential decay into the scoring process. I wanted to ask if anyone faced anything similar, or saw an approach that could work."
How long does it take to learn Data Robot and Spark?,0,ghvnxr,datascience,15,I have never used any of these programs. How long would it take for me to get the hang of it?
#Tidytuesday for Pythons's Pandas?,204,ghu8wt,datascience,40,"A friend just told me the R community has this wonderful project called **#TidyTuesday**, which provides you with a fresh dataset each week to practice your data wrangling and visualization skills. Would you know if any similar project exists in the Pandas community? Alternatively, do you think it's possible to explore the given datasets with Pandas just as well? Does it even make sense to explore similar projects in Pandas?"
Consistent Prediction Intervals Time Series,2,ghtnhu,datascience,5,"In generating predictions with associated prediction intervals for an ARIMA model I've fitted to a dataset of mine for a project, the intervals I have get wider as time goes on which makes sense, more potential variability in the future. 

But as I transformed my data in such a way such that it is now stationary and hence has constant variance over time, shouldn't I be able to get around this issue somehow and get constant width intervals?

Thanks I'm advance"
Managing Python Dependencies in Data Science Projects,118,ghk5ba,datascience,51,"Hi there, as you all know, the world of Python package management solutions is vast and can be confusing. However, especially when it comes to things like reproducibility in data science, it is important to get this right. 

I personally started out `pip install`ing everything into the base Anaconda environment. To this day I am still surprised I never got a version conflict. 

Over the time I read up on the topic [here](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html) and [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) and this got me a little further. I have to say though, the fact that conda lets you do things in so many different ways didn't help me find a good approach quickly.

By now I have found an approach that works well for me. It is simple (only 5 conda commands required), but facilitates reproducibility and good SWE practices. Check it out [here](https://haveagreatdata.com/posts/data-science-python-dependency-management/).

I would like to know how other people are doing it. What is your package management workflow and how does it enable reproducible data science?"
Was There a Data Scientist Shortage in 2019? - Yes. There were more job postings than searches on LinkedIn and Indeed.,182,gh93qv,datascience,53,
"For those with a PhD or MD, has it helped your career as a data scientist?",1,gh7f8k,datascience,26,"I'm currently a data scientist in healthcare, but have been getting the itch to go back to school again. I currently have a masters in a clinical subject, but I have been considering a PhD in epidemiology or an MD.

Since I'm already a data scientist, is it even worth it to go to graduate school again? My reasoning is that I feel I can be an even better data scientist in healthcare if I worked directly with patients and EHRs (inform my assumptions). Another reason is that a PhD in epidemiology will provide me an even deeper understanding of clinical research methods and statistics."
How do yall approach data mining in small data sets?,4,gh5hm4,datascience,3,"Hi all! I'm a recent masters student in ML and data analytics. I'm taking a data mining course where we have an open ended project where we have to mine a given data set. It's a survey with about 2k users and 40x questions and I'm curious what yalls approach for coming into data sets like these and the approaches you'd use to mine. 

Note that I am NOT asking for help with my assignment. I'm rather looking for advice on practices and thought processes that professionals use for smaller more manageable data sets. I was going to sanitize the data and ingest it with pandas and then do some association mining to find similarities between users and some cluster to find similar groups. It'd be cool to hear the steps and considerations yall take and the technologies yall use!

EDIT: To answer the questions, it's essentially a politcal multiple choice questionnaire. This is super exploratory / open ended so I was just curious if you use techniques to find interesting anomalies or relationships vs coming up with hypotheses and then using them to drive your mining."
Real world DS project repos ?,0,gh407h,datascience,5,"Hi there,

Is there a repository of real world data science projects from around the world ? I have been asked to explore some avenues in the data science/analytics field and was wondering how this is being applied in real life companies.


Edit : Not looking for code repos. I was just trying to find out what all projects have already been implemented. Just a description would suffice"
Every Kaggle Competition Submission is a carbon copy of each other -- is Kaggle even relevant for non-beginners?,362,gh3v0q,datascience,118,"When I was first learning Data Science a while back, I was mesmerized by Kaggle (the competition) as a polished platform for self-education. I was able to learn how to do complex visualizations, statistical correlations, and model tuning on a slew of different kinds of data.

But after working as a Data Scientist in industry for few years, I now find the platform to be shockingly basic, and every submission a carbon copy of one another. They all follow the same, unimaginative, and repetitive structure; first import the modules (and write a section on how you imported the modules), then do basic EDA (pd.scatter\_matrix...), next do even more basic statistical correlation (df.corr()...) and finally write few lines for training and tuning multiple algorithms. Copy and paste this format for every competition you enter, no matter the data or task at hand. It's basically what you do for every take homes.

The reason why this happens is because so much of the actual data science workflow is controlled and simplified. For instance, every target variable for a supervised learning competition is given to you. In real life scenarios, that's never the case. In fact, I find target variable creation to be extremely complex, since it's technically and conceptually difficult to define things like churn, upsell, conversion, new user, etc.

But is this just me? For experienced ML/DS practitioners in industry, do you find Kaggle remotely helpful? I wanted to get some inspiration for some ML project I wanted to do on customer retention for my company, and I was led completely dismayed by the lack of complexity and richness of thought in Kaggle submissions. The only thing I found helpful was doing some fancy visualization tricks through plotly. Is Kaggle just meant for beginners or am I using the platform wrong?"
Weekly Entering & Transitioning Thread | 10 May 2020 - 17 May 2020,18,gh09b5,datascience,227,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Data Science Salaries Post COVID 19,13,gh00nf,datascience,21,"I’ve seen a lot of data scientists laid off during covid-19, and I was under the impression DS was essential to operations. I’m curious if that’s impacted salaries in any way post covid-19"
How do I get out of the circle of “I need experience to get a job and I need a job to get experience”?,324,ggojki,datascience,92,"I have a masters degree in economics but I lack programming skills. My graduate program used STATA while I’ve seen the jobs that I want desire SAS, SQL, Python, and/or R. I’ve recently taken a course in R Programming from Coursera and i think I’ve learned a bit. I also don’t have any real job experience with data visualization and analytics other than extracting data and running regression models in my studies. For instance, my thesis used the fixed effects model. 

I’m kind of stuck right now and I have no idea how to get out of that “circle of death”. I’d even take an entry level data analyst position just to get my foot through the door."
how to turn an ARVIX paper into working code example?,5,ggj04v,datascience,3,"I'm interested in creating a crude working demo of this: [https://arxiv.org/pdf/2004.02349.pdf](https://arxiv.org/pdf/2004.02349.pdf)

Essentially, it's using state of the art NLP (specifically, BERT) to map statements like:

>How many world champions are there with only one reign?

to

    select count(*) where column(""No. of reigns"") == 1; 

I have a solid background in python, and an intermediate level of experience with ML (mostly sklearn and fast.ai) on tabular data. But I am completely self-taught, and have a very weak background in both math and NLP, i'm stronger on the practical/coding side. As such, the 'mathy' explanation in that paper is tough for me to translate into code intuitively.

Any advice? Anybody want to collaborate? give me breadcrumbs and I'll do the heavy lifting..."
"Managers, what do you think of MicroMasters?",83,ggin49,datascience,62,"I was recently looking up MIT’s MicroMasters in Stats and data science. Since it’s not officially a masters program, I wonder if it will even carry that much weight. Thoughts?"
How are you providing documentation about your reports and fields?,7,ggeiwg,datascience,3,"I've been reading about systems like lexikon at Spotify and wondering how other teams document and knowledge share about reports, dashboards and even data fields in a way that is friendly to analysts and self serve business users."
"As a remote first data team (or working remotely for the first time) , what's your ideal tool stack to manage documentation, knowledge transfer, communication etc?",75,gg74pi,datascience,41,
Remote job question,2,gg34t8,datascience,8,"If I hold an entry level position as a Data Analyst, would any company be okay with me leaving the country (being completely remote) for a few months out of the year then coming back to the office for the remaining portion?

If not, would a senior level position be okay with this?"
[News] GitHub Announces ‘Codespaces’ for In-Browser Coding,113,gg0mab,datascience,13,"Last week, GitHub announced four new products on its official [blog](https://github.blog/2020-05-06-new-from-satellite-2020-github-codespaces-github-discussions-securing-code-in-private-repositories-and-more/). The most eye-catching of the lot is the tool Codespaces. Released in conjunction with the GitHub Satellite 2020 Virtual Conference, Codespaces is an in-browser integrated development environment (IDE) that lets users type their code directly on a GitHub website page.

Read more: [GitHub Announces ‘Codespaces’ for In-Browser Coding](https://medium.com/syncedreview/github-announces-codespaces-for-in-browser-coding-6c2240f1b911)"
Plotting Big Geo Data,3,gfx9s1,datascience,13,Does anyone know any library where we can plot big geo data without lagging issues?. I googled it but all I got this useless towards data science pages where people try to plot data with 50 rows. I'm learning plotly at the moment but geo plotting 100k location values seems too laggy. Any suggestions?
"Designing a Small, Scalable Data Pipeline on a Budget",6,gfwucw,datascience,21,"I work at a small, grassroots nonprofit youth center that provides afterschool and summer camp programming to middle school students in the inner city. I was hired on full-time as their ""Data Analyst,"" however, they had no prior systems, databases, or even spreadsheets, so I inevitably ended up becoming a one-man data team (which I actually am enjoying).

I built a small system of google sheets & forms to collect our student data (attendance, grades, behavior, etc), volunteer data (attendance, skills, etc), and program data (performance evaluation), but I would like to migrate to a more centralized solution that is scalable. The organization plans on scaling and replicating this model around the city, so it would be ideal to have a scalable, replicable data system to accommodate that goal.

My question is this: Are there any open-source/low-cost solutions for building a network of automatable data systems to fit this use-case? Something like a cross-platform app that we can read, write, modify, and delete data with and store in a sort of simplified document system like JSON or Firebase. Since I don't plan on staying here forever, I'd like to build it so it can be used by someone with any level of proficiency in programming.

I welcome any collaborators or advisors, and I'd love to work together to figure this out for a great organization that does great work for the community.

Thanks for reading :)"
Multi-output prediction with correlated outputs?,2,gfqqmc,datascience,3,"Hi /r/datascience,

I have a problem I'm working on where, for each row of features, I want to predict *two* binary output variables, y1 and y2. At the moment I'm predicting these independently (using sklearn's Multiple Output Classifier). However, I know that y1 and y2 are somewhat correlated. Are there any techniques that I can use that take advantage of this correlation to improve the accuracy of y1 and/or y2?"
How long should I give myself to prepare before scheduling my DS tech interview with Amazon?,13,gfpguy,datascience,13,"I've been contacted by Amazon for the first time ever for a data scientist role. I cleared the first behavioral round and they told me next one will be a 1hr technical phone screen.

They said ""you decide when you're ready while you brush up your tech skills and let us know when you want to schedule it for"".

Since I have no experience with interviewing with big firms, how much time should I give myself to study? Is 3 to 4 weeks reasonable or would that piss them off and make them question me as a candidate?

There will be questions on ML model I worked on, model evaluation, and stats theory on probability and a problem solving question where I will have to explain my thought process of building a model for a given case.

Would really appreciate your advice. Thanks!"
"I'm sick of ""AI Influencers"" - especially ones that parade around with a bunch of buzzwords they don't understand!",818,gfnax4,datascience,350,"This is going to come off as salty. I think it's meant to? This is a throwaway because I'm a fairly regular contributor with my main account.

I have a masters degree in statistics, have 12+ years of experience in statistical data analysis and 6+ in Machine Learning. I've built production machine learning models for 3 FAANG companies and have presented my work in various industry conferences. It's not to brag, but to tell you that I have actual industry experience. And despite all this, I wouldn't dare call myself an ""AI Practitioner, let alone ""AI Expert"".

I recently came across someone on LinkedIn through someone I follow and they claim they are the ""Forbes AI Innovator of the Year"" (if you know, you know). The only reference I find to this is an interview on a YouTube channel of a weird website that is handing out awards like ""AI Innovator of the Year"".

Their twitter, medium and LinkedIn all have 10s of thousands of followers, each effusing praise on how amazing it is that they are making AI accessible. Their videos, tweets, and LinkedIn posts are just some well packaged b-school bullshit with a bunch of buzzwords.

I see many people following them and asking for advice to break into the field and they're just freely handing them away. Most of it is just platitudes like - *believe in yourself, everyone can learn AI, etc.*

I actually searched on forbes for ""AI Innovator of the Year"" and couldn't find any mention of this person. Forbes does give out awards for innovations in AI, but they seem to be for actual products and startups focused on AI (none of which this person is a part of).

On one hand, I want to bust their bullshit and call them out on it fairly publicly. On the other hand, I don't want to stir unnecessary drama on Twitter/LinkedIn, especially because they seem to have fairly senior connections in the industry?

**EDIT: PLEASE DON'T POST THEIR PERSONAL INFO HERE**

I added a [comment](https://www.reddit.com/r/datascience/comments/gfnax4/im_sick_of_ai_influencers_especially_ones_that/fpvvxsk?utm_source=share&utm_medium=web2x) answering some of the recurring questions.

**TL;DR -** I'm not salty because I'm jealous. I don't think I'm salty because they're a woman, and I'm definitely not trying to gatekeep. I want more people to learn ML and Data Science, I just don't want them to learn snake oil selling. I'm particularly salty because being a snake oil salesman and a shameless self-promoter seems to be a legitimate path to success. As an academic and a scientist, it bothers me that people listen to advice from such snake oil salesmen."
How do you explain the benefits of a ML driven customer segmentation?,2,gfhxqd,datascience,9,"My clients are some of the least technical people I’ve encountered. The whole process of getting them excited about this was not pleasant.

It got me thinking, how would other data scientist go about doing this."
What makes a good personal project - from the perspective of a hiring manager,614,gf9hrs,datascience,56,"We often see the question on this sub around ""how do I build a portfolio as a student?"", i.e., what projects should I work on?

If the resumes I've reviewed over the last 5 years are any indication, most people seem to think that the answer is a Jupyter Notebook that takes a pretty standard dataset, does EDA, builds a model, and presents a bunch of plots showing quality of fit.

From my perspective, these projects are pretty much useless. I say that because odds are that I can figure out if you can build such a notebook by just asking you a handful of questions and spending 5 minutes talking to you. Most importantly, being able to do that for a project that you chose (whether personal or capstone project) makes this project worthless in terms of helping me evaluate how you overcome obstacles - odds are that the way your overcame obstacles was by choosing a project that was easy to do and had relatively clean, available data.

So how do you make a better personal project?

**Start with a problem statement that is actually useful, even if you don't know how to solve it**

As a rule of thumb, an imperfect solution to a useful problem is better than a perfect solution to a useless one. I'd rather see you build a linear regression model to solve something that people actually care about instead of building a deep learning model to predict Titanic deaths. Why? Because problems that matter show a hiring manager that you can think through how to use data science to drive value. And if the process of getting there sends you down some windy roads, it also shows the hiring manager that you're able to navigate them. These are two *really* important skillsets.

Mind you, when I say ""useful"" I don't mean ""important"". I'm not telling you that you need to go find a cure for cancer, just to focus on something that *someone* will find a user for.

Example:

* Building a  model to optimize a fantasy football lineup.

Again, not important - just useful.

**Focus on a problem that goes beyond predicting a single metric**

A lot of data science ""side projects"" that I see focus on predicting a single quantity. While sometimes you will find yourself doing that in a work setting, most of the time your work goes beyond that, meaning you are normally predicting a quantity so that you can then influence a decision process, or estimate a broader outcome, etc.

So if you're going to work on a side project, try to follow through your model ""all the way"", i.e., through to an actual outcome that could be useful.

Example:

* Don't just predict the number of points a player will score in fantasy football - actually build that into a model that can help someone make decisions in a more complex setting (like daily fantasy football, or evaluating draft strategies).

**Start with ugly, raw data if you can**

If you start your project with mostly clean, post-processed data you've already skipped a big step in terms demonstrating what you can do. If instead you choose to go for something that isn't in its final form, you can flex a couple of different muscles.

For example, you could scrape data. Not super complicated, but it already shows me an extra skillset. Or you could start with data in log format and writing the necessary scripts to convert it into tabular form.

Example:

* Instead of starting with aggregate NFL stats, start with NFL play-by-play logs and write a script to convert ""S.Barkley runs for 10 yard loss PENALTY Holding: NYG REJECTED"" into the appropriate statline.

**If possible, build an actual product - not just analysis**

Building a product allows you a couple of advantages. For one, it allows you to just share a link to something that people can actually use. Secondly, if your tool were to get any traffic, it allows you to validate your idea. Lastly, it allows you to flex a completely different muscle - the fact that you can think through basic (or advanced) designs and deploy a solution to an environment.

Example:

* Build a web-app where people can make selections and your tool will output a recommended lineup in fantasy football.

**Work alone**

One of the big issues with group projects outside of a work setting is that it's hard for a hiring manager to corroborate what you did personally vs. what others did. That means that some hiring managers may just choose to assume that you didn't have a part in all of it - and worse, that you don't have all of those skills.

If you work by yourself, you can guarantee that an interviewer will assume that you did all of it, and there will be no questions of what you can/cannot do.

Some may say ""but group projects show that I can work in a team!"". And I think everyone that has ever worked in a group project knows that they seldom punish the person in a group who most lazy and hardest to work with. 

Obviously this is just my opinion, but since the topic comes up often I figured it was worth putting it down to at least start a conversation."
What are your favourite non-Reddit places to discuss DS on the web?,22,gf5ms2,datascience,8,"Ever since datatau originally went down I’ve been looking for an active DS based discussion group. There’s a .net clone of datatau now, but I’m wondering what else is out there and active.

What are your favourite non-Reddit places to discuss DS, stats, or ML on the web?"
Certification for project manager/business consultant?,1,gf4i3w,datascience,4,"Hi guys,

I  have an ambition to switch from IT project management in the area of CRM to advanced analytics projects in business environment. At this point of time I  work in one of the IT Consulting/Implementation companies at manager-level position. I have a  strong background in Business Administration and Project Management, but no coding skills.

What is the level of project manager's knowledge about the data science that you'd expect in order to ensure a successful management of big data/advanced analytics IT project? 

What certification should I obtain to enhence my profile? I was considering the data management architect certification from the technology that I am working with and maybe Tableau, as they seem to have some credentials for managers.

Any other iseas? Python/R course (even if I will never have a hands-on experience)?

&#x200B;

Thanks for help!"
Structuring Juptyer notebooks for Data Science projects,154,gf1uqg,datascience,67,"Hey there, I wrote a technical article on how to structure Juptyer notebooks for data science projects. Basically my workflow and tips on using Jupyter notebook for productive experiments. I hope this would be helpful to Jupyter notebook users, thanks! :)

https://medium.com/@desmondyeoh/structuring-jupyter-notebooks-for-fast-and-iterative-machine-learning-experiments-e09b56fa26bb"
Is there an over emphasis on skills for hiring in this field right now?,6,gem4up,datascience,10,"My personal opinion is that there is an over emphasis on skills in interviews in this field right now. I get that hard skills are important, your SQL, python, R, Hadoop etc. However I have been on interviews where not a single question was asked about my past projects or the kind of person I am, my thought process, who did I have to work with to get what I need, how did I go from turning business requirements into project requirements etc. They were only interested in knowing my computer skills. 

I guess it would seem to me that hirers are forgetting that they are hiring a human being who is much more than computing skills? 

I personally think it’s better to hire a good worker with “ok?” skills than the other way round. I mean what’s stopping him from picking up all the necessary skills when he’s on the job? 

Curious about what the rest of you think."
Off My Chest. After almost 9+ face-to-face interviews I cannot even get a simple entry level Data Analyst job for almost 7 months now. Any advice?,540,gei64h,datascience,88,"I did my BSc in 2017, worked as a SQL analyst for 5 months and I completed my Data Science MSc end of last year. For a entry level analyst role I have the skills in SQL, Power BI, Excel, Python, I even did a tableau course on Analysis/ Data Science.  One of my concern is my in depth knowledge on the tools and programs above as I have no idea how to compare myself to another analyst.

I have a speech impediment which as expected gets worse during interviews as I have to think on my feet really quickly. I feel like I struggle with the competency-based questions, because due to my stammer I cannot use the STAR method correctly. Most of my feedback from the interviews were I wasn't the right candidate and other had fit the bill etc etc. ""you weren't confident, and they felt I wasn't strong enough"". I have never doubted myself nor have I lost confidence.

Especially during the lock-down, it’s hard for me to get an interview as most companies are closed and those that are still hiring start from a telephone call. In terms of landing an interview I have refined my CV with professional help and most interview reaches the face-to-face stage.

I am really afraid that I will slowly lose all my knowledge and programming and analytical skills which will cause me to lose an interview in the future. My goal is to be a Data Science in the future but I cannot even land a entry level Data Analyst position.

Would appreciate if you guys can answer these questions.

* What does an entry Data Analyst do on day to day basis?
* What skills do I need to polish?
* Are there any alternative ways to answer the competency-based questions?
* Any advice or suggestions

Edit: 

You guys are awesome thank you. Haven't had a chance to read all the messages yet. Really grateful for all the feedback! "
How does FiveThirtyEight afford continuous polls?,2,gehca6,datascience,3,"I was reading up their COVID approval and concern polls, and it seems they conduct these at a consistent rate, almost day by day. As far as I know, polling is not cheap at all (even when done online),  considering you want a national sample. 

How do they afford to do that?"
As a data scientist how often do you use principal component analysis? Are there any better methods to accomplish the same task?,12,ge96qc,datascience,27,
"A question for those pursuing an MS in CS/DS in the USA and those who graduated a couple of years back, how difficult is it to land a job as a data scientist?",188,ge5bf9,datascience,73,What obstacles did you face while applying/getting an offer? How difficult is it compared to getting an SDE job? How big of a factor is job experience? Is it easier to get a data analyst job comparatively? Any advice you might have for those starting out? Thanks a lot!
Data Integration Help,1,gdyijn,datascience,7,"Hi!  I'm hoping someone can help me or provide some insight.  I work with a partner agency that is hoping to improve dataset integration. Briefly, they have one system that creates a user id and documents some information (this is related to covid testing and contact tracing). There is another system they use essentially like a service management tool. It takes data from system 1 (e.g. name, phone, tested positive) and uses this additional system to document case notes and provide service work updates (e.g. patient has not exhibited symptoms in three days).

Here's the issue:  the agency is manually exporting data from system one and uploading into system two nightly.  They use SAS for this, but i'm not sure how (I've only ever used SAS for analytics like MLR, cluster analysis, etc.).  

They need a faster and less manual way to integrate the data.  Ideally when one system is updated, the other is also updated much quicker than overnight and less manually (than export, import, matching, etc.).

I don't have a lot of specifics here; my agency was just brought on to help and i do not yet have information like metric names/types, job/etl schedule, etc.

Does anyone have any experience, insight, or suggestions?  I would appreciate it!
Thanks!"
For those on the hiring side: how do you deal with incoming or prospective data scientists with little to no communication skills?,25,gdmn0f,datascience,28,"**BG:** I'm a director of data science at a global Fortune 500 firm and am constantly on the lookout for talent (barring currently with the virus).  I recruit pretty heavily with prestigious universities in the U.S. out of their data science programs.

**Issue:**  I find it is difficult as a needle in a haystack to find qualified data scientists with proper communication skills and general business sense.  Many of these recruits have their data science masters degrees and quite of few of them have their bachelors in some sort of business degree. Many others have engineering or statistical backgrounds.

I will often get a stack of dozens of resumes each with all the check marks crossed in terms of programming and courses but when I go to speak to the students it is a near disaster.  I ask them to explain very simple concepts and they often go off on 5 minute answers that are rambling and incoherent.  I need these candidates to be able to communicate across different sides of the business, often times with individuals that have little to no understanding of data science.  It almost feels like I need someone like the guy from office space that took the specs from engineers and handed them off to marketing or sales because the two sides couldn't communicate with each other.

**Q&A:** Has anyone run into similar difficulties?  How do you work with these candidates?   Do you hire them and then train their soft skills or do you only hire candidates with the full package?"
Best interview questions as interviewer? How to identify the best candidates,19,gdh074,datascience,13,"I lead a small data science team and we are currently recruiting the first more senior people since I started (got a couple trainees previously). We got some great candidates and are interviewing them this week. For the junior positions it was quite easy to interview: ability to learn, check if they know some basic concepts, do a bullshit detector on stuff they list they know. Now my candidates all have some experience, many are PhD's and I'm gonna need to utilize a different set of questions. 

People who have recruited data scientists, what are some great questions to find the best ones? Which questions are most relevant for somewhat experienced candidates compared to fresh ones?"
[MEME] The hierarchy of data science,414,gdf9l5,datascience,90,
How are you going to account for the 2020 pandemic in your future projects?,14,gd876c,datascience,9,"There are plenty of resources on Covid data. I am not interested in the disease numbers themselves but rather how these extraordinary circumstances are going to affect future predictions.

Have you run any simulations yet? How quickly are models going to recover assuming ""everything goes back to normal"" (as far as that is possible)? Do you think that the first half of 2020 is not going to be used for training? Or will that extreme time period benefit training if handled correctly?"
"Data scientists/analysts who moved to Pandas from Excel, what operations do you find can be done much more easily in Pandas than Excel.",56,gd3b41,datascience,44,"Hello everyone,

I have been working as a data analyst for about 3 years and about 2 years ago I switched to Pandas due to how much potential it had to improve my life: I am very bad at cataloging and record keeping, so doing things in Pandas makes everything so traceable and reproducible for me. Plus Excel always becomes super slow for me when the rows surpass 80K.

This week I will give my team members a quick demonstration of Pandas's capabilities. A lot of my team members use Excel for most of their data analysis, so I'd like to show them some handy operations that can be done by Pandas in much shorter time, hence improving our efficiency.

Several operations I have in mind are:

* The magic power of `unstack` to move columns into rows, usually accompanying `set_index()` and `groupby`.
* `df.duplicated()`, esp if I want to find the rows that have duplicate values in some columns, I can do `df[df.duplicated(['A', 'B'], keep=False)]`
* I always have to write a pretty long formula in Excel to find values in column A that is in or not in column B. I love how I can just do `df[~df.colA.isin(df1.colB)]`
* \`merge\` compared to `vlookup` or `indexmatch`

That's about what I have in mind right now. Some other operations like drop\_duplicates() or sum()  can be done not without too much effort in Excel. I don't think I need to talk about groupby() as we all use SQL on a regular basis.

Would anyone care to give me some additional examples please?

Thanks for your time in advance!"
Improving Presentation Skills,12,gd0wj9,datascience,13,"Hi everyone. Hope everyone is doing okay during these strange times. I have a few questions about presentation skills:

What kinds of presentation skills do you find most important to hone at work? What did you do to develop these skills? And finally, how do you deal with fear of public speaking? 

The latter is something I struggle with immensely. I spend a lot of time familiarizing myself with the topic I plan to present, organizing my materials so they “tell a story”, practice giving mock presentations and try to think of questions that the audience may ask. I feel comfortable with the knowledge, but find myself freezing up once I actually have to present. I’ve always struggled with performance anxiety. My heart starts pounding, my palms get sweaty, and I start getting tunnel vision. This seems to happen regardless of how much preparation I do.

Improving on this is one of my number 1 goals over the next year or so! If you have any advice or stories to share, please do!

EDIT: 

Thank you for the advice everyone! I already used some of the advice given here this morning for a mini presentation. I was still nervous, but the presentation went well overall and I feel better about it than I usually do! Baby steps, I suppose!"
What are the manipulation techniques any aspiring Data Science should master in Pandas as part of their daily workflow?,313,gczle5,datascience,74,I am a beginner-intermediate level Pandas user. Trying to prioritize the vast breadth of functions available for Pandas. What should an aspiring data scientist focus on for practicality's sake?
Has anyone successfully negotiated contingent compensation or performance-based pay in DS?,5,gcsx9g,datascience,5,"Some DS projects lead to cost savings, product innovations, process improvements and more for companies.  Their effects are also reasonably well-measured if performance is a KPI, and easy to measure conceptually in any case: take the integral of profit post-production less the integral of profit trend into future, ceteris paribus; it's even easier to measure if you A/B test.  Has anyone negotiated for contingent compensation or performance-based pay (I'm thinking 0.1-5% for a  <100 employee firm) for their work? Is this normal at senior levels (perhaps in addition or as opposed to equity)? Any tips (especially legalese) for doing so?"
Weekly Entering & Transitioning Thread | 03 May 2020 - 10 May 2020,8,gcpfwi,datascience,166,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Thoughts on MatPlotLib Python library vs Tableau data visualization?,125,gcnv6y,datascience,120,What are your opinions for using either? A lot of the times I avoid using Matplotlib because I can just display data faster with tableau (theres so much customization). And I end up writing less code as a result. In what use case will it be better to use Matplotlib instead?  3D models?
Leaving your datascientist position to create your own business - what are the key factor to succeed? what are the risks?,31,gcnojw,datascience,19,"I am working as a data scientists for a top strategy consulting firm. In overall, it is a decent job but I need to face reality, my company is not a tech company and I am bit concerned about the career path in the long term. Though the remuneration/benefits are good wrt to the data science market in my geography, I  feel that the analytics team members are somehow second class citizens wrt to the core consultants. They get huge bonus, we don t. They can make it to the partner level, we can't. 
The good thing about consulting is that you get exposed to a myriad of problems, so you get quickly get an idea of the needs of an industry. There are 2/3 use cases that come back frequently and honestly, the way we tackle these is pretty basic and leaves a lot of space for further improvement. Indeed, we are generally working on projects with very tight deadlines, pushing us to choose one-shot, quick-win approaches. As a consequence, we are constantly reinventing the wheel since most of the previous code base is too specific and can't be easily reused on a new project.
I am therefore sometimes thinking of leaving the company and create my own product. A better product that can be re used across use cases. 
I am therefore very interested to hear about similar experiences, to hear about people that have left their jobs to create their own business (ideally in the field of data science). Was it easy to find your clients? What are the key factors to succeed? What are the main risks (especially in these times of covid 19)? And how to survive  during the product development phase if there is no revenue flowing in?"
Passed TensorFlow Developer Certification,397,gc29zj,datascience,57,"Hi,

I have passed this week the [TensorFlow Developer Certificate](https://www.tensorflow.org/certificate) from Google. I could not find a lot of feedback here about people taking it so I am writing this post hoping it will help people who want to take it. 

The exam contains 5 problems to solve, part of the code is already written and you need to complete it.  It can last up to 5 hours, you need to upload your ID/Passport and take a picture using your webcam at the beginning, but no one is going to monitor what you do during those 5 hours. You do not need to book your exam beforehand, you can just pay and start right away. There is no restriction on what you can access to during the exam.

I strongly recommend you to take [Coursera's TensorFlow in Practice Specialization](https://www.coursera.org/specializations/tensorflow-in-practice) as the questions in the exam are similar to the exercises you can find in this course. I had previous experience with TensorFlow but anyone with a decent knowledge of Deep Learning and finishes the specialization should be capable of taking the exam.

I would say the big drawback of this exam is the fact you need to take it in Pycharm on your own laptop. I suggest you do the exercises from the Specialization using Pycharm if you haven't used it before (I didn't and lost time in the exam trying to get basic stuff working in Pycharm). I don't have GPU on my laptop and also lost time while waiting for training to be done (never more than \~10mins each time but it adds up), so if you can get GPU go for it! In my opinion it would have make more sense to do the exam in Google Colab... 

Last advice: for multiple questions the source comes from [TensorFlow Datasets](https://www.tensorflow.org/datasets), spend some time understanding the structure of the objects you get as a result from load\_data , it was not clear for me (and not very well documented either!), that's time saved during the exam.

I would be happy to answer other questions if you have some!"
Any data science jobs that are notably low-stress?,27,gc03ll,datascience,27," 

I've been a data scientist for about 5 years now. I like the math, the work, and the field itself, and feel good about my competency there. I am thinking about making a career change to a more relaxed job, preferably still in data science, but it seems all the jobs I see / scope out are pretty intense. I found this post [https://www.reddit.com/r/datascience/comments/b3gawa/what\_are\_good\_careers\_for\_shitty\_data\_scientists/](https://www.reddit.com/r/datascience/comments/b3gawa/what_are_good_careers_for_shitty_data_scientists/)   
but that poster has a bit of a different situation - I feel comfortable with my skills regarding data science, but I want a more relaxed life, rather than constantly meeting deadlines, working 50 hours a week, etc. Most analyst jobs I find will still have to deal with that.

Have any of you found any easygoing data scientist positions?"
Q: Opportunities that are only accessible through recruiters?,4,gbx8wu,datascience,7,So I know that recruiters are a middleman that get a nice fee if they direct you to a position and you are hired. Usually I've found that these recruiters are an unnecessary middleman for job positions that are accessible to the general public. But are there any cases where some companies hire exclusively through recruiters and don't post public listings/openings?
Any self taught data scientists in here?,251,gbmv7s,datascience,197,"I'm talking no CS, or Math background. You learned from just reading, tutorials, and or online courses etc.

Anyone in here completely change careers that got into Data Science from scratch?

Please share your story and your path.

Thanks"
Anyone else really demotivated by this sub?,364,gb4rdb,datascience,96,"I've been lurking here for the past few years. I feel especially lately the overall sentiment has gotten pretty dismal.

I know this is true for reddit in general, most subs are quite pessimistic and it leaves a bitter taste in one's mouth.

Or is it just me? I'm working in analytics, planning to get a DS (or maybe BI) job soon and everytime I come here, I leave thinking ""I really should just keep studying and stop reading reddit"".

I've been studying DS related things for the past 3 years. I know it's a difficult field to get into and succeed in, but it can't be this bad... posts here make it seem like you need 20 years of experience for an entry level job... and then you'll hate it anyway, because you'll just be making graphs in Excel (I'm being slightly hyperbolic). Seems like you need to be the best person in the building at everything and no one will appreciate it anyway."
Work repeatedly lied to me about ability to transition and now I'm stuck in a role I hate with a bad economy,148,gb41m8,datascience,48,"Hello everyone,

So a bit of backstory. I started in my current role roughly nine months ago. During the interview process I made it extremely clear I wanted a data science position (particularly one that involved a lot of machine learning) but the recruiter said there were no openings on data science. She and the others I talked with did say my role would primarily revolve around deploying models into production and not building pipelines and I could transition to data science once there became openings. I did have another full-time data science offer, however it was in a different city. Therefore, I was faced with a tough decision and based both on location and their 'promises' I chose my current role. 

However, in the first few months after starting I realized three things: (1) I wouldn't be deploying any models to production as the DS team had absolutely no models past the prototyping stage (and nine months later they still don't), (2) several others were brought onto the DS team right around when I started, (3) several of the people on DS including the DS lead seemed extremely weak in terms of actual machine learning knowledge. In retrospect this should have been a red-flag but I still hoped I could move off of data engineering and get into data science going. (Also, several of my previous roles had been on contracts, so I wanted to hold down a position for at least a year and not look like a job hopper.)

 Throughout Nov/Dec I tried unsuccessfully to get put on data science projects. This was particularly frustrating as I have expertise in several areas of modeling where the company is struggling. 

Moreover, they transferred several engineers with absolutely no DS background onto DS just because they apparently had nothing better to do with them. However, they kept promising my time would come. Finally, in Feb/Mar they brought me on to a couple of projects aimed at the knowledge graph, apparently because I was the only one in the entire organization with NLP experience. I was happy to work on that but they made it clear that my primary responsibilities for the time being were still data engineering. I asked them if they had plans to hire someone full time to data engineering so I could move over and they said yes. 

Now to the present. They tell me to stop all data science work because they want me 100% focused on data engineering. They come up with some flimsy excuse about the economy and DE needing to be my focus. They also make some references to needing to improve my data engineering performance. (My performance review was perfectly fine. Plus I made it clear to them when I was interviewing DE/ETL was not my strong suit.) Moreover, they still apparently have the resources to hire a full-time data scientist (WTF? they couldn't have hired another data engineer and transitioned me).The data science manager (who still hasn't produced one concrete ML deliverable) literally sits as the product owner of data engineering. At any point he could have prioritized hiring another data engineer so I could move over. I'm beyond frustrated that they have lied to me since day one. However, now the economy is bad and I can't quit outright. I have had  a couple interviews, but I have a number of thing working against me (bad economy, data engineering job title, short current job stay)."
"[DS Topic of the Week] What is real about Data Science, and what is just hype?",39,gb2d0f,datascience,39,"Welcome to the **DS Topic of the Week**!

This week's topic is **What parts of Data Science are real and what is just hype in industry?**

Data Science is growing rapidly and being widely adapted across industries.  While some of the techniques, technologies, concepts, and attitudes that make up sales pitches and mission statements are driving significant value, some of these are just buzzwords and hype.

So, what things are the real deal, and what are simply helping you ""Monetize your assets in order to holistically administrate exceptional synergy"" - (Source: Weird Al)"
Data Science/ML/AI small active discord community.,78,gaxlxq,datascience,19,"Hello, this is regarding a server, me and a couple of ds ml and ai enthusiasts created and we tried to create a small active community where students and practitioners can come together and help each other to grow on their respective path. If you are interested, you can join us:  [https://discord.gg/v3zeSGb](https://discord.gg/v3zeSGb)   


This server is 3 days old but we already have 80+ members. We plan on doing kaggle and other projects together and be better, together. :)"
Machine Learning Competition on Kaggle,39,gavciu,datascience,19,"I just started my data science journey through Kaggle  micro courses. In the machine learning competition I saw people in the top places having 0 mean absolute difference and 100 % correct predictions , how common is building a model like this in real life projects? , I was very shocked to see this for the first time because they are too accurate for being ""prediction""."
Is job progression really based on academic qualifications?,3,gau9gi,datascience,8,"I have a few questions about how your qualifications correlate with job progressions. To keep it simple, I'm only asking about when you have a relevant bachelors/relevant masters/ relevant PhD from a decent to great college. 

Is there any job progression ceilings you're bound to hit because you're ""underqualified""? Does a masters automatically push you to a higher role (and/or) pay than a bachelors? Does work experience done between your bachelors and masters automatically push you to a higher role (and/or) pay? Are there roles where not having a PhD automatically disqualifies you barring exceptional cases? If so, how common are these roles and are they more in FAANG companies or in top startups as well?"
"Has anyone here switched from a data scientist role for a data engineer role? If so, what was your motivation and did your career switch meet your expectations?",16,gappkq,datascience,12,"I'm currently getting more and more interested in switching out of data science to a more data engineering role and am not sure whether the switch is worth it.

I know there's a lot of overlap between the two so it's not the biggest career leap in the world, but I am looking to get some perspective on this from people who have made this journey before me. Thanks!

Edit: grammar"
Seeking Advice: My boss is not giving me enough time to do my analyses and is pressuring me with deadlines. What to do?,243,gap9nc,datascience,76,"I work as a data scientist at a medium-sized company (with \~200 employees). I've been with the company for a little over 4 months. My salary is $90K/year in a city where the cost of living is relatively cheap. (For perspective, $1200/month for 2-bedroom-2-bathroom apartment.) I have a BI analyst as my boss and I have another boss who's a BI director.

The BI team in our office is small. Just 3 of us in the office. The issue I have is that my bosses don't understand the complexity of running a valid analysis, which is forcing me to cut corners and produce sub-par quality work. Those sub-par quality analyses then get criticized by people in other departments (e.g. finance people, data scientists in other offices, etc.) and it makes me look like an idiot.

Don't get me wrong. My bosses are hardworking, smart people. They can write complex SQL code and make stunningly beautiful Tableau dashboards. However, they don't have any statistical background to properly design studies and go through the proper procedures to come to accurate conclusions. But they care too much about how beautiful the presentations must be (font, color, company branding, etc.) and meeting deadlines instead of focusing on the important stuffs, like valid experimental procedures and properly separating out correlation from causation.

I would say that the overall company culture is very healthy. The CEO is super transparent about the company matters. Everyone is very open and caring. The company sent a lot of care packages during the quarantine for the employees and they also host weekly fun company-wide activities. They give great medical and health benefits as well as PTO.

I thought about quitting because not having enough time and resources that I need to do my job is making me look incompetent. I haven't quit yet because:

1. I don't think many other companies are hiring amid this quarantine crisis,
2. I have a criminal background so I'm not sure if there is any other company that's willing to risk hiring me.

What should I do? At this rate, I'm gonna continue looking like an idiot and maybe I'll lose my job.

TLDR: My boss is not giving me enough time to do my analyses so I'm producing sub-par quality work. What should I do?

&#x200B;

UPDATE: Thank you so much to all of you who shared valuable feedback!! I feel so much better after reading all your comments than before. I will definitely bring the issue up with my manager and ask which corners she's comfortable cutting so she can pick and choose whatever is more important to the company. "
How to Find Data Science Jobs in Canada?,68,gahkqd,datascience,36,"Hi,

I need some advice from any data science practitioners in Canada.

Recently immigrated to Canada from a third world country and have 7 years of data science experience.

However, I am having trouble getting interviews here in Canada.

I am hearing you need Canadian Experience to land a job here so in a catch-22 situation right now!

Any tips of getting a data science job here?"
What virtual data science conferences are coming up?,3,ga82ef,datascience,4,Given the current circumstances I was wondering which virtual data science conferences are coming up in the next months. I'm particularly looking for conferences with a focus on women in data science. Any recommendations?
Worth being in digital advertising if outside of FB or Google?,2,gaa3bf,datascience,4,"I’m working at a digital advertising firm that was founded and has matured in the land of milk and honey over the last 10 years. 

It is a great company with competent leadership and great people. We’re handling the current episodes pretty well actually. 

Nevertheless what we do is optimize the use of FB’s and Google’s tools and platforms. I’m wondering if there’s a future in digital advertising for relatively small firms (we’re under 400) in the medium term. Though there is nuance to the situation, it feels like firms like mine are middle men between the platforms and the brands. 

Any thoughts?"
"How much of data science work tends to be for the sake of selling, rather than learning?",0,ga4ggw,datascience,8,"How much of data science work is doing:  
1) Stuff that ultimately amounts to Facebook's business model: taking people's data (in large part due to their addiction to your platform, product, etc.), learning things about them, and printing money with it due to targeted advertising.

2) Learning interesting/unexpected relationships between variables that are broadly applicable, insightful, fundamental to human/etc. behavior/the world?

3) Something else?"
Feeling stuck since one year at data science job. Need career advice.,207,ga23pe,datascience,128,"Pay: 80k. Medium col city YoE: 2.5

**TL;dr: DS job doesn't have ML/modelling work. Underpaid. Imposter syndrome kicking in. Want to switch jobs but afraid that I didn't build good experience to apply to bigger more challenging roles. Feeling stuck. Thinking of switching to swe since my statistics and ML growth hasn't been too good at current role. Need advice. More details below.**

I'm a data scientist, and I've been working on the same application for an year or two. I don't see it changing. Most of my experience has been writing spark code and  dev ops and cloud infra work for an application that we build. There's a bit of prototyping work here and there. And some business case development with upper management. The team is really small. And there are no senior members in the DS team. The only thing that I like about it is that I have positioned myself to become the most experienced person in the team on a product that we work on so i get to have a lot of say in the dev process.

I never go to do any ML or statistical modelling at this job. It was my first job after college, and I have severe imposter syndrome kicking in. So now I don't feel like a data scientist, and I'm becoming disillusioned with the field. My MS in data scientist is going to waste since I'm not using the ML and stats I learned. I am afraid to apply to other data science jobs since I feel that I will not be able to clear a DS interview round when it comes to describing what I've done with stats and ML and deep learning. I can study and practice sure but experience matters a lot, and if I don't have that, the only DS jobs I would be able to land in the future would be title inflated analyst roles.

I might switch to a software engineering role with maybe an ML focus because I fear I didn't build any relevant experience for the type of jobs that I want in DS but I have good experience and love writing python, plus coding in general. And I'm also tired of the lack of strong software dev practices in DS teams. I want to go somewhere where I can build things and code more than I do, with a more engineering focused team. Do you think DS jobs with actually challenging work will be harder to get into since I don't have modelling/ML experience?

My company is willing to start Green Card process, and then I'll be stuck here for a couple of years. At least my gc will process faster since processing dates for my nationality is current. It also makes staying at my current role more attractive since I don't know if newer companies would be willing to file GC straight away.

And then there is coronavirus.

Edit: thanks to everyone for their comments. It was a very valuable discussion."
What data do you commonly work with and who are you supporting (internal group wise)?,5,ga0aei,datascience,13,"Title says it all - had a huge realization today that data science isn’t necessarily operating in a think tank fashion but more of a supportive role, much akin to other back office functions."
Companies insourcing data analytics?,15,g9vudg,datascience,9,"So, in every investment portfolio of every VC fund, you'll find at least 3 big data, BI, Analytic platforms. Every single one of them seems to gain some sort of traction. There used to be this data euphoria.

But I recently read this article on the [McKinsey website](https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/why-data-culture-matters) citing some concerns about data outsourcing. In there, a new skepticism is described as well as a desire to insource most analytics.

Have you personally experienced this? Are your companies mainly in- or outsourcing their analytics needs? What problems arise when you try to insource analytics & BI?"
What are the options for mid-career online courses and certification?,102,g9m6n2,datascience,73,"I am a mid-career professional interested in moving into digital transformation/analytics consulting (e.g. BCG Gamma or McKinsey Digital) or digital transformation project management in big companies. I am finishing up my MBA in an M7 school and have basic knowledge about python and machine learning, and looking to upskill this recession.

1. What are some good online courses to better my data science skills/concepts (e.g. in python and machine learning)?
2. Are there any certifications recognised by the industry?"
Questionable choices in statistical python packages,11,g998gm,datascience,9,"Now to start off I am in no way saying these packages are bad, they are open source and I am thankful for wonderful free access. 

But I can't help but question some of the decisions made. For example linear models in sklearn use regularization by default when the main purpose of linear models is to learn the relationship between independent variables and dependent variables, prediction comes second. Or scipy ttest assuming homogeneity of variance between samples by default when that's hardly ever the case in the real world.

Why do you think these decisions were made by original developers?"
What coding bad practices did you find yourself having to make a particular effort to train out of yourself.,3,g976q0,datascience,10,"Particularly keen to know of what some common pitfalls are, especially as they relate to coding and software engineering!

As someone who does 75% of my coding in Jupyter Notebook it's not lost on me that I probably check a lot of boxes, I'm just trying to know what the most glaring offenders are to be conscientious of!"
Hiring in Data Science & Analytics,9,g96721,datascience,31,"Over the past couple of months and I’ve probably interviewed over 50 people for some roles that we are trying to fill.

This is my first position where I am part of the hiring committee. 

I’ve been absolutely floored by the amount of people who’s Job Titles do not match their skill sets at all.

I’ve interviewed some people who are Senior Level who cannot put together a coherent SQL statement and/or know basic functions. 

Which leads me to this question - do a lot of companies just throw Data Scientist/Analyst into someone’s title without knowing what the title/role entails?"
Looking to pick up an additional language - I want to hear your actual experiences,0,g92fg6,datascience,11,"Got my first job as a data analyst in 2010.  Between then and now, as a function of 1) me moving up in the ranks, 2) macro changes in the entire industry, my bread and butter software went from Excel -> SPSS -> SAS and SQL -> Python.

&#x200B;

Now, I'm trying to be proactive, and start learning one or two new languages.

&#x200B;

I'm not looking for a ""you should just learn X"" answer.  I want to hear some ""IF you learn X, you could do Y.""  I'm more interested in finding a Y I want to do, and then I'll just learn whatever X I need to be able to do it.

&#x200B;

For example, I've been toying around with the idea of learning JavaScript, actually, precisely since most data type people don't know it, and I'm thinking that if I could do some cool interactive or data vizs or web apps, that could distinguish me from my peers.  So if I want to do more reporting and communication, JavaScript maybe would be the way to go?  Anyone have an anecdote that would back that idea up, or knock that idea down?

&#x200B;

Alternatively, I'm thinking about R and Julia.  Right now, I'm a data analyst who only knows how to pandas.  So maybe if I want to go more the science route, I should pick up R or Julia?  (Or: I'm thinking being able to use Shiny and ggplot would let me do more interactives/viz, so have any Pythonistas out there had their life changed by the R, in that way?  Can you tell me about it?)

&#x200B;

I also just started learning bash and awk.  Any data analysis type folks (but not database admin or ETL or IT type folks), discover that learning shell scripting solved a real problem they were having?  Enough to the point that its worth it to learn well?

&#x200B;

You get the idea.  I'm not trying to crowdsource An Answer here, I'm just trying to crowdsource Some Cool Options To Consider.

&#x200B;

Thanks!"
Knowledge Repo equivalents for insight sharing?,1,g8we2d,datascience,2,"Hi guys,  
what are some alternatives to the knowledge repo developed by Airbnb in order to share data insights?   


At my job we are currently exploring tools to share insights between data scientists as well as external shareholders.  
Is there anything out there that you are satisfied with?"
Incognito mode for Data Scientist,385,g8vjx3,datascience,39,
"It's Meme Monday, so here's a python meme for DS folks",1749,g8v44c,datascience,87,
Any data analysts/scientists in capital firms? What do you do?,5,g8uh5j,datascience,0,"Just curious what kind of stuff people do in capital firms like PE, HF, and VC.

What do you do?
What was your path like?
Do you enjoy what you are doing?"
Any good resources for unit testing in a data science context?,12,g8s770,datascience,4,"I’m familiar with unit testing in a traditional software engineering context, but how do you you unit test for data science operations where your inputs might be dataframes? Do you just hard code a few edge case data frames? Any good articles / books / videos / code based that you would recommend to learn more about best practices?"
Critique/help with the MLOps plan for a small DS team,10,g8ojeg,datascience,11,"I work for a small (~4 person) data science team within a much larger organization. The team is responsible for making two machine learning models, creating a single set of very important predicted values, and creating reporting and data validation tools relevant to those predicted values. I came on board about 4 months ago with experience in data science, systems administration, and devops. I have a strong linux background and plenty of experience with Docker and Kubernetes. 

I've been asked to improve the existing modeling pipeline. I've come up with a plan that I think is feasible given the organization's goals and (considerable) constraints, but I'm hoping to get feedback on potential pitfalls or things to add from people with more ML/dev ops experience than myself. I also thought it might be fun for this sub to think through what the ideal toolchain might be given a pretty serious set of constraints.

## Goals

- Make our pipeline more robust. No more undetected data issues or breaking commits. Automatic unit and integration tests on all commits/merge requests.
- Improve pipeline transparency and reporting. Make summary and performance statistics about each model more easily available.
- Make testing and comparing new models significantly easier. More clearly tie new model results/objects to the code that produced them.
- Make the whole pipeline run continuously and automatically (given new data or other triggers).

## Constraints

- No cloud infrastructure. Everything has to be on-prem.
- Absolutely no additional money. Zero.
- Need to keep the developer toolchain as light as possible. It has to be usable by a team with limited devops/linux experience.
- Infrastructure can be (and is) linux + Docker based, but it has to be simple enough that if I die it's easy to understand and maintain for someone with a moderate devops background. For the same reason, all infrastructure setup has to be infrastructure as code.
- Any rebuild has to be done within 6 months of one person's full time work. This includes all infrastructure setup, code refactoring, CI/CD setup, and new code.
- The pipeline/modeling itself has to be written in R.

## Tools Available

- Hardware is limited to 2 beefy SQL servers, 2 beefy Ubuntu VMs, and ~6 beefy Windows workstations. 
- We recently upgraded to GitLab Silver for the whole organization and have all the features that go along with it.

## Current Setup

This is a relatively new team that had to get something up and running quickly, so they haven't yet had the time or resources to setup a mature ML pipeline or incorporate many devops best practices. However, they're committed to improving things and making the best system possible, hence why they asked for this plan. The current pipeline is:

1. **Data extraction/processing.** Data is stored entirely in SQL and feature engineering/data extraction is done via SQL views. The view definitions are stored in GitLab. There is one SQL server that is used for both reporting and modeling. Data extraction takes a *very* long time.

2. **Modeling.** The entire pipeline is written in R and is stored in a single, large GitLab repo. Scripts are manually triggered sequentially to run the actual pipeline and modeling. Data ingest/validation, modeling, model validation, and reporting are all roughly part of the same repo. This repo has no unit testing or integration testing.

3. **Reporting.** Reporting is done via R Markdown and a set of Shiny apps that exist separately from the main modeling repo. These reporting applications pull from the same SQL server as the main modeling scripts and report on the predicted values created in the modeling step. Model performance metrics are not available to the reporting apps.

Other notes:

- Intermediate data and model objects are not saved. The model specification and performance statistics of the best performing model are saved to an excel sheet. The predicted values produced by this model are saved back to SQL.

- Testing new models and/or functional forms is done manually by editing the main repo's R code. Model outputs are not tied to specific commits or branches.

## Planned Improvements

Given my constraints, I'd like to make the following improvements:

- Disaggregate the steps of the pipeline into discrete repositories/tasks that can be individually run, tested, and worked on. Add unit testing to each of these repos that runs automatically (via GitLab CI/CD). 
- Create an R package or packages that contains widely used functions and small datasets. Also add unit testing to these repos.
- Create a separate SQL server that mirrors the original server and is used exclusively for reporting.
- Use [DVC](https://dvc.org/) and [MinIO](https://min.io/) (running in Docker on a VM) to store the intermediate data produced by each step in the pipeline as well the final model objects. This is to prevent people from needing to constantly re-run the same data ingest scripts.
- Use DVC to define clear DAGs that automate the process of running the pipeline and collecting metrics on the results. Upload model metrics to a new table in SQL.
- Again use DVC to tie model output and data to specific commits and branches.
- Using the model summary metrics in both DVC and SQL, add some sort of reporting dashboard (Tableau, Shiny) that facilitates easy comparison of different models.

Those are my immediate thoughts for improvements, but I'm curious to get this sub's take as well. Additionally, I'd love to find an ML ops mentor if someone out there is willing to teach/talk.

**TL;DR:** You have 2 SQL servers, 2 VMs, a GitLab subscription, 0 money, and 1 person with linux experience. What's the most robust/transparent machine learning pipeline you can make?"
Weekly Entering & Transitioning Thread | 26 Apr 2020 - 03 May 2020,12,g8d5te,datascience,161,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Towards Data science articles quality are degrading,438,g8c7me,datascience,125,Most Towards Data science articles have become click bait articles. Do you agree?
How do I get out of data science?,324,g8250o,datascience,130,"Edit: Thanks for all the help and good ideas. I think I really just need more variety and (substantial) human interaction in my work. A couple mentioned they didn't have trouble going into systems engineers from data science, so I'll look into that. I work for a defense contractor that really focuses on IT implementations, and I think I want to get more into working with tangible products. So I don't know if I can quite do what I want without making a lateral move. I live right down the road from Raytheon and the ULA, so after all this blows over, I think I'll send my resume out. I'll also talk to my boss and see if I can shadow our company's product managers for a little while. I don't know a ton about that world but it does seem interesting. Thanks a ton! 

I've worked as a data scientist for a couple years now, and I'm really unhappy. I've worked at a start up and a large company. I'm well compensated but I've really grown to hate my career.

I'm tired of spending my days staring a computer. I'm tired of working for ""AI experts"" who couldn't import a Python module if their lives depended it. I'm tired of having to solve everyone's data problems and having my projects drag out for months. 

I've considered systems engineering and project management, but I don't feel like I have enough experience for that. 

What else can I do? I don't really want to go back to school because I hated college and honestly didn't do very well. Has anyone else made a transition out of data science?"
What’s data science like in the big tech companies like FAANG? How much theory is needed?,19,g8228z,datascience,19,I’m currently working in advertising research/analytics and am also about to finish up my first year in a stats MS program with a DS focus and noticing there is obviously a lot of theory in classes. One of my classes is a programming class in R which is both interesting and frustrating to me. I’m obviously gunning to eventually make a move to DS in a FAANG company and just wondering what I should be doing in the meantime.
Joined DS from different fields (or going to grad school for DS) - what misconception have you learned about the field?,0,g7v03d,datascience,10,"Notes

* Different fields can be from engineering, sciences, etc.
* School can be grad students

I think the title is clear enough - were your assumptions about the field correct? Were you disappointed? Were the people telling you about the field got it completely wrong? Has it helped in your current career? etc."
Should Students Put DS/ML Projects That Involve Games On Their Resume? Will They Be Taken Seriously?,94,g7u81k,datascience,39,"Hey r/datascience! I run a youtube channel applying machine learning concepts to online games like Runescape and Neopets. I’ve had a few students reach out to me wishing they’d have the time of day to work on projects like these but they are worried that the projects will not be taken as seriously as other projects would. It’s especially worrying during this pandemic with jobs being scarce and their future being uncertain which I can definitely empathize with.

That said, I wanted to ask professionals/students alike in this community a couple questions regarding projects that involve games:

1. In the context of hiring, are DS/ML projects that involve games as valid as projects that don’t involve games?
2. For side projects in general, how long would a typically good project take? Does the time frame really matter?
3. What do recruiters/managers look for to measure good understanding in these DS/ML projects?
4. If you’re a student, what would be your concerns with projects like these? 

I personally think that properly applying DS/ML principles in an end-to-end project would be a valid talking point in any context. However, I’m a little biased so I definitely wanted to see what people thought. Please let me know and thank you for your time!"
Hello! I create a subreddit for people applying to graduate programs in Data Science!,128,g7hzh2,datascience,42,"It is called r/DataScienceAdmissions ! Everyone is more than welcome, I would love if we could get some established data scientist to offer their advice :) Anyone who is considering applying to Data Science Programs is more than welcome!

I appreciate you all :)"
This sub is fucking garbage,333,g766dj,datascience,218,"This sub is fucking garbage. It's just random low-effort content that isn't interesting to professionals, people trying to market their garbage tool or total newbies asking questions with answers in any data science/machine learning/statistics book. They don't even bother to take a course or read a book before asking questions.

Compare it to /r/machinelearning where there is proper professional discussions (even though some of the content is academic in nature).

I'd much rather there be 3 interesting threads per week than 20 garbage low-effort threads in a week. There isn't even good content anymore, at least I can't find it because it's buried in ""Do I need this certification"" -> google ""reddit data science certification"" and there are pages upon pages of reddit threads from this very sub dozens of threads with the very same ""is X certificate useful/do I need certificates/what certificate should I get"" type of questions.

Half of the frontpage is just generic career advice and the other half is /r/askreddit styled ""what do you think of X"" questions where nothing of value ever comes up. It's fine if there is 2-3 less serious threads per week but jesus christ THEY'RE ALL GARBAGE.

I don't even bother lurking this sub that often anymore because I just know that there is nothing interesting or useful out there. It's just going to be garbage."
My line manager asked me to move a package I wrote in my spare time to under the companies name what should I do?,40,g75ysc,datascience,46,"Hi all, I'm looking for some advice. I recently wrote a package around data augmentation of images. The package has been deployed to PyPi and gained a small amount of interest. My line manager contacted me and asked if I was okay moving the package under the companies name citing ""outside of work interests must be reported"". The package does not use any of the companies IP nor does it compete with it. What should I do?"
Ambitions - Taking advantage of this time,6,g6jqm1,datascience,18,"You have ambitions. Probably you want to get a better job position at your company to gain more responsibilities earning more money or start your own business with new tools for Data Science. 

However, do you feel that you add things to your to-do lists and they never get done?  Do you feel like work is constantly piling up on you? Are you overwhelmed by an ever-growing ‘to do list’? Do you want to accomplish more?

Fortunately, now we have more free time than expected, what is keeping you from starting?

Let’s comment what are our goals and what are the obstacles we are constantly facing that prevent us from reaching our goals."
What are some intriguing data domains?,10,g6g0ei,datascience,8,"I'm researching big data use cases and I'm trying to figure out if more data science in the real world is needing to slice up data in a few known ways or if it's more like endlessly dissecting and iterating?

In my career I've only seen companies that are still working to collect and organize data and improve data quality such that a list of defined metrics might be generated.

I'm a little burnt out on that role and I'd appreciate your advice on some domains or industries that are generally past that stage and are into researching the nth dimension."
Version Control for Datasets?,6,g6e3kr,datascience,15,Heard some good things about DVC & aware of git. Curious to know what other good practises and tools exist out there
[DS Topic of the Week] What Technical Skills are in Demand for Data Scientists?,184,g69uv5,datascience,114,"Welcome to the **DS Topic of the Week**!

This week's topic is **What Technical Skills are in Demand for Data Scientists?**

While things like problem solving, ability to learn, and being a good communicator may be the most important overall skills for an effective data scientist, **this topic is intended for specific technical skills such as modeling techniques, languages, tools, and platforms** (e.g., PyTorch, BigQuery, NLP, Julia, BERT, SageMaker, Spark, etc).

This could be based on:

* What your team has been looking for in new hires
* Skills you have been developing internally due to need
* Searching for your next role"
What went wrong? How do you fix it?,10,g5r33i,datascience,8,"[I made a cartoon that is semi-autobiographical.](https://raw.githubusercontent.com/adamrossnelson/HelloWorld/master/sparefiles/DataScienceCartoon.png) I had in my mind that it illustrated a pretty specific issue (problem), cased by a specific behavior (mistake). But, the conversations I'm having around this cartoon are blowing my mind. So, I torn to Reddit. What went wrong here? How can it be fixed (or avoided)?"
Established Team or Wild West?,9,g5pu5w,datascience,15,"I have recently accepted an offer but current employer expressed interest to retain. Just want to pick some brains to see how people choose between a mature team and a brand new team.

First of all both are large companies that are not directly impacted by the disease.

My current team is very resourceful. I work with a group of PhD and masters, who are all extremely bright and have a lot I can learn from. I picked up a ton of knowledge just from being exposed to their work. 

The new offer I received is for a brand new ""data analytics"" team. There are a lot of potential for legitimate data science projects but the team is about .5 - 1 year away from having the right infrastructure (proper data warehouse, tooling, and culture).  Once that's fulfilled, the bulk of work will be in BI, with areas enhanced by machine learning.

&#x200B;

I guess I've been the dumbest person on the team for a while and it's time to branch out and try things on my own? With my current team, I don't get R&D project and to be honest, I constantly feel the problems we're solving (deep learning, NLP) are too difficult for me. A big part of my work is in deploying and executing models, so they are software engineering-heavy in nature as oppose to business-related (which I prefer more).

With the new team, I have more say on directions and the type of projects the team should be doing. There will be more chances of identifying business opportunities and implementing a solution. The work seems to be more inclined to using traditional ML methods, which I'm more familiar with, but I'm certain I'll be fighting politics, budget, and maybe even struggling to come up with impactful ML solutions.  

&#x200B;

I'm really interested in hearing from people who left an established team for a relatively new team and how their experiences are or just the pros and cons for working for these two types of teams."
How to improve coding skills for data science projects,304,g5nqks,datascience,55,"I'm currently a PhD student. I mostly write in Python, creating deep learning models. I think my coding skills are good, and I've definitely improved a lot, but there is always more to learn!

I think a place I could improve is how my projects are structured, where my input and output data is stored, readability, things like that. I thought maybe to get the book Reafactoring by Fowler, does anyone have any opinions on that?

Is there any other good resources people can recommend? I'm also generally interested in other thing I can do to improve my code. What are things you think people could generally improve upon? Ideally, I would like to be able to produce readable code that is structured in a sensible way, that won't annoy other people if they have to use it.

Thanks!"
Is this r/datascience or r/machinelearning,112,g56zs3,datascience,85,
Does my current salary seem appropriate for my location & experience?,0,g54gnx,datascience,31,"I'm a Data Scientist in San Francisco, with a base salary of 150k. My company is a private mid-sized tech company, but not that well-known, so my equity doesn't seem to matter in counting.

For some context, I have under 2 years of experience working as a Data Scientist. I have a Masters and Bachelor's degree in pretty well-known schools, but these degrees aren't actually in data science or software engineering. I came into the workforce basically straight out of Master's. I would say I'm pretty proficient in ML, SQL, and Python, but my understanding of model deployment and cloud architecture is weak since I don't have an engineering degree. My strength is in analytics, business insights, and communication with external stakeholders (somewhat like sales).  

My day to day responsibilities runs wide, since it's not a big company. It's everything from data analysis, model training, A/B testing, dashboarding, etc.

Based on the above information, I'm wondering if my current base salary sounds appropriate to what what I am performing and where I'm located? Someone asked this question in cscareers subreddit, and I wanted to ask the same thing.

The reason I ask is due to what my peers seem to be making around the area. Buddies of mine from FANG are pretty vocal about making 250k straight out of college (of course, a lot of that comes from equity, but does it really matter?). I'm pretty content with my current company (our work hours are really good, like 9-5 without much stress). 

But I'm constantly wondering if I'm making too little and that I should be aiming toward 200k now that I'm reaching toward almost 2 years of experience."
are you worried about having a data job after 50 or 60 years old?,31,g4yn0l,datascience,13,"I had a long IT career, switched over to data engineering, and aiming to eventually get into modeling or machine learning. 

Assuming I get there, I am wondering what the job market will be like. I'm 45 now. Wherever I end up, should I be worried about looking for jobs as I get older? 

I never had to worry about finding jobs before. I have strong technical experience but only academic modeling experience. Now I'm wondering how easy that will be, due to my age. 

Maybe I need to start my own business so I don't have to do interviews anymore."
Tell me why I should learn SQL (a little bit of a rant),0,g4w6ax,datascience,45,"TLDR is at the bottom,

Some background first, I've been working for almost two years as a Junior Data Scientist at a small IoT startup in Massachusetts doing mostly big data analysis with Apache Spark, and ML research/deployment with Amazon SageMaker. With the pandemic going on, and the market the way it is, not many investors are looking to fund new rounds right now, so things are getting pretty tight. Fortunately for me, the executive team is very transparent and let me know it might be time to start looking for something more stable for the time being.

Since then I've had more than a few technical interviews, and a lot of them haven't gone very well, mainly because my SQL skills are extremely basic at best. This isn't a problem at my current company because I use Apache PySpark for everything, I run it on an EMR cluster and it's usually faster than traditional SQL. I usually try to explain Spark to potential employers when they ask me about my SQL skills, but their response is usually like ""ok great, now solve this complex SQL problem anyway"".

In my opinion, PySpark is a faster alternative to raw SQL. I feel a bit frustrated because I feel like employers don't care or believe that I'm just as effective as someone with strong SQL skills.

TLDR:

Why should I learn what in my opinion is a slower alternative (SQL) to a tool I am already skilled with (PySpark)?

Am I wrong to believe I'm as effective as someone who is strong with SQL?

Why do employers insist that I must be skilled with SQL to be a good Data Scientist, even if I explain Apache Spark to them?

# Common Responses:

Really all the responses are in one of three bins

1. You need to learn SQL so you can (\*insert thing you use SQL to do\*)

My response is that I don't, I can use Spark to do almost any SQL task.

2. Just learn SQL it's easy

Yeah, It looks like I'm going to need to do this, but it doesn't really answer my question.

3. People working on a team should all use the same technology for peer review, and so others can pick up where one left off if they leave, plus other reasons. (\*insert harsh sarcasm implying I want everyont on a potential team to switch from SQL to Spark\*)

I come from a collaborative team of scientists who use a variety of tech, from my perspective it seemed reasonable to have a team where not everyone uses the same technology. I guess this is more of a unique case than I was aware of and most companies only hire people who can use the same tech as the team they would be working on. This makes sense to me, I just didn't think it was as obvious/required as others are suggessting.

&#x200B;"
The next time my coworkers ask what metrics I used for my model.,1800,g4jc29,datascience,66,
Are DS jobs at higher risks of being made redundant due to the current epidemic?,8,g4j9f0,datascience,28,"I got an email from top management with regards to the layoffs (""restructuring"" they call it) due to the epidemic and mostly came from sales and services, but also some parts of the tech devision.

From your experience or POV, is DS at a higher risks of being made redundant for the current climate?"
When do you know to give up?,48,g4elcd,datascience,37,"* This is not technical. 
I did a master in physics with focus on observational astrophysics where I did mostly data analysis and a simulation, due to circumstances decided not to pursue PhD and instead go to data science. 
After doing a “software development boot camp “  i got a job as data engineer, my boss was a data engineer himself and he gave me an option; he could teach me and be kinda my mentor which I accepted of course. Because if I eventually go into data science, having a background in data engineering only helps. 
I lost that job few weeks ago after 5 months due to corona crisis. 
I’ve been applying and I’m getting interviews much more than I used to but they’re not going anywhere so far. I looked into data science/machine learning master programs and earliest I could start would be September 2021. 
I am not sure how long I should fill this goal logically, I love working with data but there’s a point one should give up and move on realistically. 

Do you have any advise? I’m 31 f and starting over in a new country. I’m willing to work hard but I don’t want to follow pipe dreams."
Weekly Entering & Transitioning Thread | 19 Apr 2020 - 26 Apr 2020,48,g46k9c,datascience,208,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Open source/community edition dashboard tool that can integrate with spark and has a web interface,81,g3i4cj,datascience,24,Does anyone know of a drag and drop one like tableau I saw that I could use dash but I wasn't interested in doing the html portion of the dashboard. I also need a web interface.
Has COVID-19 reshaped/tweaked the data science problems you are solving?,22,g3gwbv,datascience,28,Wondering if companies need data science more than ever to understand the impact of COVID19 on their business? Are the models from the past any good going into the new age?
"I am both Data Scientist / Engineer, was this a bad move?",163,g2yd94,datascience,67,"Our departments are split with the CTO running front/back-end and the Chief Data Scientist. I currently work under the CDS. The CTO needs a dedicated Data Engineer and I've maintained and optimised our current databases and ETL pipelines.   


This is a big step up, and A LOT of work. It, however, really solidifies my dependency at the company ( i was worried I would become redundant.)   


I don't think they realise the amount of time-management and prioritising is needed to schedule DS projects and DE projects and to work side-by-side, however, I could just be new to the responsibility.  


Is there anyone who is in the same position, and if so, how difficult is this track? Should I ask for a raise given the double responsibility?   


I wish you all well and stay healthy!"
"From your experience, how has data science changed in the past 7-8 years?",61,g2k5zi,datascience,42,"I've seen a lot of ""predictive"" posts on ""where do you see data science going in 10 years?"" on this sub.

But I'm actually curious about the *retrospective* end of the question. So to those who have been in the industry for a while, from your experience how has data science changed in the past 7-8 years or so?"
Is my B.S. in Biostatistics making data analyst hiring managers ignore me because they think I'm only specialized for healthcare?,198,g2hoyc,datascience,123,"I've applied to about 100 jobs with no call backs yet. My only opportunity right now is a job to where a recruiter reached out to me on linkedin. Any advice?

EDIT: I just graduated and I do have a data science internship under my belt with a large healthcare system that included typical data cleaning in sql and machine learning in R. The degree was basically a traditional stat major with 4 elective slots swapped for intro level bio classes. I'm fluent in R and sql too

EDIT2: here is my resume https://imgur.com/a/2RtGPlP, formatting is messed up just from making it anonymous

EDIT3: Just wanted to say thank you to all of you. I was not expecting to get this much advice and I'm feeling a lot better going forward"
Mathematical Proof That No Decision-making Algorithm Can Be Completely Fair,10,g2f68k,datascience,8,"I few months ago, when listening to a data science podcast, I came across a notion that there have been papers published demonstrating a mathematical paradox related to algorithmic fairness. The gist was that there a three characteristics that we would ideally like a decision-making algorithm to embody, yet it can be proven mathematically that these can't be simultaneously satisfied—there is always a trade-off. I believe that two of these characteristics were false-positive and false-negative rate but I'm not even sure of that. Is there anyone familiar with this topic that could point me towards the paper? I've lost the original podcast episode and Googling has got me nowhere."
FAANG Data Scientist -> Software Engineer?,5,g23gw3,datascience,21,"I'm currently a data scientist at a big tech company, about 2 years in after a career change in my mid 20s. My current job is about as close to my dream job as it gets. I work on interesting problems and I genuinely enjoy the work. I'm concerned about my career path and am considering switching to software engineer for a few reasons:

1. I only have a bachelor's degree. It's a **solid** bachelors degree (computer science and stats from an ivy), but a bachelor nonetheless. Literally every data science manager i can think of has at least a master's. I'm confident that I *could* make progress at my current company, but at places like google they won't even hire a data scientist without a masters. I'm paying down lots of student debt right now and couldn't dream of going another 100k in the hole. From what I can tell, software engineering doesn't have this hard education cutoff.
2. I write next to no production code. I crank out analyses using jupyter notebooks and SQL like my hair is on fire, but only my final recommendations are seen. Combining this with a recent influx of MBAs into the field, I worry that I'm on track to a not-so-technical career path. Like consultant or something. Not necessarily bad, but I fell in love with writing code before I was a data scientist.
3. The big advances in analytics seem to be coming from building platforms, services, etc. I think I'm naturally inclined to build things and I enjoy this kind of work. Down the road, the combination of these two kinds of data science (business-focus and engineering-focused ) would give me a huge leg up.

Should I make the jump? I'm in my early 30s and I'm just not jazzed about dropping a mortgage down payment for another degree just for the ability to advance. I'd rather leverage what I've learned as a data scientist as a leg up on a career path that doesn't have the same barrier to entry.

Thanks in advance!"
100-days Data Science Challenge!,478,g20x47,datascience,67,"One month ago I made [this post](https://www.reddit.com/r/datascience/comments/fisj71/from_economics_to_data_science/) about starting my curriculum for DS/ML and got lots of great advice, suggestions, and feedback. Through this month I have not skipped a single day and I plan to continue my streak for 100 days. Also, I made some changes in my ""curriculum"" and wanted to provide some updates and feedback on my experience. There's tons of information and resources out there and it's really easy to get overwhelmed (Which I did before I came up with this plan), so maybe this can help others to organize better and get started.

&#x200B;

**Math:**

* Linear Algebra:
   * Udemy course:  [Become a Linear Algebra Master](https://www.udemy.com/course/linear-algebra-course/)
   * Book: [Linear Algebra Done Right](https://www.amazon.com/Linear-Algebra-Right-Undergraduate-Mathematics-ebook/dp/B00PULZWPC)
   * YouTube: [Essence of linear algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)

I've been doing exercises from the book mainly but the Udemy course helps to explain some topics which seem confusing in the book. 3Blue1Brown YT is a great supplement as it helps to visualize all the concepts which are massive for understanding topics and application of the Linear algebra. I'm through 2/3 of the class and it already helps a lot with statistics part so it's must-do if you have not learned linear algebra before  


* **Statistical Learning**
   * Book: [An Introduction to Statistical Learning with Application in R](http://faculty.marshall.usc.edu/gareth-james/ISL/data.html)
   * YouTube 1: [Data Science Analytics](https://www.youtube.com/channel/UCB2p-jaoolkv0h22m4I9l9Q/videos)
   * YouTube 2: [StatQuest](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw)

ITSL is a great introductory book and I'm halfway through. Well explained with great examples, lab works and exercises. The book uses R but as a part of python practice, I'm reproducing all the lab works and exercises in Python. Usually, it's challenging but I learn way more doing this. (If you'll need python codes for this book's lab works let me know and I can share) The DSA YT channel just follows the ITSL chapter by chapter so it's a great way to read the book make notes and watch their videos simultaneously. StatQuest is an alternative YT channel that explains ML concepts clearly. After I'm done with ITSL I plan to continue with a more [advanced book from the same authors](https://web.stanford.edu/~hastie/ElemStatLearn/)  


**Programming**:

* I use the Dataquest Data Science path and usually, I do one-two missions per day. The program is well-structured and gives what you will need at the job, but has a small number of exercises. So when you learn something it's a good idea to get some data and practice on it. 
* Udemy: [Machine Learning A-Z](https://www.udemy.com/course/machinelearning/learn/lecture/6453704?start=0#overview)
   * I use their videos after I finish the chapter in ITSL to see how t code regressions etc. But their explanation of statistics behind models is limited and vague. Anyway, a good tutorial for coding
* Book: [Think Python](https://www.amazon.com/Think-Python-Like-Computer-Scientist-ebook/dp/B018UXJ9EQ/ref=sr_1_1?crid=2NDPR8R8GRQ8N&dchild=1&keywords=think+python&qid=1586982845&s=digital-text&sprefix=think+python%2Cdigital-text%2C139&sr=1-1)
   * Good intro book in python. I know the majority of concepts from this book but exercises are sweet and here and there I encounter some new topic.
* Leetcode/Hackerrank
   * Mainly for SQL practice. I spend around 40 minutes to 1 hour per day (usually 5 days per week). I can solve 70-80% of easy questions on my own. Plan to move to mediums when I'm done with Dataquest specialization.
* Projects:
   * Nothin massive yet. Mainly trying to collect, clean and organize data. Lots of you suggested getting really good at it, as usual, that's what entry-level analysts do so here I am. After a couple of days, I'm returning to my previous code to see where I can make my code more readable. Where I can replace lines of code with function not to be redundant and make more reusable code. And of course, asking for feedback. It amazes me how completely unknown people can take their time to give you comprehensive and thorough feedback! 

&#x200B;

I spend 4-5 hours minimum every day on the listed activities. I'm recording time when I actually study because it helps me to reduce the noise (scrolling on Reddit, FB, Linkedin, etc.). I'm doing 25-minute cycles (25 minutes uninterrupted study than a 5-minute break). At the end of the day, I'm writing a summary of what I learned during that day and what is the plan for the next day. These practices help a lot to stay organized and really stick to the plan. On the lazy days, I'm just reminding myself how bad I will feel If I skip the day and break the streak and how much gratification I will receive If I complete the challenge. That keeps me motivated. Plus material is really captivating for me and that's another stimulus. 

What can be a good way to improve my coding, stats or math? any books, courses, or practice will you recommend continuing my journey?

Any questions, suggestions, and feedback are welcome and encouraged! :D"
How to get real meaning from clustering analysis?,14,g1yrv7,datascience,32,"Hi folks,

I've been looking at Clustering with Kmeans in SciKit Learn. I've produced a workbook and got everything to work with a pretty graph and decent metrics. If anyone wants the detail, code is at [https://github.com/michaelf736/Unsupervised-learning-with-Kmeans](https://github.com/michaelf736/Unsupervised-learning-with-Kmeans) 

My question is, how do I interpret this in the real world? My boss is going to say, 'great but what does that tell me about how I should run the business?' and to be honest, I haven't got a clue.

My dataset has 8 features, which I reduced to 3D in order to make the analysis work. However, that leaves me with a 3D scatter plot that looks nice but I can't relate it back to the 8 features I started with.

Can anyone help me with this or point me in the right direction please?

Thank you :-)"
Is BERT too general for an NLP project with a very limited corpus with very specific contexts?,62,g1suaz,datascience,22,"I am working as a Machine Learning dev on an NLP project in the Aerospace industry. To give professional context, prior to this most of my ML work so far has been with structured numerical, ordinal, or categorical data from 3D simulations & video games and NLP is somewhat new to me. 

Specifically the goal is the following

1. Users take a picture of standardized work specifications with a custom app on their phones and then an OCR technology recognizes the text in the picture. (The OCR tech is already working)
2. A custom NLP tech classifies the text in the picture into specific classes and then populates a form in the app with the recognized text.

I am working on the NLP side and trying to decide which word embedding to use. The corpus for this project have meanings that are very specific to an Aerospace context (for example ""ceiling"" would relate to almost exclusively to the maximum altitude of an aircraft and NOT walls/floor/etc. ) and the amount of unique words on the work orders is likely no more than 2500-4000.

BERT's bidirectional approach seems like it would lead in general to accurate understanding of context, but I'm wondering if the pre-trained BERT models would be far too general an application like this where the context is ultra-specific.

My questions specifically are

1. Would a pre-trained BERT model be likely to overgeneralize here? 
2. Would training a BERT model from scratch (likely to do NER) be overkill? Would a simpler model be better here?"
[DS Topic of the Week] Should Data Science Managers/Leads have a Data Science background?,20,g17928,datascience,23,"Welcome to the **DS Topic of the Week**!  

This week's topic is **Should Data Science Managers/Leads have a Data Science background?**

>While data science practitioners can come from diverse set of technical backgrounds, the people who manage teams of data scientists can come from both technical and non-technical backgrounds.  
>  
>Do you feel that having a technical background is important for these managers?  Alternatively, do overly technical managers tend to lack the non-technical soft skills to being an effective manager?  
>  
>Given the choice, what kind of background would you want your next manager to have?  Does the size and composition of the team make a difference?

&#x200B;

***Note:*** *The mod team is trying something new here, which is a rotating weekly topic/debate for discussion.  We will hopefully have this automated soon, if feedback is positive.*"
20 Best Libraries for Data Science in R,959,g12zmd,datascience,87,
Build an efficient recommendation system in R using apriori. Code included (both R & Python),24,g12g3b,datascience,5,"Step by step guide to build an information filtering engine called recommendation system. Downloadable code included for R & Python.

This page is purely technical. If you would like to read some basics of recommendation system. Click [here](https://medium.com/@karthik.thandapani/a-beginners-guide-to-understanding-recommendation-system-f6c0054dfb7c?source=friends_link&sk=70c9b7177a1e731b3c742aca26ae22e7)

# Intuition

Once upon a time, there was a task given (this was a decade back when excel & vlookup were the 2 of 3 famous terms in the world of analytics).  
As the story goes… this was for a retail industry, we did some analytics around the products that customers are purchasing. 1. What are the products they are looking at & searching? 2. What are the commonalities, pattern, segmentation etc etc.  
End of the day, we had to analyse hundreds of thousands of transactions; thousands of people, their purchase and invoices;

We found an interesting pattern happening very often. When people shop in the evening between 6 and 9. **Customers who buy diapers also buy beer**.

&#x200B;

https://preview.redd.it/syeee0ym4rs41.png?width=1081&format=png&auto=webp&s=80befea480ce0ec2391ebfdbed336a776433e30b

But, this insight was like out of the blue completely as these 2 products are completely not connected.  
***Why would somebody buy beer when they’re buying diapers or why buy diapers when they’re buying beer!!!***  
So that was the fact we came across in the data and the explanations as fact. **One of the plausible explanations we gave;** In the evenings, when the husband gets home and when they take care of their baby; they sometimes find that they run out of diapers and who has to go pick up the diapers.. well, the husband. The wife sends husband to go pick up the diapers and **while he is picking up the diapers because its already after work hours, he also picks up some beer. Right.**

And this plausible explanation might be logical or not be. This is something you can’t really think of it just by yourself but that comes from the data.

As I’ve highlighted this in my previous [***post***](https://medium.com/@karthik.thandapani/a-beginners-guide-to-understanding-recommendation-system-f6c0054dfb7c?source=friends_link&sk=70c9b7177a1e731b3c742aca26ae22e7), based on certain insights derived from data; a supermarket or retail industry can decide how to arrange products in your shelf **whether you run an e-commerce store to rank & show your products in your virtual shelf or a superstore to put these 2 products to entice people while shopping.**

So there is a lot of interesting marketing tactics that are using based on this data. But the question is; how do you get to this data?

>*You may read :*[*A beginner’s guide to understanding recommendation system*](https://medium.com/@karthik.thandapani/a-beginners-guide-to-understanding-recommendation-system-f6c0054dfb7c?source=friends_link&sk=70c9b7177a1e731b3c742aca26ae22e7)

**And one of the ways to get to it is leveraging analytics use apriori algorithm.**

&#x200B;

https://preview.redd.it/s8omtg1s4rs41.png?width=892&format=png&auto=webp&s=b0c636afa4201f6f81484f1eebd8224e123e7f8e

# Problem Statement

When we go grocery shopping, we often have a standard list of things to buy. Each shopper has a distinctive list, depending on one’s needs and preferences. A housewife might buy healthy ingredients for a family dinner, while a bachelor might buy beer and chips. Understanding these buying patterns can help to increase sales in several ways. If there is a pair of items, X and Y, that are frequently bought together:  
*Both X and Y can be placed on the same shelf, so that buyers of one item would be prompted to buy the other.*  
*Promotional discounts could be applied to just one out of the two items.*  
*Advertisements on X could be targeted at buyers who purchase Y.*  
*X and Y could be combined into a new product, such as having Y in flavors of X.*

Association rules are “if-then rules” with two measures which quantify the support and confidence of the rule for a given data set. Having their origin in market basket analysis, association rules are now one of the most popular tools in data mining. This popularity is to a large part due to the availability of efficient algorithms. The first and arguably most influential algorithm for efficient association rule discovery is Apriori.

**Besides increasing sales profits, association rules can also be used in other fields. In medical diagnosis for instance, understanding which symptoms tend to co-morbid can help to improve patient care and medicine prescription.**  
Folks from healthcare industry, are you reading this ?

# Definition

Association rules analysis is a technique to uncover how items are associated to each other. There are three common ways to measure association.

1. **Support:**  
This says how popular an itemset is, as measured by the proportion of transactions in which an itemset appears. In Table 1 below, the support of {apple} is 4 out of 8, or 50%. Itemsets can also contain multiple items. For instance, the support of {apple, beer, rice} is 2 out of 8, or 25%.

&#x200B;

[image KD nuggets](https://preview.redd.it/ecsl15nw4rs41.png?width=503&format=png&auto=webp&s=5310d5b9c688b944b938d8dbbef0029167781157)

2. **2. Confidence:**  
This will highlight how likely item Y is purchased when item X is purchased, expressed as {X -> Y}. This is measured by the proportion of transactions with item X, in which item Y also appears. In diagram below, the confidence of {apple -> beer} is 3 out of 4, or 75%.

&#x200B;

https://preview.redd.it/3h2hccty4rs41.png?width=527&format=png&auto=webp&s=d295d99297f9b7e0f21c17062d3c4b53a1f63e43

**3. Lift:**  
Table below how likely item Y is purchased when item X is purchased, while controlling for how popular item Y is. In diagram below, the lift of {apple -> beer} is 1,which implies no association between items. A lift value greater than 1 means that item Y is likely to be bought if item X is bought, while a value less than 1 means that item Y is unlikely to be bought if item X is bought.

&#x200B;

https://preview.redd.it/ko7fjsg35rs41.png?width=566&format=png&auto=webp&s=50b3cdf0cb7497a5043dcbe689c40a61c0096db6

**Association Rule Mining**  
Now that we understand how to quantify the importance of association of products within an itemset, the next step is to generate rules from the entire list of items and identify the most important ones. This is not as simple as it might sound. Supermarkets will have hundred of thousands of different products in store. After some simple calculations, it can be shown that just 10 products will lead to 57000 rules!! And this number increases exponentially with the increase in number of items.  
Finding lift values for each of these will get computationally very very expensive. How to deal with this problem? How to come up with a set of most important association rules to be considered? Apriori algorithm comes to our rescue for this.

**Lets build an efficient recommendation system in R studio**

1. Load data
2. Install apriori
3. Data pre-processing | Decode sparse matrix | Plot
4. Train & Test
5. Visualize

In this example, we will work on a sample dataset from a grocery store, understand the business problem, and ways to optimize the sales using apriori algorithm leveraging machine learning.

Link to full article is [here](https://medium.com/@karthik.thandapani/build-an-efficient-recommendation-system-in-r-using-apriori-98ae21d4433a).

&#x200B;

[https:\/\/github.com\/thecodemasterk\/download\_apriori](https://preview.redd.it/fd8882u95rs41.png?width=467&format=png&auto=webp&s=20474b9ec1e57e654517cfc6a703b1703f2cb45c)"
How has COVID-19 affected the job market for data science so far?,16,g0ogmu,datascience,24,"Have you experienced more difficulties in getting a job?  Less openings?

What is your advice for someone looking for a junior position in this climate? Is 3 month a realistic timeline for getting an offer?

&#x200B;

Thanks"
Machine Learning Workflows Solutions,8,g0n8v1,datascience,4,"Currently, i'm tracking all my machine learning experiments by logging the parameters and the evaluation metrics. I now have a need for a more dynamic solution to track workflows and experimentations. I found Kubeflow which seems to be great at first glance, but I wanted to ask what the community uses to track machine learning experimentations?"
Numpy,467,g0iwnm,datascience,159,
Uncomfortable as data scientist: looking for guidance,95,g0is1r,datascience,38,"This may not be a super structured post, but I just want to get something off my chest: I'm 24 years old, and around 6 months ago I joined as a data scientist at a consulting firm (for people who care, MBB) and I am extremely uncomfortable in my position. I simply feel like I don't know enough, and that I never will.. At the same time, I find the work very rewarding and technically interesting, and I definitely want to stay in the field. This leads to the realization that if I am to stay in the field, I should find ways to deal with this discomfort. Maybe you guys can help me..

I have a background in aerospace engineering, and got into the field by basically doing self study (understanding the math behind most basic algorithms, applying them to Kaggle problems, and getting as good as possible in Python). I interned as a data scientist where I basically did nothing academic (sort of a real-life Kaggle competition to be honest), and through some luck ended up in the position I am in now.

Fueled by imposter syndrome, I tend to spend most of my free time (weekends mainly) doing self study and trying to learn more. I am not doing this because I **have** to, I am genuinely interested in the field. However, it feels like there is so much to learn and it is starting to get to me.

To give some context, I have never done anything related to neural networks. I kind of know how it works on a high level and I know what backpropagation is and the math behind it, but I have never actually coded up any sort of deep learning model. I am definitely not comfortable in using it in my daily work.

I also don't know anything about Bayesian statistics. I have spent the last week or so going through numerous sources and am now comfortable with the idea of priors, likelihood functions, how to update the posterior, and various ways of finding the posterior (grid approximation/quadrature/MCMC). But again, I have never actually used it so I don't feel like I actually am capable of using it in my day-to-day work.

Just today I learned about the existence of Generalized Linear Models, and it is as if suddenly I am confronted with yet another beast which I had no idea existed. But guess what: if I truly want to be a good at what I do and be a master in my field, I have to learn this as well. And at this point, I don't even really know what it means.

I guess my general question is: how do you guys deal with this situation? There are seemingly infinite things to learn about, and then each of those things can be learned to an arbitrary level of detail. How do you pick what to learn/focus on, and how do you decide that ""enough is enough?"".

Also, how do you decide if something you learned off-the-job is useful in your daily work? Having conceptual understanding is one thing, but actually applying it requires quite a leap of faith in knowing what you know."
"Been perpetually baffled ever since stepping into the field as to why Matplotlib is considered a staple for DS in Python, beyond very basic EDA. Matplotlib experts - do help shed some light!",11,g0ijxj,datascience,16,"While I've found myself using Python *extensively* for all kinds of Data Cleaning, machine learning, and a number of other more software engineering-related things, visualization is one thing I find myself resorting to much easier options for. 

Beyond very elementary data visualization during EDA stages that serves just to paint a clearer picture in my mind of what a physical representation of my data might look like, I'm pretty stumped as to what more matplotlib offers. Does it really bring something to the table that not only makes it worth the trouble of trying to learn it properly despite its unintuitive rules, but also makes it superior to other options that are plain easier and less time consuming?

I'm not dense enough to think that people who take the time to get extremely good at it don't have their reasons - I'm just really eager to learn what those are. Just came out of a stackoverflow exchange thinking ""how on EARTH could that dude have known precisely that"", so now left curious as to what the motivating factor is for matplotlib virtuosos."
How do you deal with forgetting?,39,g0ht0j,datascience,21,"Data Sci undergraduate here. Dabbled in

\- theory behind modellling - regression & classification, basic NN mathematics

\- SQL Databases

\- Tableau analytics

\- Web Dev (Front End)

\- Software Dev (Telegram bot)

\- Web scrapping

&#x200B;

Supposedly fluent in python, R, Tableau, SQL, Java, Javascript.

&#x200B;

However, spent 4 weeks working on math for a few classes. Yesterday, when I popped open jupyter for some analysis, felt like i forget everything, had to google subsetting data, how .apply() works and stuff.

Did webscrap 1/2 ago and I almost have no memory of it, asides from knowing I gotta work from BS4/selenium. 

&#x200B;

Any advice?"
"Do any of you use survival analysis in your jobs? If so, what function do you work in and how are you using survival analysis techniques?",8,g00c3a,datascience,9,"I've been getting more and more interested in survival analysis these days, but I'm curious what use-cases there are to it in industry. I know it's used a decent amount in pharmaceutical companies. But I want to get a sense of a broader range of how survival analysis is currently  being utilized in data science. Thanks!"
"Other than the US, where do you think the best place to be a Data Scientist is?",19,fzz190,datascience,38,
My Giant Data Quality Checklist,808,fzweaf,datascience,59,"First - [I also published this on Medium if you'd prefer to read the full article there](https://medium.com/@TWB_BI/starting-a-data-quality-checklist-2d500e97ab5c),

Here's the list without all the intro BS. Please do comment if you have some items to add! :

# Chapter 1 : General Structure

* Is there an established map of the database?
* Is it visible to all users?
* Is there a public strategy of how it is tested for truth?
* Are there known party(ies) responsible for updating it when there are structural changes?
* How often is it updated?
* When is the next scheduled update?
* Is there a change log to track prior changes?
* Is there a group of humans you can go to with questions?
* Is there a group of humans you can go to with general conversational topics?
* The user list from a DBA is great for this.
* Consider having a monthly meeting and yearly summit per database. Remember, this is YOUR responsibility. Not the owner of the database.
* If the source of data is an application or form, is there a map from every entry field to the corresponding field in the database?
* Capacity / Uptime
* How concerned should you be with locking up the database with poorly written queries?
* Who do you go to when it is dead?
* Is the data backed up / archived anywhere?
* For how long?
* Do you remove old values from the production database after archiving?
* Are queries logged?
* How often is the database refreshed, if it is part of an ETL?
* Automatically check, at the appropriate time, if it has been updated. Have a plan in place for when it is inevitably not updated.
* What is the official way to request access to the database?
* Is there a time-out process of old user ID’s?
* Have a plan in place for when an automated procedure’s stored credentials are suddenly invalid.

**Tables**

* Is there any rhyme or reason to the naming of tables?
* If there are very similar tables (ie. CUSTOMER, CUSTOMER\_NEW, CUSTOMER\_NEW\_NEW), do the alternates need to exist?
* Is this table “one row that is constantly kept updated” or “one row for each time the data changes”?

**Joins**

* Should there be at least one “Child” for every “Parent”?
* Is there a maximum expected “Children” for every “Parent”?
* Should there be “Children” who don’t have “Parents”?
* Is every table relatable to every other table?
* On joining fields
* Do the field types match, or do you need to do a conversion?
* Queries / Processes
* Is the query properly notated?
* With the code removed, the notes should be copy and paste-able to a non-technical business partner.
* The notes should represent reality. Please.
* Is it possible to do an “anti-query”?
* Reverse your filters, but mirror your production process. In high value pipelines, this can be a huge preventative measure for errors, and an easy way to provide “free” extra value.
* Is it possible to do the query by hand on a small subset of records?
* If so, do this periodically. Seriously. I know you got into this line of business to not do this stuff manually, but doing this periodically can help verify all systems are working properly.
* Is the process entirely automated?
* If not, don’t launch.
* This includes any of the tests below that say “periodically”, if possible.
* Is it possible to store the results of every query, along with a timestamp of run (especially as part of an ETL process?)
* Are you choosing a “whitelist” approach, or a “blacklist” approach?
* If there are changes after launch — will you be applying those changes to previous projects, or leaving them in place with old (and potentially inaccurate) data?

# Chapter 2 : Data Types

**All / General**

* Are null values allowed?
* Are the fields expected to change over time? If the answer is “no”, take hashes of lines at the time of development and test periodically to see if they change. If the answer is “yes”, take extracts with timestamps in the name and only use those (instead of production) for reproducibility.
* Expert level — Create a X / Y grid of every field against every other field. Have all parties involved in development (especially the humans that are the source of the data) write assumptions and rules that come up in each cell (if this field is “beer” this other field should be “$5.99”) Document all of these. If something looks wrong and the customer says “that’s ok”, DOCUMENT THIS. With audio evidence if possible. Video isn’t bad either.

**General Text (Free entry)**

* If there is a default size, why is the default size set to the size it is?
* Is the field having an identity crisis — does it only contain integers, dates, locations, etc.? If so — should it be converted to the correct type? What do you do with those that can’t be converted?
* Does the text contain invisible characters that will cause it to print strangely (line-break)?
* Does the text contain special (or international) characters? Should it? If you are planning on exporting to .csv downstream, are you removing commas upstream (or tabs, or pipes, etc.).
* Is there a list of “stop words” that should be applied? Especially inappropriate words. Don’t let an f-bomb get into a shareholder report.

**Categorical Text (Unique list of values)**

* Store the unique values at the time you are developing, and the counts of each value. Periodically test for new/missing values. Have a plan in place for when this inevitably happens.
* Periodically test for wild changes in distribution. Communicate these to anyone who will listen. This will make you a hero. Provide this list to stakeholders during development. This is always interesting, because often it is vastly different than their estimate.
* If there are multiple categorical fields, is there an hierarchy that is documented and should be followed (if veh\_type is “car”, then veh\_brand can only be “audi”, “ford”, “toyota” etc.). Have a plan in place for when this inevitably breaks.
* Is the field indexed for fast grouping?
* If the values are text numbers (one, two, three) — should they be converted to integers (1, 2, 3)?

**Boolean (True/False)**

* If these represent a “switch” in the process, should the downstream impact also be represented in data? (if override\_price=0 then discount\_price should never be null)
* Store the distribution at the time of developing, and periodically test for changes. Communicate these to anyone who will listen.
* Does True or False have a different name to you customers? IE, 0 = No Sale, 1 = Sale.
* What should you do with nulls, if there are any?

**ID (Keys, AutoNum)**

* Is the ID an AutoNum? If so, are there missing values?
* Is the ID a complex key? Do characters in the complex key relate to the data in any way? Periodically test that this remains true.
* Are duplicates allowed?
* Are you operating under the assumption that the ID for any given record will never change (maintaining an extract or join to a private table)? Have a plan in place for when they inevitably do.
* If you remove the ID from the equation, are there any two completely identical rows?

**General Number/Integer**

* Does null = 0?
* Are negative values expected?
* Are decimals expected? If not, is there rounding occurring upstream? What are the rounding rules?
* Is there a maximum/minimum expected value? Record the minimum and maximum value at the time of development. Periodically test to see if this record has been broken.
* Is there an expected distribution? Periodically test to see if this has changed.
* Is the number secretly categorical (only certain allowed values)?
* Does the number increase in steps instead of linearly (100, 150, 200, 250…)?
* Is the number secretly a phone number or postal code?
* Is there any chance that the number has been cut off to fit in a smaller field (I’m looking at you, Smallint)?
* Is any number field the result of math on other number fields (price\*tax=total)?
* Is there a business preferred format for showing numbers (commas, negative signs)?

**Currency**

* Is there an assumed currency? If not, is there a categorical field that will tell you what currency it is?
* If the record also has a “country” — does the currency match the country?
* Are you converting these currencies to a single currency downstream? If so, store the conversion rates at the time of development.
* Is there a maximum sane currency? Record the maximum and test frequently. Have a plan in place for when it is inevitably broken.
* Does null = 0?
* Does the value represent a “current” value, or a “point in time” value (current price of product, price of product between 2018 and 2019)?
* Are there negative values? Does negative represent a debit or a credit to the company?

**General Contact Information**

* Is there a schedule for updating contact information?
* When was the information last updated?
* When was the information last successfully used?
* If you use this information for any purpose, store the information at the time of use, and the reason for use. If possible, get as many employees as possible to do this in the same location using the same format.
* Do any two customers have the same piece of contact information?
* Does any contact information match your own company/office information?
* Does any customer’s information match that of a current or former employee?
* Is there a no-marketing list that you should be aware of? Ask multiple people and get excited when there are multiple answers!

**Phone Numbers**

* Is there an assumed country code? If not, is the country code stored in another field?
* Do not assume the country of residence is the country code of the phone number.
* Does the phone number follow the rules of that country code?
* Is there an assumed area code?
* Is the area code a toll free area code?
* Is the area code a legitimate area code?
* Is the phone number stored as text?
* Is there any rhyme or reason to the formatting of the phone number? If it is text, is there a single format? What do you do with numbers that do not match that format?
* Is there a preferred format for displaying phone numbers?
* Are you removing “bogus” phone numbers (All the same digits, counting up, etc.).
* If there is a dialer campaign that returns invalid phone numbers, is anything being done with that information?

**Mailing Address**

* Is there an assumed country? If not, is the country stored in another field?
* Is the address free entry text, or cleaned via a service?
* If it is cleaned, what happens to un-cleanable records?
* Is the Postal Code -> State/Region -> Country strictly enforced?
* Is the mailing address in an expected area of business?
* Is there an additional “APT” or “PO BOX” field? Should you be aware of this?
* If there is a latitude/longitude field, does it match the address? Do many customers have the same latitude/longitude?

**Sensitive PII**

* Are these fields humanely appropriate for modeling or analysis (ethnicity, income)?
* Do you need to be aware of HIPAA guidelines?

**Financial Information**

* God help you if your company is storing unmasked financial information.
* Did two different customers make a transaction with the same credit card? Or the same last four digits and expiration date?
* See what your most popular card type is and and provide this to your marketing department if there is a clear winner, for use with reward programs.

**Date / Time**

* Is this a system recorded timestamp field, or human entry?
* Is the time being stored with an assumed time zone?
* Store the minimum date-time during development. Periodically check to see if this has changed.
* Are there any dates with missing information? For example, there are sales every day of February except the 12th.
* Are there records outside business hours?
* Are there any fields that look like they were entered before their timestamp (people trying to create records in the past)?
* Are there any dates that are in the future?
* Do you need to have a specific game plan for leap years?
* Do you need to have a specific game plan for holidays?
* When counting records by day or hour, are there any outliers?Communicate this to stakeholders as soon as possible. Check this frequently — it’s valuable information and will make you famous when you catch something. Additionally, it will ruin your model if there was a rare event.
* If there are multiple date fields, should they have an order of operations (field2 should always be after field1).
* Does everyone know what “biweekly” means?
* Does everyone know what “midnight” means?
* Is there a business preferred date format?
* For forecasting purposes - keep a separate table telling you what dates to NOT take into account when training forecast models. IE - Hurricanes, marketing campaigns, giant international pandemics.
* Do you have a plan for daylight savings time?

The end! Thanks for reading through, and contributing more ideas. I will try to keep this list updated."
Weekly Entering & Transitioning Thread | 12 Apr 2020 - 19 Apr 2020,10,fzvidt,datascience,165,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Best Python data science book for business?,2,fzv39v,datascience,16,"Hello, I have been looking for threads like this one asking for data science books but the answers/questions scope was too general.  
I would like to know if there any book(s) that you would recommend for people to learn how to apply **data science** in **business**.   
Thank you very much.
I recognize that my question is somewhat broad, to be more precise I am looking for books that apply data science in marketing, sales, finance, optimizing supply chains, etc. 
And yes case studies would be great."
"Data science made me forgot my business/MBA knowledge, did same happen with you?",124,fzlp2d,datascience,67,"I transitioned from working as a BA in consulting to BI & then to DS. Been out of touch for many years from qualitative business/market research projects I used to work on and instead doing coding, modelling & creating dashboards I feel my knowledge of business and economy has diminished drastically.

I crave to regain my business acumen, understanding of economy & markets but seems difficult to do that in my present job. When I see big gap in  my understanding of business world vs my friends in strategy consulting I feel v inadequate.

How do data science people work on this aspect, suggestions please."
Is data collecting dead?,0,fyyrl6,datascience,2,"We are in an economic downturn and companies are going out of business. How do data companies do in these times? Is data a necessity for companies that use it? For example, lead generating and hedge funds use data for enhance their success, is it necessary?"
"What are some ""obsolete"" technologies that new data scientists shouldn't waste time learning?",14,fyubi4,datascience,18,"I guess no one write MapReduce code anymore, but what about Pig and Hive? Are they still relevant? For the sake of studying for interviews in 2020, what are technologies/tools that one should not bother study for?

&#x200B;

Thanks"
What is actually done with the Data I collect?,24,fyr7kk,datascience,3,"I'm so sorry if this isn't actually allowed here, as I myself am not a data scientist in any capacity. My job however does deal with data, and I'm curious about it. Tl;dr why do companies want certain data and what do they do with it? 

My company provides retailers with pricing data collected by employees in the field. I am one of those Field Data Collectors. Basically I'm assigned several jobs at different stores throughout the week. Some jobs repeat weekly, or monthly, or quarterly. Some jobs require the collecting of certain items on a list, some requiring scanning every item in a category and collecting those prices. 

An example: every week Bullseye wants to know how Walcarts prices a specific 500 items at 20 different stores in the area. I'm assigned 3 stores, go into each of those stores and find the items, scan them, and input the prices. If that store does not carry the exact item I indicate it. Different DCs are assigned the different locations.

I don't even know what happens in my own company after I upload my job to submit the data i've collected, let alone what the retailer does with the data they're given. 

I'm just curious, why do these major retailers (and even some minor more local/ region specific retailers) contract with our company to get this data? What do they use it for? The company website sells itself as ""Our clients benefit from omni-channel, normalized, and actionable Pricing Intelligence at massive scale to inform on-target pricing strategy and maximize business impact."" What does that even mean? 

Another question I have, who benefits most from this data? Is it only the corporations, or is there any benefit to the consumer as well? 

Also, when Bullseye wants pricing from Walcarts, Walcarts sends us to a Rokger banner, and Rokger finally asks for Bullseye data, does that really end up benefiting anybody? They're all getting data from eachother in a circular manner. 

I'll delete this post if it's not welcome here, I didn't know where else to post."
How to stay organized when writing code,216,fyk6y8,datascience,96,"I'm using R to do an analysis of my dataset, and there's a lot of EDA and filtering in my code as I compare results of different segments.  Is there an easier way or best practice that has worked for you in terms of staying organized and making sure that as you make changes to our code and revert back, you're not forgetting or missing anything?

&#x200B;

For example:

I have a 300 line code that generates some results and graphics of an overall performance.  If my boss asks me to slice my data and look at the same results and graphics at a different segment, I need to go back to line 79 to change my filter,  maybe line 120 to adjust my dataframe, etc etc to get the code working.  Lots of things can go wrong here, especially when I revert back to the original and I may forget about line 120, something like that, or if I have to do multiple segments, I dont have to scroll up and down so many times

&#x200B;

curious to how everyone manages this."
Whats the coolest project you have worked on?,22,fyhw8s,datascience,16,"I am thinking about making a career change and even thought i think the creativity and puzzle solving nature of a data science career makes me a good fit, i want to know what exciting things has the average guy worked on."
Unique R Packages for Data Science,15,fyf96h,datascience,14,"Hey all, I’m looking to begin writing a notebook for my team (data science), where I keep track of “unique” R packages and what they can be used for in the DS realm. An example I can think of off the top of my head would be something like “Plotluck”. It’s not your typical package that most people know about, and it seems to be pretty cool from a higher glance at it.

So my question - Which R packages different from the norm do you advocate for? What do they do that makes you such a big fan of them?

Note - I prefer R packages but if there’s a Python package you strongly feel deserves to fit in this conversation, by all means mention it!"
Internship got rescinded. What to do?,163,fy52zf,datascience,77,"Hello Everybody,

Just a little background: I am a [M.Sc](https://M.Sc) in Data Science student graduating in December 2020.

I had a Data Analytics internship lined up for summer with a company I really liked but they recently rescinded their internship program due to COVID-19. I know internships are vital towards landing permanent positions.  Since, it is fairly late to apply for other internships and remote options are heavily applied for leading to low likelihood of securing one, I am worried about the whole situation.

So my question to current Data Scientists is how important is an internship in securing a permanent job? Are there any alternatives to that?

Also, what should I do over the summer that would be helpful towards advancing my career in Data Science?

Thank you for your time."
How do you know if your dataset has been exhausted,111,fxvb1b,datascience,51,"You're given a task from a client. You're given the data. You've gotten to understand the data. 

It's sparse, very sparse, imbalanced also. All your tricks do not seem to work. 

Yet there's still this hunch, and a big chunk of dissatisfaction, with failing to prove the underlying relationship you set out to do. 

You can always reparameterize; Maybe the response should be encoded in a different fashion, what about additional feature engineering, basis functions, priors, enriching the data.

The question is, **when do you stop**? When do you accept the solution you're looking for, does not exist in this haystack. Accept the defeat."
Turned down Uber's Data Scientist final job interview...did I make a mistake?,5,fxtwal,datascience,17,"Data Scientist in Silicon Valley here. Started applying for jobs 2 months ago to transition to a new company before the pandemic hit. I interviewed with multiple companies and reached the final interview portion for Uber before bailing on it (as well as all other companies in my pipeline). I increasingly felt that these service app companies were especially volatile and vulnerable right now, if you see what's going on with their stocks, their non-existent customer base, and mass layoffs (ex: Thumbtack).

But did I make a mistake in my assessment? I don't know if I overly freaked out and turned down what would likely have become a job offer. My company pays me well, and since I'm in the online streaming business it feels a lot more secure. But my total comp isn't as great as what Uber/Lyft offers in the Bay Area (200k+) and switching to these companies could mean almost 30%+ lift in my total comp. 

Thoughts?"
My company requires that I come into work during corona,0,fxp1qv,datascience,7,"Has this happened to you, and how did you handle it as Data Scientists? I have said twice now that I will not go into work. I am in Germany, there are no strict restrictions, only social distancing. However, this goes against my morals and I do not want to put others at risk / I need to take public transport.   


My employer is, however, making it clear that he's becoming impatient.   


I honestly don't know what to do.

&#x200B;

Thanks r/datascience"
"Ex FB DS - Analytics, where are you now?",19,fxgy04,datascience,13,"Recruiter reached out to me to interview for their DS Analytics role and after the technical screen I made it to the ""onsite."" Of course, lots of people know that it's just a glorified analytics role. If my interests are in statistics/ml (studied it in grad school) with 2 YOE under my belt, would this be the wrong career move to make? Has anyone who worked in these roles gone on to do more modeling type work at other companies? Did having a FAANG on your resume help?"
How to study for product data science interview?,148,fx98h9,datascience,52,"I have an interview with FAANG for their product data science team. I somehow made it past the technical screen with the hiring manager knowing nothing about product. But, I want to know how can I best prepare so I actually know what I'm talking about in my upcoming interview? Thanks.

edit: i have a strong grasp of data science curriculum, but don't know much about product aside from logical reasoning (lol)"
Books on Data Science/Machine Learning impact,20,fx3xyz,datascience,6,"I am a data scientist/ML engineer trying to get to know different  angles for looking at my profession, especially how it may affect people  with other background.

In the last years I read some books, but probably they're biased  (being written by people who did it professionally, at least at some  point)

* *Master Algorithm* by Domingos (good book, but it's sort of popular science on ML and the social aspect part is very weak IMO, because it is full of hype and reads more like a sales pitch than result of some analysis)
* *Weapons of Math Destruction* by O'Neill - it touches some relevant points. I'm not sure about the validity given O'Neill's track record though - she once lamented how no one does research on AI fairness (this was in a newspaper article, it was not long ago, when there were established programs and research groups on that). Also book is very political and might sometimes be annoying if you don't exactly lean left
* *Outnumbered* by David Sumpter - this is by far the best book I've read, it's well balanced, like for example the author mentions different metrics that were used to assume whether algorithms made racist predictions or not. Also he doesn't push any ML hype, and actually finds there is no proof for some results that got huge media coverage.
* *Architects of Intelligence* \- it's a set of interviews with ML people. What is great about it is that you can see that there is no consensus on the future of the field, and that people who actually have impact have divergent opinions on some topics (like for example on regulation)
* *AI Superpowers* by Kai-Fu Lee - a book by author who was involved with many facets of ML - research, business side (as head of Google China) and venture capital. This one is especially interesting since aside from AI it describes digitalization in China. One of maiin theses is that the US leads in research, but implementation side is tilted towards China because of different business culture (author says that in China companies are not so innovative, as everyone copies from one another another, but that makes its environment more competitive since it doesn't have so strong founder effect where first company to come up with an idea dominates its niche).

I'm looking for books preferably written by specialists (as opposed to journalists), also maybe if this becomes a big list someone will find it helpful.

Thanks for suggestions."
Data Science: Reality Doesn't Meet Expectations,220,fwxy6o,datascience,58,
Bootcamps for already employed data scientist?,1,fwupoq,datascience,13,"Hi everyone,

I received my Bachelors in Statistical Science (combo of math, stats, coding) in  Jun 2019 and I have been working as a full time data scientist since I graduated. My manager said that the company  would pay for any bootcamps I want to attend.

A coworker is taking this bootcamp [https://generalassemb.ly/education/data-science-remote-online](https://generalassemb.ly/education/data-science-remote-online), but it seems somewhat introductory?

I am comfortable working with Python, R, SQL. I think I'm a pretty good coder, but I would like to learn more and get better. I really enjoy coding!  I know enough Javascript and HTML to do my job (interactive dashboards using D3js). I'm familiar with ML and have done projects, but I'm not super comfortable. Also, I learned all the math and stats in college, but I haven't done much data analysis in the real world yet so it would be nice to practice those skills. Also never learned any big data stuff, so maybe it's time to learn Hadoop? Not sure.

Has anyone done any bootcamps that they can recommend that are for fine tuning these data science skills that you already have and learning more complex things?

Thanks so much!"
"Is data science generally not considered ""business critical"" at most companies? If so, why?",12,fwqocq,datascience,25,"I've been seeing some discussions here around layoffs and some people were saying at many companies data science is not considered business critical and, in fact, many DS teams don't even actually return much value. How true is this? And if it is, why?"
How to avoid procrastination at home,6,fwmuo5,datascience,4,"You are probably working at home remotely. At home, you may find many distractions: mobile notifications, social media notifications, kids around, the TV turned on or phone ringing constantly.

These things are keeping you away from getting things done. Now you have enough free time to work on that project, to widen your in Data Science, to implement this new tool at your job, to do that course or to become an expert in your field. Here are 3 quick tips that will increase your focus and will make you avoid distractions:

- Set up a clean environment. Have your desk clear. If possible be alone in the room, where no one in your family will be passing by. Set boundaries with them, telling them that you will be working so please no interruptions if it is not needed. 

- Follow your normal routine at your job. Take breaks, do the pauses you normally do and when finishing your job totally disconnect from work. Avoid reading and responding to emails in the evening.  

- Set clear goals. The uncertainty makes us work with no direction. Create specific and objective goals, give them a time frame and start each day with the task which needs a bigger effort from you. 

I hope these tips are helpful. What is the biggest struggle you are facing these days? Comment in the posts below."
Do you have a data science portfolio website?,185,fwmgqi,datascience,117,"I read in multiple sources that you should create a portfolio website to showcase your projects, it'll increase your chances of getting hired. I'd like to create a nice website but I'm not a front-end developer. I'm also not sure what's the best way to present a combination of writing, code and visualization.

Have you tried to create one? Are you considering building it? Does it really increase your chance of getting hired? Share yours if you have it already!"
Real world problem statements for each of these questions.,0,fwm06g,datascience,8,
What are some good general questions to ask when tasked with creating a database?,8,fwemp0,datascience,7,
Is it normal to have trouble with matplotlib?,11,fwa7kq,datascience,31,"Problem: 

I've been using matplotlib fairly extensively for more than a year (previously used ggplot) yet I still don't understand it. I mean I've generated a bunch of common templates that I reuse, but every time I need something different, I have to google it because I have absolutely no idea how to do it. It's just not intuitive to me for some reason. Having two APIs makes things even more confusing, and I just can't remember which method works with which API (e.g. to turn off axis labels).

What I've been trying so far:

- reading stackoverflow answers
- reading references
- practicing

Despite all this I'm still terrible with matplotlib. I'm trying to understand why, what I need to be doing differently... Is it because I don't spend enough time learning matplotlib? ~~Do I need to have a PhD in matplotlib?~~ Do I need to focus on one API and forget everything else? Should I be looking under the hood to have more insight?"
Which industry is the best to work for?,3,fw9sg7,datascience,8,"I'd like to preface that I am aware tech maybe the most popular go-to industry for data scientist but outside of that option, where do you see as the best place to work? 

Possible discussion criteria:

* Availability of data
   * availability of data in the next 10 years 
* Goals of applying data to said industry
   * What are some projects being tackled in said industry
* stakeholder's opinion of data science
* work/life balance + industry culture
* career growth be it into more technical or managerial positions 

background: currently working in marketing space as an data analyst with 3 year out of college, curious if i should shift industries before becoming pigeon holed. Eric Shmidt of google said ""its easy to change jobs but not change industries"", or something along those lines."
What are your favorite VS Code extension for Python and datascience,16,fw6ty0,datascience,8,"I've been trying to move from just Jupyter notebooks to a full fledged IDE with debugging support, remote development and remote debugging and all the other bells and whistles. I also work a lot with PySpark so remote development is huge for me. 

&#x200B;

So how do you like VS Code, and what are your favorite extensions?"
Data science teams being laid off,3,fw1eel,datascience,15,"I've been looking at this [link sporadically tracking the layoffs](http://layoffs.fyi/tracker/) happening at companies primarily geared towards tech. Seems like it's mostly startups right now that are going through a huge cut to the workforce while the bigger companies can weather the storm for now.

I was wondering if any data science teams were getting completely cut? Given that DS is not business critical, I would expect some companies to be completely gutting their teams. I heard Bird cut their data science team from 50 down to 5. 

Has anyone else heard of/experienced this?"
Dealing with Unrealistic Expectations as Employee #2,16,fvyrky,datascience,16,"Wondering if anyone can help me out in my current situation

&#x200B;

**Tl;dr** the company that just hired me is not ready for data scientists. I’m being asked to do things that are very far from my expertise, but I also have no other job prospects. I also really like the field the app is in, have a ton of time while under quarantine, and the motivation to try and make as much of this work as possible. Any help is appreciated.

\----

I’m a data science bootcamp graduate (I know, I know. I apologize for existing.) and not surprisingly have been struggling to find my entry into the field, but I was getting interviews, particularly in my area/domain of interest. Then the virus hit the US and all my prospects shriveled, except for one. It’s a startup in my domain, an app where users would make decisions regarding a particular “score”.

&#x200B;

Originally, we had discussed integrating with his development team (working with them on an initial model of the aforementioned “score”) - then, as the initial model is productionalized, I would switch to data-driven content creation (data viz, dashboards, articles and presentations for non-tech users) to help in communicating technical aspects the product internally, and marketing the product externally, an area of the field I enjoy. Great.

&#x200B;

Well, we negotiated equity, and I sign-on, and it turns out I’m the first (and only) full-time employee. The development team is all freelance. The company has no data engineers, so the founder has asked me for guidance on setting up historical data from an API on our own servers. The extent of my data engineering knowledge is: I’ve used SQL to connect to preexisting architectures, and I’ve seen people use Spark/Hive/Hadoop. I’m researching Apache Airflow like a madman, but (obviously) in way over my head.

&#x200B;

He also wants me to spearhead the marketing campaign. There is no website. There is no chosen domain. But I’ve had dozens of pages of “marketing book notes” delivered to me, and I’m supposed to turn it into some kind of plan for my own content, then execute said plan. He wants me to be the lead on creating strategic partnerships within the industry. While I love ""making things"" (I'm also a YT/podcast content creator for fun), I’m not a marketer at whatsoever and don't have some big list of in-industry contacts, so... I’m just completely in the dark there.

&#x200B;

I know a ton of people would just peace out and look for another job, but since I've got no other options at the moment: for those who have been in similar situations and stuck it out: who’ve dealt with a founder/boss with unrealistic expectations re: what one entry-level data scientist can do, I’d love to hear how you went about A) your work (what tools/resources) you saught-out and B) how you handled communicating unrealistic expectations while still doing your level-best to rise to the occasion.

&#x200B;

Thanks for your help in advance.

&#x200B;

Edit: spelling"
Fit an exponential curve to anything...,1794,fvu3qu,datascience,95,
What hiring managers are really looking for,503,fvgx3n,datascience,113,"I’ve been following this sub for awhile, and am currently in the middle of a few hiring processes for data analysts/ scientists. I work for a midsized SaaS company as an embedded and thought I’d share what we are really looking for! 
* **SQL**: For some reason, this is a huge hole. 90% of DS is data cleaning and manipulation. Don't just know the syntax; know how to manipulate raw product tables to get the data you want, and be able to defend your pulls to business line owners and stakeholders when they ask why you're showing them what you're showing them.  
* **Logic and self deduction skills**: I'm not just talking about math-like logic. This includes business and interpersonal logic as well. For example, why is this person asking this? What is the “whole board” they’re seeing?
* **Ability to check your data and findings against the product output / business situation**: How do you know what you pulled is right? That your findings make sense? Do your numbers hold water against someone who knows the product data and inter-workings inside and out?
* **Non technical stakeholder communication skills**: This includes presentations, building rapport and relationships, managing up, managing different attitudes, understanding perspectives, understanding how to ask questions and listen between the lines, building strong daily partnerships
* **Business strategy skills**: Now that you’ve completed this project, now what? What does this mean for the business? How do you see the whole board and make a recommendation that fits in? 
* **Grit and attitude**: AKA the ability to wrangle through messy problem,  messy data, and with messy relationships and politics. Know how to get through the mess, how to self problem solve, and when to call in favors. Also, have a willingness to do grunt work, like write SQL, or figure out what the product data is, how it is produced, and wtf the engineers were thinking when they structured the product in that way.
* **Politicking and relationship building**: understand how to work with product, biz line owners, execs, etc to solve problems. Have a strong willingness to HELP OTHERS! 
* **Tableau / data viz in some way**: be able to clearly relay your findings, with ""like I'm 5"" attitude, to people who are not comfortable with even basic bar charts or graphs. You should be able to look at a graph at a glance and consume what it is telling you. 

Then... python/R, special packages, math, modeling, etc. 

I see so many people worried about x language or Y package, where I actually think those are relatively easy to learn. The soft skills aren’t taught in school and are VERY important - and the hardest to find! 

Honestly, analysts and data scientists don't get to do the cool stuff all the time. There is a lot of boring stuff that is easy to do, technically. I built a dashboard the other day that took me maybe 4-6 hours from start (coding) to finish, and people falling over themselves in excitement. It wasn't fancy, but it made it VERY easy for them to get what they needed, quickly. 

What do other hiring managers think?

**EDIT TO ADD:**
* When all else is equal, we hire based on culture and team fit, and willingness to learn. **Attitude and fit often outweigh technical skills!**

* The requisite mastery level certainly does depend on the job level. For more junior level candidates, I understand when you haven’t developed those yet... but how is your attitude? Do you think you know everything bc you have the hard skills down? Or do you recognize that you are just starting out and the soft skills are what you need to learn? 

You’d be surprised at how many people graduate with a MS or PhD, but have no work experience, and think they deserve senior level roles. Sorry... drop the ego, you only know a little bit of what you actually need to know to be successful. 

* Re: how to convey this in an interview / resume, or how to ask interview questions - you ask performance based questions. “Tell me about a time you partnered with a non technical stakeholder to solve a business problem”. 

Talk about how you solved the business problem first, then about the tools you used to get there. I like hearing about cool stuff, but I also need to know you can do the basic stuff and the soft skills REALLY well. 

* Re: starting my own business and my skill level - obviously I’m not 100% at all of these things. No one is! We all have areas to grow. Also, I don’t want to work on my own.

* Per a comment, I cleaned up my formatting :)

* We hire for a well rounded team. Everyone has a different background. Not everyone is going to know everything. That is ok. Lean on what you're good at, have an attitude that focuses on continuous learning, and be a strong team player."
Weekly Entering & Transitioning Thread | 05 Apr 2020 - 12 Apr 2020,3,fvcsk4,datascience,176,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
Does anyone dislike the whole deployment phase of data science,9,fvbj5z,datascience,9,"I just managed to deploy an api in a docker container on aws bean stalk after messing around for hours on ec2,lambda and with different ports,packages. This part doesnt excite me really id much rather discover insights and present value to a business."
"Experienced data scientist, what's the one thing that you wish new grads would invest more time in?",321,fv9yja,datascience,150,"[Inspired from this pos](https://www.reddit.com/r/cscareerquestions/comments/fu9gto/experienced_developers_whats_the_one_thing_that/?utm_source=share&utm_medium=web2x)t

Edit:- So many comments, I thought I should right a summary.

**This is not a priority order, just a simple summary.** 

\- **SQL**

* Optimising SQL objects
* Indexing for performance,[https://www.brentozar.com/](https://www.brentozar.com/), [https://use-the-index-luke.com/](https://use-the-index-luke.com/)
* Normalization
* Temp Tables
* Query Optimization
* CTE
* join
* Execution plan assessment

\-  **Work as a team**

* Git
* Reusable and maintainable code
* Reproducible

\- **Preprocessing and analyzing data**

* Pipeline
* Verify data integrity
* find and report leaks in data
* productionise the preprocessing steps and ensure you can replicate your accuracy metrics in production.

\- **Web Scrapping**

* beautiful soup

\-  **Soft Skills**

* Communication skills
* Presentation skills
* How to communicate complex concepts to large audiences
* Ethics
* Finding What user/client wants

\- **Hypothesis testing**

\- **Domain knowledge**

\- **Statistics**

* Book -Think Stats and Think Bayes by Allen B. Downey
* Book - An introduction to statistical learning

\- **Software Engineering**

\- **Psychometrics**

\- **Thinking through a long term strategy of experimentation and automation**"
Text classification service API or docker image recommendations,4,fv1itk,datascience,3,"I have a website that organizes factual claims and allows the community to rate them based on objective qualities.  One current feature associated with each claim is called ""topics"".  I'm considering a redesign where topics are calculated automatically based on the contents of the claim, its sources, and its evidence provided.

Technology is no bother for me, as I built the website from the ground up.  However, I know next to nothing about data science.  I've spent most of today researching where I even need to begin.

What I think I'm looking for is called Text Classification.  Here's what I imagine my process would look like.

1. Certain users sometimes enter topics with each claim.  When they do, the back-end will take that opportunity to train a model with the user provided topics.  Maybe I have to spend some time training the model myself, which is fine.  Who trains it doesn't matter, but I would like the model to be trained against a specific set of topics.  This could eventually be in the thousands.
2. Certain users take advantage of auto-tagging of topics, and the claim document is then submitted to the text classification service by the back-end where it will predict one to many topics automatically.
3. Depending on other services provided by the text classification solution, it may also be used for fuzzy searching and trending topics.

Here's where I'm uncertain:

1. Am I on the right track with text classification as the right solution to this problem?  I've seen several tools for ""text annotation"" but those seem more interactive, and tied to recognizing existing named entities, whereas I want to train the model against a more tailored lexicon (train a document against a topic/category/label/whatever).
2. Most examples I saw while researching only used one topic to train one document, and got only one topic in return when predicting a document.  I am looking for a solution where I can provide many topics per doc in training, and get many topics back when predicting.
3. Does training end, or is it continuous?  Is there such a thing as over-training?  I'd also need to factor in storage size for trained topics, especially if it is continuous.
4. Can text classification be used to determine topics that are trending and fading?  Or, is that a different data science approach/solution?
5. I think I found what I need in GCP [AutoML](https://cloud.google.com/automl) Natural Languare Processing API, but it is too expensive ($5 per 1000 doc predictions!?).
6. And, assuming I'm on the right track with all of this, does anyone know of any production-ready service API's or docker images out there, or even libraries I could integrate with or build a service around?  I'm technology agnostic and am comfortable in many languages including python.  But, most everything I've found seems one-off, white-paper-ish, experimental, small-scale (i.e. in-memory only), etc...  Here are the ones that seemed closest to what I want to do:
   1. [natural](https://www.npmjs.com/package/natural) \- node toolsuite with most everything I think I need, but would need to build up persistence storage and run benchmarking to assess its scalability.
   2. [prodi.gy](https://prodi.gy) \- Seems more UI human interaction focused, rather than API driven.  And, not sure about custom lexicon given the emphasis on general annotation.
   3. [tagtog](https://www.tagtog.net/) \- Same comments as [prodi.gy](https://prodi.gy), but  got excited when I saw they had a docker image. Didn't seem like the right solution for my problem, though.
   4. [cortex](https://www.cortex.dev/) \- AWS based, service based, but wasn't clear on how they offer text classification at all.  I wondered if I could makeshift their sentiment analysis just using a custom  topics.  I could work with AWS, but it's not my first choice
   5. [monkeylearn.com](https://monkeylearn.com) and various other services that aren't upfront about pricing or are just too expensive.
   6. [xgboost.readthedocs.io](https://xgboost.readthedocs.io) \- here's one that I believe is production ready and \*probably\*, but I have a hard time figuring out what the heck it does or what I do with it!
   7. [klassify](https://github.com/fatiherikli/klassify) \- This one seemed the most straightforward, and closest to what I'm trying to do, has a docker image, works with redis, and so it seems scalable.  But, I wasn't sure if anyone had any experience with it or if it meets my requirement of pulling multiple topics out of one document (at first glance it only seems to work with one).

Appreciate any help on the matter!  I have a [sandbox](https://sandbox.thinkards.org) up if that helps gauge what the website abilities are.  I'm aware the UI/UX needs some work, and I am working on it (that's at least two things I'm clueless on)!

**Edit**: Some spelling and grammar fixes, and added xgboost and klassify to my list of researched tools."
htmlcreator: build standalone HTML documents from Python,14,fuzwli,datascience,9,"I often find myself in need to share my findings (mainly tables and pictures) with collaborators. When I started working in Data Science I was using Jupyter Notebook a lot, so I usually exported .ipynb to .html and voilà. But over years I switched completely from notebooks to scripts (even though I love new Jupyter Lab). Without notebooks, creating standalone HTML file with images and tables wasn't easy anymore. I couldn't find simple Python package to help me with that, so I created my own one: [htmlcreator](https://pypi.org/project/htmlcreator).

It exposes simple API for creating standalone HTML files from Python code containing text, images and tables embedded inside. It has also default styling (CSS), so everything looks nicer. I've been using it for around 2 years now and recently decided to publish it, so others can use it too.

see [examples/1_build_first_document.py](https://github.com/ar-nowaczynski/htmlcreator/blob/master/examples/1_build_first_document.py) and its output: [examples/1_first_document.html](https://htmlpreview.github.io/?https://github.com/ar-nowaczynski/htmlcreator/blob/master/examples/1_first_document.html)

installation for Python >= 3.6:

    pip install htmlcreator

source code: https://github.com/ar-nowaczynski/htmlcreator"
"Data scientists of Reddit, why would you like to share your datasets?",8,fuyrbk,datascience,7,"I am curious to learn the use cases in which data scientists want to share their datasets. I can think of cocreating, cleansing, pull requests, etc. 

Also, how do you do it now?"
I find this data science map really useful. Where are you on it?,580,fuyoai,datascience,108,
Was looking for Data Analyst/Scientist positions and then Covid happened...How do you expect this to change the entry-level market?,215,fuw7r1,datascience,106,"I will be graduating with an MS in Stat next month and was in the process of looking for a job in my city before Covid took over. I'm starting to feel some anxiety that I won't be finding a job for a while. Are your companies freezing hiring and do you expect any layoffs in your teams?

Side question: If you potentially had months of time, what skills do you think are the most valuable to spend time improving?"
Is Tableau worth learning?,297,ful3b9,datascience,192,"Due to the quarantine Tableau is offering free learning for 90 days and I was curious if it's worth spending some time on it? I'm about to start as a data analyst in summer, and as I know the company doesn't use tableau so is it worth it to learn just to expand my technical skills? how often is tableau is used in data analytics and what is a demand in general for this particular software?

Edit 1: WOW! Thanks for all the responses! Very helpful

Edit2: here is the link to the Tableau E-Learning which is free for 90 days:  [https://www.tableau.com/learn/training/elearning](https://www.tableau.com/learn/training/elearning)"
Any dyslectic or dyscalculia data scientist?,4,fuinw8,datascience,13,"Hello data science subreddit, 

I have a question. I'm thinking about doing a minor in data science and later on maby a master. I'm doing a bachelor in marketing, and right now I'm doing an internship in marketing insights (research). I have really taken an interest in data and statistics and also data science. I would love to learn more about it but there is one thing holding me back.

 I am dyslectic and I have discalculia, both diagnosed at a very young age. There both not as severe now that I'm older. Mainly I'm bad at spelling and mental arithmetics. But I will also  misread numbers or letters or remember them wrong fairly often. So this might lead to small errors here and there.

On my current internship it's not a super big deal because we always look over everyone's work before sending it out anyway. 

But I guess my question is to anyone reading, is it a stupid idea to get into data science with these learning disabilities because I'm probably more prone to making errors? 
If there is anyone working (or studying) in data science who is dyslectic or has discalculia I would love to hear about your experience.
Don't be afraid to give me an honest answer, I want to know.

Tnx for reading bye.
(sorry if my English is bad I'm not a native speaker)"
"Looking for an online, part-time MEATY DS/ML graduate program",110,fua9o7,datascience,88,"I am a data analyst who is looking at getting a MS in Data Science/Machine Learning, and I'm running into the issue that a lot of the online programs are pretty light--very weak on math and theory and clearly oriented towards making a quick buck in the Hot New Field Of Data Science. But the math and theory behind DS/ML techniques and algorithms are what I'd really like to learn about the fields. I am OK with taking courses to meet the program's math and CS pre-reqs. 

So far the closest I've seen to what I want is the [JHU part-time online data science master's](https://ep.jhu.edu/programs-and-courses/programs/data-science), but they have the weird requirement of C++ as a pre-req (at least it seems weird to me). I'll pick it up if there really aren't any other theory-focused programs out there, but I'd rather not spend a year learning a language I probably won't ever use in a job.*

Does anyone have any other recommendations? Or is a stats degree what I need? And if so, does anyone have recommendations for that?

*Or maybe I would, maybe I don't understand how hardcore data scientists work?

EDIT: just because there have been a few comments--I know R and a bit of Python, and fully expect any decent program to require programming experience. I was just thrown by the C++ requirement as I've never seen that used in DS."
Why should people learn Rshiny and/or Dash when you can use Google Data Studio?,1,fu7dxo,datascience,7,"I see people on reddit making some really fancy dashboards using Google Data Studio.
I know R and Rstudio and I've designed a couple dashboards myself in Shiny. 
Rshiny is amazing (specially for people with very basic CS knowledge) but it's very time consuming and requires a good amount of effort. ( I am assuming same is true with Dash)

So what is the advantage/disadvantage of using Google Data Studio over the Shiny/Dash?"
Jupyter Notebook/Python equivalent to Rmarkdown feature allowing dynamic reference variables in md cells?,3,ftoq0t,datascience,4,"I love Rmarkdown and I used it a lot at my previous job to create parameterized monthly updates/reports to non-technical staff. I loved being able to run the same report for different objects instantly, and most importantly I really liked being able to reference R variables in my markdown cells directly instead of having to reference a table elsewhere in the document. In certain cases it really improves readability and therefore, the likelihood of the report being read.

At my new job, there is quite a push to only use python since we are relatively small and it facilitates code review if everyone shares the same language. I can make OK reports with Jupiter notebooks, but I was wondering if anyone knew of a nice way to include dynamic variables directly in the markdown cells, or of any other tool that would allow me to do this. Thanks!"
Using Monte Carlo simulation to estimate potential impact on sales? (Retail),140,ftnuqe,datascience,35,"I am an analyst at a large retail company that is deemed to be essential by state governments. Sales impact questions are coming to our analytics team, I proposed we run a Monte Carlo simulation to provide a range of sales impact given the virus. 

Questions: 

* Would this be the appropriate approach? 
* Are there any other approaches we can take to estimate impact?"
Looking for resources on Spark from the Data Engineering side?,42,ftmis5,datascience,10,"I'm looking to learn Spark (ideally using the Python API, but Scala would also be okay) but from the Data Engineering/ETL/pipelining side, not the ML side. There's plenty of Data Science-oriented Spark courses, but few that deal with the Data Engineering/Big Data side. Does anyone have any recommendations? I prefer online courses, but books are good as well. Thanks!"
Coding for work vs coding as a hobby,21,ftdpb7,datascience,12,"Hi,

I don’t know if this is the right sub, I hope if not I will take it down.

So I work as Data Scientist/Software Engineer and obviously most of my day coding.

I also wanna learn new stuff / work on side projects as a hobby but I find it really hard to find the motivation as I feel like I’d spend my entire day only coding and it also reminds me of work.

I tried to separate my work environment from my personal environment, different machines/ different location (from home though) still didn’t help.

Any tips on how you guys manage both?

Much appreciated!"
Thoughts on long case studies as part of interview process.,9,ftcxuj,datascience,27,"At large companies, I haven't had an issue with these.  They may ask for a case study that takes like 5-10 hours and have you present it in person.

Ive run into issues with smaller companies  doing one of two things:

1.  Sending me a case study that is 10 plus hours long prior to any sort of interview with the hiring manager so I don't even know if id want the job or not.
2. Asking for an extensive amount of coding and work far beyond 10 hours.  like if you want to have a complex coding problem with large data files with tons of issues, its kind of bullshit to ask for a powerpoint on top of it  

&#x200B;

Ive been a hiring manager myself in the data science field for about 5 years hired maybe 5-6 entry level data scientist/analyst throughout my career.  And was always mindful to keep any work I sent them to very brief and just enough to show that they could do the basics.

It really rubs me the wrong way when a company sends me a case study prior to having the hiring manager taking 5 minutes to discuss the opportunity with you over the phone.   I just got ghosted by a hr person at a company who sent me a case study as the first part of the process and never took the time to confirm he even received it or give feedback.  I go on glass door and they had like 30 negative interview reviews of other people saying the same thing

what are your thoughts on this?  I may start nexting companies that want me to do a case study prior to speaking with the hr manager or asking for lengthy case studies"
Talented statisticians/data scientists to look up to,375,ft5nsy,datascience,93,"As a junior data scientist I was looking for legends in this spectacular field to read though their reports and notebooks and take notes on how to make mine better. 
Any suggestions would be helpful."
Virtual Data Science Communities,0,fszm2b,datascience,1,With COVID-19 Virtual Communities are popping up more than ever. I was wondering what would ppl like about Data Science Virtual Communities to have enough for them to be active on it?
Best Clustering/Grouping method to solve this problem?,2,fsxgeq,datascience,9,"I want to cluster or group my data into 3 categories:-
- High performing companies
- Medium Performing companies
- Low Performing companies

I have a dataset which has the company name, company rating, company turnover, Total Business transacted. 

I could probably loop through them and based on a couple conditions I could classify them in these categories but there are so many companies and so many different permutations and combinations that can be made. So I am not sure if that's the best and most efficient way.

Will K-means clustering be a good and viable technique to use here?"
"Have you adjusted your salary ask for Corona times? If so, how much?",4,fswflj,datascience,8,"Everyone understands salaries will be lower for anyone looking for work now. The question is how much?

I follow Mckinsey Insights. This seems to be a good proxy for what corporate CEOs read to make their decisions. There's no clarity on how long the Corona crisis will last nor what the economic impact will be.

I guess anyone who will face a salary negotiation will have to estimate:

    How long the crisis will last

    How damaged the world (or at least local) economy will be

to be able to produce a number.

Can we look at your calculations here?

What is reasonable? best case? worst case?

Is 'half my usual ask' too crazy?"
Seeking Feedback on Data Science Workflow Tool,1,fsif1v,datascience,3,"I'm excited (and nervous) to share a product I've been working on for the past few months to get feedback from this community. While I'm more of a *heavy* lurker, /r/datascience has always been an excellent source of discovery and insights for Data Scientists both new and experienced.

I've seen a lot of frustrations when it comes to making Data Science effective in an organization. Issues like:

- Complicated tooling and configurations
- Lack of pipeline and data testing
- Lack of visibility into projects as they start to expand in complexity
- Being forced to wear hats for every step of the end-to-end data cycle
- Different data teams operating in silos
- Lack of access to required cloud resources
- Projects rarely making it to production

All of these issues make it difficult for a Data Science team to drive value and build trust. But I don't think it should have to be that way.

With these frustrations in mind, I set out to build a workflow platform - [Shipyard](https://www.shipyardapp.com) - that helps eliminate the friction of getting solutions to production so Data Scientists can focus more on Data, not DevOps.

To be brief, we've designed the platform to:

- Launch solutions with no DevOps or complicated setups involved. We're cloud-native and handle all scaling on your behalf.
- Orchestrate solutions across teams to create complex pipelines with no edits or additions to your code.
- Monitor and alert on the status of hundreds of solutions for peace of mind.
- Share custom, repeatable solutions with the larger organization using Blueprints.

We're still in the early stages, so I'm looking for anyone that might be interested in testing us out and providing feedback. It's 100% free right now in exchange for your feedback. If you're interested, let me know.

Either way, I'd love to hear the tools currently being used to manage workflows/pipelines and any problems you may be facing with them right now."
Estimating Covid-19 Infections based on Reported Deaths,0,fsej3k,datascience,18,"Since the number of test varies significantly between individual countries, and no country is is even close to reaching 100% test coverage, the reported infections have to be taken with a gigantic grain of salt. However, reported deaths should be much more accurate, since everybody who dies as a consequence of a covid infection pretty much has to be ""in the system"".

So I tried to find a way to ""backtrack"" actual infection numbers based on reported deaths and some other parameters. The calculation could look something like this:

**Assumptions**

* Number of infections is doubling every 3 days
* It takes on average 12 days from infection to death
* Case fatality rate is 2.5%
* There are 100 new deaths reported today

**Calclulation**

* We know, that the people who died today have been infected about 12 days ago. Since 2.5% of infected people die, we can now calculate the number of people who were newly infected 12 days ago with n=100/0.025 = 4000
* We know, that the number of infections doubles every 3 days. Therefore, the number of newly infected people today has to equate, all things being equal, 2^((12 / 3)) = 16 times the amount of 12 days ago. Thus, we can assume that, today 16\*4000=64000 people will be infected
* We can run this calculation for every date, resulting in a timeseries of (new)infections
* We can take the cumulative sum of that timeseries to retrieve the final timeseries of cumulative total estimated infections

&#x200B;

I created a little tool using streamlit to visualize the timeseries and play around with the assumptions for different countries:

https://preview.redd.it/7dcbk6zfw0q41.png?width=2277&format=png&auto=webp&s=51c26cebcbe48d8f1c2d00907cd2a3f44ee5fc37

The Python source can be found on [GitHub](https://github.com/ZanyCode/covid-sim). You can also [play around with it directly](https://covid-sim.sloppy.zone/). 

I would be happy for some feedback, especially  pointers to mistakes with the estimation logic and suggestions for other features that could be interesting to explore."
Focus on Data Science vs. Deep Learning?,2,fsc7hr,datascience,10,"Hello, fellow Data Scientists,   


With the current lockdown for COVID, I found myself with a decent amount of free time on my hands that I wish to repurpose for my own growth. 

I'm a junior data scientist, working more on the MLE side of things (but also building models). 

I seek advice regarding the following: 

  
A. I can invest this out-of-work time to develop my current work skills:   

- Python: improve from intermediate+ (design and write better OOP, develop a more software dev style of coding)   

- Statistics: Still using out of college knowledge, can get more developed at abstraction, intuition, and baking in more stats in my general intuition (that comes with time and practice but I feel I can learn more on this end)   

- Cloud Dev (aka) MLOps: I've been some work on that end, seems very interesting to me as I come from an engineering background


B. Pick up a completely new skill: Deep Learning: 
I know just enough from school to say I trained a Neural Network, I'm not familiar with the details, the Keras/PyTorch feud nor advanced hyperparameter tunning. Either I can invest in the famous Coursera DL bundle, or Udacity or whichever fits. 


Whenever you think about these choices, think employability, job proofing and well expanding my skillset. On one hand, mastering one's job is essential so A would be great, but it only covers so much of the field."
Business Analytics.,3,fs9eqi,datascience,7,"Does anyone know how would Business Analytics postions differ from data science job roles? 
 
I have done a one year program on Business Analytics and have a business bachelor's degree. But I don't know what difference should I expect."
How do you appreciate efforts of your data team nowadays? And how did you transition to remote work?,0,fs7plc,datascience,1,"Hi Fellas,

I'm working as a high performance data team manager. We are working fully remote since a couple of weeks now. And this community has helped me to understand and overcome some of the challenges that I might have faced while going remote.

Although, we do face some challenges even today. But by documenting everything we are able to streamline a lot of things in the team. And now I feel it's time to appreciate the extra efforts my team has been putting in.

Would you mind sharing some of the best practises to celebrate the success remotely?

Thanks in advance :) Stay Safe!!"
New External GPU for deep learning,3,fs07kh,datascience,5,"I’ve been wanting to get into deep learning with a GPU for some time. Cake day for me and a brand spanking new eGPU from the wife! Great day!https://imgur.com/a/Xetb4o6/

Not sure if the images are loading, but I got:

-	Radeon rx580
-	Razer core x enclosure"
MlFinLab Updates & Mentorship,3,frz521,datascience,1,"Hi All,

We have just released MLFinLab 0.8.0 which includes a couple of bug fixes and the new [Tail Set Labeling technique](https://mlfinlab.readthedocs.io/en/latest/implementations/labeling_tail_sets.html).

Additionally, we have started a [mentorship program](https://hudsonthames.org/mentorship/) that caters to ambitious students looking to make an impact on open-source and develop a portfolio of work based on financial machine learning.

Finally, we ran a poll to figure out which verticals to focus on for 2020, below are the results.

https://preview.redd.it/wsk6rax4jvp41.png?width=581&format=png&auto=webp&s=ca8f34de9d0030c817f396cc59bec0917945c58e

I must say, I am very surprised by the results. I thought that portfolio optimization was going to dominate. Re the Backtest overfitting: Last week we added the [Deflated](https://mlfinlab.readthedocs.io/en/latest/implementations/backtest_statistics.html#deflated-sharpe-ratio) and [Probabilistic](https://mlfinlab.readthedocs.io/en/latest/implementations/backtest_statistics.html#probabilistic-sharpe-ratio) Sharpe ratios, [Campbell's](https://github.com/hudson-and-thames/research/blob/campbell/Backtesting/Backtesting.ipynb) famous Haircut Sharpe Ratio and Profit Hurdle algorithms will be released in the coming week.

If you have research topics that you think will be helpful to the open-source community, please do let us know in the comments below.

Thanks for all of your support."
"How do you use AWS, Google Cloud Platform, and Azure? Are there any good tutorials or books to help me get started?",11,frxyhm,datascience,8,"I will be working as a data scientist soon and was told I needed to know these three cloud tools. I just registered today for the three but I am a bit lost on how or even where to start. I would like to know how to use these three so by the time I am physically working, I will be prepared to use them. Are there any tutorials, videos, or books that can help? I searched Google but could not find much on the three, not even any cheat sheets."
Thoughts on lower-than-desired metrics for production or output?,2,frx60n,datascience,6,"In my sort of work/project, I was tasked to classify tweets (sentiment analysis). I did the annotation step (farmed it out actually), did the inter rater thing, tried to clean it as best as I could, used a bunch of algorithms, from naive bayes to multilingual Bert to even novel algorithms, but only got an accuracy of about 80%, very little hyperparameter tuning tho (interesting to note tho is that regardless of which method I chose, they're all  quite near that accuracy range of 80%). And tbh man I'm feeling so down about it.

I sort of know why the accuracy isn't very good. Even the annotators and myself were also having some trouble during the annotation per se because there's a lot of nuance and context in the data (and a LOT of sarcasm). Like, there are some items that could really go either way. 

Is real world data really this messy? The text I'm dealing with has so much slang, text speak, different dialects and related languages, typos, all on top of code-switching. I have nothing to base on whether it's a good enough accuracy for me to proceed with my analysis or not. I am tho gonna ask my supervisor/head on their thoughts, as I clearly lack experience. I feel like I'm being overdramatic, but if anyone has any tips or words of encouragement, I'd appreciate it."
Does anyone have any non-technical books about data science and machine learning they recommend?,3,fru0uv,datascience,3,"I'm looking for any good books, articles, or video explaining data science and machine learning (common misconceptions, business use cases, etc) that are aimed at a more executive and non-technical audience. 
I'm hoping to provide some materials to the broader team at my company to help them move past the buzz of data science and develop a better understanding of what data science is and is not capable of."
Publishing interactive datasets and visualizations using Python and R libraries,12,frsbby,datascience,1,"A few months ago, I was wondering if it is possible to build interactive data visualization without writing HTML, CSS  or knowing a lot about server scripting. I even asked a question on the forum - [https://www.reddit.com/r/datascience/comments/ekawho/how\_do\_you\_track\_and\_share\_your\_data\_reports/](https://www.reddit.com/r/datascience/comments/ekawho/how_do_you_track_and_share_your_data_reports/)

Based on the feedback, I and my friends built a free data publication service that supports Python and R libraries for visualizations. And you do not need development and deployment skills.  We published a blog post on how to use the service.

[https://medium.com/dstackai/publish-track-and-share-data-analysis-results-without-development-skills-3c4e8d170232](https://medium.com/dstackai/publish-track-and-share-data-analysis-results-without-development-skills-3c4e8d170232)

We would love to hear about your challenges in the area of collaboration around data visualization, and receive any feedback on what we currently have. If there is any specific feature that you see relevant to you as a data scientist, please let us know."
How do you predict after getting the moving-average of a time series?,1,frs6zi,datascience,6," 

Say I have the moving-average for this data: [https://i.imgur.com/7qz5ZZt.png](https://i.imgur.com/7qz5ZZt.png)

How do I predict? Because the moving-average only gives me a sequence of averages, not a function that I can use to plug in future dates.

Do I still have to use linear regression on the data points or the moving-average points to predict?"
"""With our new neural network architecture, we achieved 100% accuracy on our training set (n = 50).""",651,frq469,datascience,67,
Key things to learn to be able to meaningfully contribute to open source packages/projects?,8,frmhqy,datascience,4,"Quick background, I'm self taught and I first learnt Python specifically to do data science stuff in Jupyter (I'm hoping to get an entry level DS/DA job in the next few months). So as you can imagine, my Python code practices is trash compared to industry standards.

What are the key things I should learn in order to start meaningfully contributing to open source stuff?

- I imagine there's some code style standards I should learn?
- What are some critical aspects of Python that I might not know due to primarily being a Jupyter boi?
- What are the tools to learn to remotely collaborate with others who may be editing similar parts of the codebase?
- Is controlling the versions of package dependencies super important when writing package code and if so, what are some tools to learn to handle it?
- I primarily use JupyterLab. What's a more optimal environment setup to do this type of work?
- What obvious and important things have I missed?"
How are you all thinking about demand modeling in this pandemic?,1,frkhr0,datascience,2,
Graph of graph analysis,2168,frkgr7,datascience,43,
How important is domain expertise/knowledge for data engineering?,1,frh0ve,datascience,2,"For data scientists, I think it's pretty obvious as to how or why domain knowledge is important. But I'm wondering if the same also applies to data *engineers*. Since data engineers are engineers first, is domain knowledge important? In other words, if I work as a data engineer in, say, a financial services firm, would it help a lot to have finance background, or would just having data engineering in any domain be pretty sufficient for the job?"
Unethical Nobel Behaviour,691,frd031,datascience,67,
Looking for Coronavirus datasets,1,frafwp,datascience,1,"Hi All,

I am looking for coronavirus data, specifically X-ray scans of lungs. I'm aware of this source: https://github.com/ieee8023/covid-chestxray-dataset/tree/master/images

Is there anything else?

Thanks in advance!"
Infection Map vs. Population Density - Seems like we are all on similar trajectories... what are the implications?,2,fr77ua,datascience,8,"&#x200B;

https://preview.redd.it/3v33emcummp41.jpg?width=3899&format=pjpg&auto=webp&s=22f306c496c7e7e4209aa11033f32dcf80d79be5"
Are there good Python alternatives to pandas that don't store datasets in memory?,0,fr5sw5,datascience,8,"One of the ostensible selling points of Python over R is that Python supposedly deals better with large data sets, as it doesn't store datasets in memory. However, I recently learned from this very subreddit that pandas stores datasets in memory. 

Given how frequently data scientists can need to deal with very large datasets, are there any good alternatives to pandas that doesn't do this, or ways around this, etc? Otherwise, given how essential I've always understood pandas to be to data science in Python, the language seems to lose a major advantage in its favor.

(I don't mean for this to be a Python vs R post -- personally I plan on learning both for flexibility.)"
Weekly Entering & Transitioning Thread | 29 Mar 2020 - 05 Apr 2020,6,fr4umt,datascience,129,"_Bleep Bloop_. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki. You can also search for [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).

---

I am a bot created by the r/datascience moderators. I'm open source! You can review my [source code on GitHub](https://github.com/vogt4nick/datascience-bot)."
[Source code with demo] Here is my python implementation of Deep Q-learning for playing Tetris,702,fr4hc1,datascience,72,
Do yo know any streams (like Jon Gjengset's but) about data science?,3,fr2bx8,datascience,0,"I'm looking for streams about data science with the full process (see [Jon Gjengset's long videos as an example](https://www.youtube.com/channel/UC_iD0xppBwwsrM9DegC5cQQ/videos)) and real world examples.

Thanks!

&nbsp;

^^^EDIT: ^^^Do ^^^**you** ^^^know..."
How do you set yourself up for success in a new role?,0,fr0xjo,datascience,2,"I'm starting a new role in a few weeks and was wondering what you think are most important to do in the first 30 days.

I thought about my first 30 days in my current role and wrote a short summary [https://medium.com/@mtidowu/five-actions-to-take-in-the-first-30-days-of-your-new-data-science-role-1a98aab5ce5e?source=friends\_link&sk=523530adafe6572fc36dae5f685dbd08](https://medium.com/@mtidowu/five-actions-to-take-in-the-first-30-days-of-your-new-data-science-role-1a98aab5ce5e?source=friends_link&sk=523530adafe6572fc36dae5f685dbd08) but looking for more things!"
Is it worth doing masters in data science?,0,fqzjst,datascience,6,"I am planning to pursue masters in data science next year, after I complete my undergraduate. I will have zero work experience, but I completed an internship on machine learning while studying. 

I've heard people say that usually companies don't hire fresh data scientists, because it takes a lot of  time to actually become a data scientist and just getting a masters degree won't make you a data scientist. Also considering that I will not have any work experience prior to taking up data science, I'm assuming it is going to be hard for me to get a job. 

Should I look into other masters courses? If so, can you recommend me some relating to data science."
What’s the simplest way I should’ve answered this conceptual statistics/methodology question in my interview (Market Analyst)?,2,fqzhwd,datascience,10,"Hey all,

So brief summary, I applied for a Market Analyst position (first analyst position in general) and essentially after proving my SQL skills in a few, very tedious interviews beforehand, made it to the final interview (via video, woo!)

It was this last question in this final interview that just threw me off of everything, as I have like no statistical experience/knowledge (except for taking one stats class in early college lol). 

So I know this is probably simpler than I made it out to be in my head, but it being in the moment, and again, my lack of statistical knowledge in general, I literally was stumped. 


Essentially here’s what I was given:

Upon past email marketing survey efforts to a test send group of 10,000 customers, we had a 20% response rate. We then had a control group to 1,000 customers, and had a response rate of 15% with them. 

We want to lower the control group and yet, be confident we can measure the response rate with statistical significance. What would you recommend?


So basically, I pulled stuff out my ass with things like “further personalization of the designs of these email surveys as we decrease the control group size, as well as trigger(automate) emails to send surveys out in a more timely manner” (LOL) etc etc; knowing damn well that this problem isn’t really focused on the process or design of the survey itself.

They tried giving me a hint saying that this is supposed to be conceptual and there’s no one right answer and they don’t need exact calculations or anything but more of the statistical thought process one would go through for this experiment.


The only stats I remember was like simple t-tests (one sample and independent samples) but I’m rusty in both concepts and definitely need to go back and refresh every little thing about them. Plus, wasn’t even sure if this scenario even constitutes those two tests lol. 

I was feeling so good up until then since literally all of the other interviews and questions were about SQL and they were really impressed by my queries and such. And on top of that, they said most of the day to day is SQL so I felt like this might be my first analyst position I could finally land.

But what’s done is done and as I wait for a decision, I wanted to see what thought process you guys would’ve essentially said (in simplest terms?) so that I can learn and just be able to familiarize myself with some of these terminologies for future references.

Thanks in advance for any input on the matter~

EDIT: should’ve added their response when I asked for general clarification:


“So let’s say whatever lower control group we chose, we saw that the new response rate was 10%. How do we know that that given response rate can be trusted and significant? “

“Again, don’t focus on the actual value of the new response rate. It could be 15% or 20%. We just wanted to know how you’d go about saying that this response rate was not just an anomoly but can be trusted in the sense that in the future if we wanted to use the same control group number then we can expect that same response rate?”"
Marketer moving to data science?,0,fqz7m4,datascience,1,"Hi everyone! I’ve got about 5 years in marketing experience in the non-profit sector and I’ve recently come into a data analyst position and have fallen in love with data. I’m dealing mostly with web analytics (Google Analytics, tag manager etc) and am really looking to hone my skills and possibly move into a data science career path. 

It seems like everything that I’m reading points to people who have undergrads/masters/phds in stats or math or computer science and I’m getting a lot of imposter syndrome as to whether I can start from zero at age 25 and really turn this into a career. Is it realistic to go through some code academy courses and read some books and break into the field? Or is it really going to take some extra schooling/degrees? Interested in all thoughts!"
Do Data Scientists use Google Colab/Jupyter notebooks or prefer using text editors like VScode?,3,fqya1f,datascience,15,
Want to change domain but do not know where to begin.,0,fqy2xd,datascience,0,"Hi,

I have been working as data scientist for almost 3 years now, in e-commerce domain. Mostly image and text. Most of the work is in Attribute extraction from text and image, taxonomy classification etc.

I want to make change in domain and really want to work in finance and other related field. I have Computer Engineering background and know Deep Learning, Machine Learning at an intermediate level and programmed only in Python. I have started to work on SQL as it is an important skill as data scientist. I am not sure where to start for finance domain. Tried learning Time Series during the current lockdown in India it is for 21 days, I want to make most of it. Any suggestion will be appreciated. The other thing why I want to change is because I do not like Computer Vision which is mostly I worked on, I like NLP and Text Analytics but for computer vision I feel a bit out of place."
"Is it advisable for a newbie to attempt Amazon's Data Scientist certificate, to make a career shift into Data Science?",19,fqx0wq,datascience,6,"I thought that completing this [program](https://aws.amazon.com/training/learning-paths/machine-learning/data-scientist/) and attempting to earn the certificate might be a good use of time and effort, as there's a trustworthy credential involved at the end.

I have been looking for a study plan/list of topics & curriculum that'll help me structure my learning process. So far, I've been following some popular/suggested plans (like this [one](https://towardsdatascience.com/how-to-learn-data-science-if-youre-broke-7ecc408b53c7))

However, I'm not entirely sure about whether this would lead me down the path to shift toward the data science profession.

I also felt like I was going off on a lot of tangents, and with no defined goal. 

If anyone of you experienced data scientists could recommend/give your feedback on whether pursuing the Amazon certification would be advisable, or if you could share some study plan for statistics and Python/R programming for data science, I would be very grateful!

Thank you, and stay safe & healthy"
I created a discord server specifically for those starting out or interested in the field of Data Engineering!,0,fqvi14,datascience,2,"I am sure there are similar people out there looking for help/resources/a place to ask silly questions/ find study buddies, etc in this field! Let's help each other out...here is the link: [https://discord.gg/aUawNPm](https://discord.gg/aUawNPm)

It would also be awesome if experienced Data Engineers joined and helped us out.

Disclaimer:

1. I am not a Data Engineer; just pushing this cause along to get into this field myself.
2. This is my first discord server - bare with me while I figure things out."
Recommendation for example on DS project from beginning (EDA) to end (deployment),0,fqu8en,datascience,2,"I don’t have a good context of what happens after the ‘model’ building phase of DS project, and would like to see some examples, tutorials, books, whatever that shows what it looks like.  I’m referring to deploying the model in AWS or something.

Are there good resources to learn about this?"
My First Year as a Data Scientist,364,fqs1l7,datascience,45,"Over a year ago I made the move in my company from full-stack dev to data scientist. To help myself reflect on what I've done well and not so well I've written a blog post about this here -  [https://codebuildrepeat.blogspot.com/2020/03/my-first-year-as-data-scientist.html](https://codebuildrepeat.blogspot.com/2020/03/my-first-year-as-data-scientist.html) 

I hoping that my experiences will help others on here who are either going through a similar transition or thinking about making the move."
"CALLING ALL DATA SCIENTISTS! Four minutes of your time can save thousands, if not millions, of lives!",0,fqqdnn,datascience,13,"*TL;DR: fill this 4 min survey to save the planet :)* [https://www.surveymonkey.com/r/QFQJH7V](https://www.surveymonkey.com/r/QFQJH7V)  
   
As you all know, governments across the planet are struggling to contain the spread of Covid-19. The reason behind this is simple: things are moving too quickly making it extremely difficult to keep track of what is happening and where it is happening. The answer is simple: **DATA**!

Until treatments and vaccines are developed, data is our greatest weapon against Covid-19, and it’s about time we used it. We are launching a global survey to collect and analyze data from citizens across the planet - the first of its kind in history- to help governments and our communities in their battle against the greatest challenge of the Internet Age.

All we are asking for is four minutes of your time to share this post and fill out this simple, completely anonymous survey that can save thousands, if not millions of lives, as well as the livelihoods of most small business owners and day laborers. If you answer these questions as accurately as possible, you will provide us with extremely valuable information that can reveal where outbreak zones are and how they have been developing over the past few weeks. That means seeing an early end to the mass quarantine measures currently being employed and enforced around the planet.

**How?** Well, for example, if thirty people on your block report that they have symptoms consistent with Covid-19, your local government will be able to act quickly to treat patients, contain the local spread, and warn those on your block to take extra steps to safeguard themselves. You yourself will be more cautious and will have a direct view of your neighborhood's status regarding the coronavirus.

Imagine the network effect, and application of wisdom of the crowd to actually get more insight and provide a new angle to specialist & data analysts to come-up with the most impactful solutions.

All of this anonymous information will be released daily on Kaggle and Github so that researchers, data scientists, companies and governments can quickly access and analyze it.

Thank you for your patience, your input and your time, here is a link to the survey: [https://www.surveymonkey.com/r/QFQJH7V](https://www.surveymonkey.com/r/QFQJH7V)

\#fourminutes #wearetheworld #smashthecurve #dataforcoronavirus

## Who are we?

We are an international team of volunteers donating our time and our effort to support those on the front line. Our team consists of graduates/post-graduates from the Universities of AUC, Cambridge, Oxford, Toronto, UCL, and KCL. Our members are from Egypt, England, Germany, Italy, Poland, South Korea, and the US. Among our ranks are junior doctors, physicists, engineers, marketers, political scientists, and data scientists. We welcome and are open to collaborating with anyone who can help us develop FREE, OPEN-SOURCE solutions to the challenges up ahead.

## Who is supporting us?

We are currently collaborating with [Lyra](https://www.linkedin.com/company/lyra-analytics/?viewAsMember=true), a leading firm in AI and Data Analytics, and are supported by Eva Pharma, a global pharmaceutical company based in Egypt, who have kindly provided full access to their resources in support of our common cause.

**Contact information:**

*If you want to track updates of our efforts or collaborate with us, you may reach us through our*

*FB page: SMASH the CURVE*

*or*

*via email:* [*smash.the.curve.covid19@gmail.com*](mailto:smash.the.curve.covid19@gmail.com)"
Python Beginner COurse for Free,16,fqoi81,datascience,0,"Hi all,

For anybody starting there data science journey or early on here are some free python courses.

 [https://realpython.com/free-courses-march-2020](https://realpython.com/free-courses-march-2020)"
Brutal Honesty - No Naivety,0,fqoesg,datascience,24,"My personal set of circumstances: Political Science graduate. Lots of customer service experience. Lots of philosophy courses, both collegiate and self-learned. I like to think that I have a great capacity for critical thinking, but I think it’s essentially against the very nature of critical thought *itself* for one to have the thought that they *are, in essence*, a critical thinker. I have a knack for learning complex mathematics and arithmetic. Obviously, that stuff isn’t “natural”, but I know how I best absorb material through memorization and repetition. I have never programmed, but I am very confident
that I can learn. 

My question: What would it *really* take for me to learn Data Analytics/Data Science in such a way that it would BEST prepare me to tackle the true problems and projects that Data Scientists and Analysts face in the world? And that means to say: Should I go back to *school* and learn it, or should I take the necessary steps to dedicate immense amounts of free time to studying it, making my own projects, and displaying them in a hiring process? 

*Seriously*, I want people on this thread to be brutally honest. *I want to know the degree of severity in my situation*, in regards to what I will NEED to do, *in order to be successful in Data Science*. 

What would be THE BEST STEP TO TAKE so that I am the MOST SUCCESSFUL I CAN BE in Data Science/Data Analytics in, say, 10 years from now?

Any help is appreciated. Thank you.

EDIT: If any of these thoughts are *stupid*, or make you think that I am *ignorant* about data science as a whole, then *tell me why*. I’m certainly aware that I am tremendously ignorant about this stuff, for the time being. I’m grown, I can figure it out - If I’m being stupid, *tell me*."
"I want to use my quarantine time to improve my ability to use data, where should I go?",9,fqn20p,datascience,8,"Background: management consultant, basic (maybe intermediate) use of PowerBI in the past. Even when doing functional work or in my personal life I’ve found having sharp visualizations can be really powerful. 

Any suggestions on where I should go and what I should spend my (seemingly unlimited) time on? 

Thanks!"
Why Choose UVA Data Science Program?,46,fqm9hg,datascience,59,"I'm a Georgia Tech OMSCS student, who for 60 seconds or so researched the possibility of transferring to UVA's Data Science program. After reading about the curriculum, I then looked for the price tag. It was roughly $41,000!

Here's my question: why would anyone choose UVA's Data Science program over Georgia Tech's OMSCS (assuming it's ML-focused) or OMSA programs? 

I'm serious. Tech is one-fourth of the cost or less. It's hard to imagine any hiring manager, even if a UVA alumnus, being more impressed with a UVA DS masters than a Georgia Tech OMSCS or OMSA degree. Given the existence of OMSCS and OMSA, how are they able to get people to pay $41k (even in-state)? 

On top of that, the UVA DS program has a $120MM gift. How can they charge $41k with a straight face?"
"ELI5: What is the difference between an in- and out-of-sample forecast, and the difference between stationary and dynamic forecasts?",43,fqjagz,datascience,14,"Heya, I have a time series comprising of 348 observations and am required to do an in-sample and out-of-sample forecast for it but I'm a bit confused on how exactly this works. Likewise, I would like to attempt static and dynamic forecasts.

Could someone explain how exactly these types of forecasts work and should be approached, and also if they can be linked (i.e. is it possible to do static IS, static OOS, dynamic IS, dynamic OOS)?

Thanks :)

EDIT: should of wrote **static** and dynamic, not stationary and dynamic"
"I know python.... and have somewhat knowledge of machine learning, what should i do to make myself ready for job in data science?",0,fqiqlv,datascience,18,
Algorithms for text analyzation,3,fqi6jc,datascience,8,"Hello,

I've been searching for some algorithm to help me analyze a PDF file - extract the important information and then build Excel tables with. I am trying to work in R. 

I have found many text mining algorithms but that is not really what I want I think.

I need to read through a PDF and detect for example specific words, the date and so on. 

I've been looking on GitHub but so far no luck. Do you have any suggestions perhaps? Thank you!"
COVID-19 Forecast Web App,7,fqfimf,datascience,10,"I created a web app to forecast active COVID-19 infections in the US at state and county levels based on confirmed cases:  [https://matt5mitchell.shinyapps.io/COVID19Forecast/](https://matt5mitchell.shinyapps.io/COVID19Forecast/) 

The app estimates the effective reproduction rate (transmission rate) based on the most recent data from Johns Hopkins, which in turn feeds a SIR model to create the forecast. My GitHub is [here](https://github.com/matt5mitchell/covid19).

&#x200B;

https://preview.redd.it/r3s5jqym7dp41.jpg?width=800&format=pjpg&auto=webp&s=abfa6562ba8ac9683b7a8612e99b038998c362c8"
If there is anyone in the financial sector here that can answer this that would be appreciated.,0,fqds60,datascience,11,Is Data Science/Analysis more geared toward public auditors or tax accountants in the sense of practical use and career development. Thank you
Any data sets towards soil erosion?,3,fqcwb1,datascience,1,"Looking for where I can get datasets which have soil erosion data.

Looking specifically at regions around Torres strait. 

Any help is appreciated."
Questions related to Facebook University for Analytics,0,fqco03,datascience,0,"Hi everyone. I am a data science freshman in UW seattle. I am preparing for FBU for analytics in summer 2021. Wanna ask what questions they will ask during the interview?(coding questions like python, sql, java? Behavioral questions? case interview questions? stat questions?) And I wanna know about the details or similar examples of the questions. And also the difficulty of the interview in according to that of the full-time data scientist, analytics in facebook. Thanks!"
My friend made a website that tracks COVID-19 statistics by county. See where your county falls!,5,fqcfeb,datascience,1,
Free Game Theory Class,1,fqc38i,datascience,0,
Open COVID-19 API,7,fqbe99,datascience,7,"Hello all, first time posting here. So let me know if my post is breaking any rules or syntax.

I created a website in early March for displaying COVID-19 data/stats, and now I have gathered enough reliable sources to distribute them as API. Here is the documentation: [https://covidnow.docs.apiary.io](https://covidnow.docs.apiary.io)

Feel free to check out the documentation and use the API for good purposes (and please be mindful of your request rate!)

Let me know if you have any questions or tips."
Books/Resources to learn Python or R to Get Into Data Science (Data Analytics),4,fqa8tr,datascience,9,"Hey all. I wanted to get into the data analytic world and was wondering what books would be the best in order to have a good foundation so that I can work on my own projects for applying to jobs. I am a senior that recently switched from applied math to probability and statistics thinking that I would have a better chance of having a job that I would enjoy.  I don't plan on getting my masters and I know that the term data science is very ambiguous and it mostly means data analytics which is most likely what I would like to pursue. I learned a little bit of Java but I would definitely not call myself an intermediate in programming. I looked around the subreddit and heard that ""R for Data Science"" by Hadley Wickham have been quite praised. But I heard that python is often used more in data science and it's a more ""general"" language such that the knowledge you have for python can be transferred over to R or anything else.  I also heard that python is used more if you want to get into tech. I am quite new so any insight on where to start would be appreciated. I live in California and wish to have a job somewhere in the west coast. Thanks!"
Amazon Applied Scientist Position,5,fq5wph,datascience,8,"So over the long-term I’m really interested in Amazon’s Applied Scientist position. I may get a Master’s in the future, but I’m currently self-teaching by going through Elements of Statistical Learning as well as Statistical Inference. Other than that, once I finish up some interviews I have lined up, I plan on reading through papers, implementing them, and recording results in a blog format. I don’t really see the reason for a graduate degree if I’m able to effectively self-study, but I also just want to plan a bit. Is it at all feasible to attempt getting a position like this without a graduate degree given I show enough initiative and actually put forth the time and effort to learn (not just writing a small project using TF and then saying I’m an ML expert)?"
Difference between Gyana and coding data science?,0,fq3npb,datascience,1,"Hello all, before I dive into learning how to code with R and python, I am trying to understand the differences if I just use [https://www.gyana.co.uk](https://www.gyana.co.uk) instead. I am sure there are weaknesses with not being able to code. But for those that don't need to build an entire proprietary engine from the ground up, why use anything else than Gyana? I am a newbie. School me, please."
"People who prefer R over python, what's your rationale?",387,fq2k7w,datascience,369,"I've been using python for \~3-4 years now. A couple classes at uni used R and the feeling was generally the same - ""I already know how to do this in python, relearning how to do the same task in another  language is an unnecessary burden."" But with libraries like reticulate and rpy2, being able to mix these languages together is becoming increasingly easy.

I'm curious what things are so easy in R, you'd never consider doing it in python? Tasks R is better suited for? Or more generally, why do you prefer R?

I figure I should master it to further open up my career options, but I haven't been motivated to do. Maybe your feedback will give me a push in the right direction."
Prediction or insight?,8,fq1bqo,datascience,4,"I am fairly new in a Data Scientist position, so I thought I'ld come here to align what may be a false expectation I had. I am working right now in a project for a company that wants to extract useful things from its database. They don't know exactly what they are looking for, but they expect to see magic spontaneously happening; nothing new in the front. 

This void of a clear target is starting to be a real problem for me. My boss appear to be following his client's expectation: we are making a lot of graphs with a lot of potential things that may be going on. The problem is, whenever I try to predict some import outcome (like the probability of default), all these previous insights that we extracted don't seem to hold water. The accuracy of any model that I fit is pathetic. This, for me, is a real warning sign suggesting that we should change our approach to the client; we are basically telling fairy tales to him and suffering in the way trying to find these bs correlations.

How should I approach this situation? My north always used to be predictability (if this information does not help me predict a situation, then it is not useful), but maybe I am being too dogmatic?

&#x200B;

What do you think?"
How will the UK data science job market be affected in the next months by COVID-19?,4,fpvl95,datascience,7,"I am currently looking for a position as Data Scientist and I just wanted to know others' opinions about how the UK job market will be affected in the next months due to the pandemic. What are your thoughts, are firms going to put on hold hiring? Any personal experience on the topic?"
Coding vs COVID-19 Hackathon,0,fpsm38,datascience,3,"Hello data sciencers, 
The world’s brightest minds collaborate in a 72h non-profit online hackathon to fight the COVID-19 crisis.
​
This is an initiative under the patronage of the Swiss Federal Department of Economic Affairs, Education and Research (EAER) and the Federal Department of Home Affairs (FDHA).
​
The first edition starts March 27, 5pm CET.
You need to sign up until Friday, March 27, 4pm latest. 

https://www.codevscovid19.org/[https://www.codevscovid19.org/](https://www.codevscovid19.org/)"
How do you judge a master's program,1,fpqvod,datascience,10,"I am looking to apply for a Master's in data science by next year, however there are just too many universities, how do you filter out which universities are the best for you -given you are interested in the curriculum and like the city/country- what other measures do you use to see if this is a good master's program?

I personally would look at the university ranking but not sure if this is a good measure, cause a. there are alot of University ranking websites out there b. Data Science is a relatively new field, so this may not be accurate enough

Edit: For reference, I use  [https://www.topuniversities.com/](https://www.topuniversities.com/)  to check the ranking of universities"
[R] StellarGraph version 0.11 open-source Python Machine Learning Library for graphs just released,8,fpplby,datascience,0,"StellarGraph is an open-source library featuring state-of-the-art graph machine learning algorithms. The project is delivered as part of CSIRO's Data61.

Five algorithms and streamlined onboarding are only some of the major new features delivered in the [0.11 release](https://github.com/stellargraph/stellargraph/releases/tag/v0.11.0) of the library, with substantial API, documentation and demo improvements to support users in running and exploring StellarGraph functionality.

New algorithms include:

* Watch Your Step: computes node embeddings by simulating the effect of random walks, rather than doing them.
* Deep Graph Infomax: performs unsupervised node representation learning.
* Temporal Random Walks (Continuous-Time Dynamic Network Embeddings): random walks that respect the time that each edge occurred.
* ComplEx: computes multiplicative complex-number embeddings for entities and relationships (edge types) in knowledge graphs, used for link prediction.
* DistMult: computes multiplicative real-number embeddings for entities and relationships (edge types) in knowledge graphs, used for link prediction.[ ](https://github.com/stellargraph/stellargraph/issues/755)

A sixth algorithm remains under active development, but is available in this release as an experimental preview:

* GCNSupervisedGraphClassification: supervised graph classification model based on Graph Convolutional layers (GCN).

The new release incorporates extensive enhancements and bug fixes, some of which include: 

* StellarGraph.to\_adjacency\_matrix is at least 15 times faster on undirected graphs[ ](https://github.com/stellargraph/stellargraph/pull/932)
* ClusterNodeGenerator is noticeably faster, reducing the time taken to train and predict with a ClusterGCN model 
* Addition of a subgraph method for computing a node-induced subgraph
* Addition of a connected\_components method for computing the nodes involved in each connected component in a StellarGraph
* The info method has been improved for heterogeneous graphs with many types and also shows information about the size and type of each node type's feature vectors
* Four new datasets added to stellargraph.datasets
* Neo4j functionality is now tested on CI
* Example Jupyter notebooks can now be run directly in Google Colab and Binder
* New notebooks demonstrating how to construct a StellarGraph object from Pandas, and from NetworkX.

Go to [GitHub](https://github.com/stellargraph/stellargraph) to access StellarGraph and explore these enhancements. Details for breaking changes can also be reviewed here.  

We welcome your feedback and contributions.

Until next time, the StellarGraph team."
Should I standardize/normalize the dependent variable if I standardize/normalize independent?,1,fpomd3,datascience,2,"I'm running the multiple linear regression (for now) to predict the revenue. From many IVs (some categorical some with low values) one is a 'budget' variable, which has a large scale (in millions).

So for the 'budget' not to have a massive disturbance on the variance I plan to standardize/normalize or use log. If I decide to do any of the above-mentioned methods should I also apply the same method to the DV ?

Both revenue(DV) and budget(IV) are scaled from several million up to hundreds of millions"
How do you keep local data files ? Do you sync them up to a database / google drive? I'm confused about workflow,3,fpmubr,datascience,13,"
The problem is that we sync our code up with git, but the data is stored
locally. So that if someone else wants to run the code or something there's
an issue.

The data comes from a mixture of sources

* most is from Google Storage
* some is from data scraping / whatever during the project
* some is processed data

I was thinking about having a local directory rsynced up to the data storage,
and sync on git pushes with a git hook.

An issue with this is that there would be duplication of data, for example,
if I have some `data.csv`, then it might originally be located at

```
storage/bucket_1/data.csv
```
I pull this down to my local project
```
project/data/thing/raw/data.csv
```
and then I sync my local data up to storage again, putting it at
```
storage/bucket_2/data/thing/raw/data.csv
```
So that data now exists in two places, which isn't so great.

I'm not aware of a process to prevent this though and would appreciate any
thoughts/considerations that others have.
 
thanks"
What level of python leetcode is required for DS and MLE roles at FAANG?,3,fpmki9,datascience,7,"I've heard for:
DS: leetcode easy
MLE: leetcode medium

But I've also heard some people say there is no python leetcode type questions? Has anyone interviewed at FAANG and can shed some light?"
What are good Data Science 'screening questions' that aren't pop quiz questions.,4,fpljxi,datascience,15,What would you have HR ask a candidate on an initial screen?
A Survey of Methods for Low-Power Deep Learning and Computer Vision,0,fpirbq,datascience,0,
A Corona Dashboard where you can compare progress between counties,0,fpihzg,datascience,5,"To compare counties hold the Windows key (Command for Mac) and select the countries you want to compare  
[https://public.kelp.app/id/NqCOCDB4TPm.Md-fAoKqkyg](https://public.kelp.app/id/NqCOCDB4TPm.Md-fAoKqkyg)

https://preview.redd.it/m8olysduo2p41.png?width=1347&format=png&auto=webp&s=791846268d22a4e62aac2214d0a137df2dfffc79"
Udacity is offering access to their courses for free due to COVID-19,616,fpi8qf,datascience,119,"I myself am fairly new to data science and found this to be rather exciting amidst the current crisis. I'm not affiliated whatsoever with udacity and have limited experience with them due to the paywall they normally have for their courses. Hope this information is helpful

[Udacity courses](https://www.udacity.com/courses/all)"
You need a solid foundation for your data before being effective with AI and ML,3,fpi3xx,datascience,1,"Credit to Monica Rogati for the image

https://preview.redd.it/uqobmhswk2p41.png?width=1436&format=png&auto=webp&s=bd7fd87061d2ca55c333e76892808bd13d899f6f"
[Request] Advice on learning Python . So many options make it confusing,3,fph3vn,datascience,5,"My objective is to learn Python and use it for machine learning and data science as an important but secondary tool in my career. I'm proficient in R and Stata but almost no previous knowledge in Python. I've checked in [Codecademy](https://www.codecademy.com/catalog/language/python) and [edX](https://www.edx.org/course?search_query=python) but both of them have thematic courses (e.g. Analyzing, Visualizing data with Python) rather than teaching the language comprehensively which I don't love because it limits my options for the future. My question for you guys is if you know of a program that would help me to learn Python from basics to an intermediate level, that are free or for a very small payment."
Data collection for an Italian study about the Self and Morality,2,fpg07u,datascience,0,"Dear all,

I hope that everything is ok and that you are handling the quarantine well. I am currently a student in Milano doing my P.h.D. in Psychology. Furthermore, I am a Rossoneri in my heart for almost 20 years now (you can imagine that I am living the dream because I am living in Milano right now).

If you are bored and need something to fill your time I got the perfect solution for you. Could you fill out a questionnaire for a study I am doing? My data collection is not going well and I really need some participants. Furthermore, some of the items are pretty interesting and could help you dealing with the quarantine boredom (if it is present). So it's basically a win/win. My study is about the relationship between future self-continuity (do we feel connected to our future self or not) and moral decision making. In other words, I want to see whether the degree of our perceived connectedness to ourselves in the future is related to decisions we make about moral dilemmas.

**The questionnaire is for Italian speakers only.** This is an exploratory study and it would require approximately 40 minutes of your time. If you are interested you can check out the link below:

[https://psicologiaunimib.eu.qualtrics.com/jfe/form/SV\_78uMwJHJitwX8SF](https://psicologiaunimib.eu.qualtrics.com/jfe/form/SV_78uMwJHJitwX8SF)

P.S. If you have the time can you share the questionnaire to your contacts :) Thanks in advance guys!"
Mahalanobis Distance out of two other Mahalanobis Distances,1,fpctf3,datascience,2,"I'm not sure if this is the appropriate sub for this, but it seemed like the best one since Mahalanobis distance seems to be used for Machine Learning as well. This is for a work in Management though, so not Data Science per se, more Data Science adjacent I suppose.

After getting my head around the Mahalanobis distance, I found statistical significance in the variables I am using calculated with it. There is a pretty established author that measures the same thing I am trying to, and they publish their Mahalanobis Distances, but not their component variables, being that they use different variables to measure this construct. Their variables, and process of recovery is so obscure that it is unlikely that I'd be able to access them myself.

So, to get to the point as quickly as possible, I've was wondering if it is even worth it to look into if it is theoretically sound to aggregate two Mahalanobis Distances with the Mahalanobis Distance, for the same subjects. 

Or would it be better for me to use those my variables and include that distance as another variable. In the same vein, should some ponderation be made regarding how many variables each Mahalanobis distance computes?

I'm still looking at understanding better how Mahalanobis works, but if you guys could offer some input that would be great!"
Timeseries source per country and US state of coronavirus cases and deaths?,2,fpclv5,datascience,2,I’m looking for a place to download csv files (or similar) of per-date case and death counts per country and US state.  JHU’s site doesn’t appear to have easy access to much past data (maybe I’ve missed an api link?) and derivative sites I’ve found are only sporadically updated.
Data Scientists are just glorified analysts (and why Research Scientist is the new Data Scientist),285,fpcltw,datascience,171,"Data Scientist here in a mid-sized company in Bay Area tech. After working in this industry for few years, the fact that Data Scientist in no longer a true Data Scientist position is the only natural conclusion I can come up with. There are obviously those in companies, reputable or not, who get to do and productionize complex modeling solutions (especially if you have a PhD), but the overall trend is that most ""Data Scientists"" without PhDs in big companies have become SQL monkeys who don't even get to do something as simple as A/B testing. This is like if front-end web developers were rebranded as software engineers.

I mean it's even public knowledge too:  Lyft publicly stated how they rebranded the titles from analyst to scientist and data scientist to research scientist. This was  just to compete with other tech companies for talent that want the ""scientist"" in their title. [https://medium.com/@chamandy/whats-in-a-name-ce42f419d16c](https://medium.com/@chamandy/whats-in-a-name-ce42f419d16c). I was told by a buddy in FANG that Facebook is the one that started this trend.

How did this happen and what's the consequence? I don't know the precise origin, but I know that today what's driving this movement is the huge rush new grads with ""data science"" degrees, or perhaps waves of career changers from bootcamps who also want to find their gold.

What's the consequence? I think the consequence is that we all suffer from the rebranding, especially in terms of career development. First of all, it cheapens the name for everyone who holds this title. Second, those who have been doing true Data Science work (not just SQL all day for metrics tracking) will have to shift expectations and titles in order to preserve what they already have. Third, being stuck on menial tasks that don't impact business bottom line will make the job more expendable, meaningly highly susceptible to layoffs far more than those that are in the front lines of business/product impact. Fourth, this means lack of promotion and career development, since those who do get those have proven impact on business.

Yes, I have become jaded and pessimistic about the Data Science world in the Bay, especially not having a PhD myself that limits me from pursuing Research Scientists positions...

**EDIT:** It's quite funny that half of agree with me and half of you disagree vehemently. I actually want to be proven wrong in this case. But I'm nonetheless surprised that people couldn't care less about the HR who are cheapening the name of a scientist to make their job search easier and directing all their criticism toward a fellow Data Scientist just for pointing this situation out.

Also, yes, titles might not matter for you individually, but not having a clear breakdown of the work expectations in an organizational and institutional level is not a sign of progress. You wouldn't make this claim on the murky division is labor on government or hospital jobs for instance, or any positions of authority in public/private space.

Finally, Science as a title infers hypothesis, testing, validation through formulaic rules (mathematic or otherwise), etc. Yea sure at the end of the day, titles are just semantics, but the other extreme end of that is saying that ""well what's the problem of giving a someone who munges chemistry data the title of a ""Chemical Scientist""? Hell let's call anyone who deals with legal data a Lawyer. What this shows it that titles do matter to some degree, because it infers authority over a particular subject and the technical know-how. To throw this concept to the garbage can so that HR can have better leads on candidates feels a bit insulting."
[Career] Interview with a Director of Customer Analytics Pawel Godula,4,fpbpcx,datascience,0,"Hi everyone!  


A few weeks ago, I had a chance to interview an amazing person and a total rockstar when it comes to modeling and understanding customer data - Pawel Godula.  


We talked about:  
\> How to build models that are robust to change  
\> How to become a leader in a technical organization  
\> How to focus on the “right” questions  
\> Why model ensembling can be more important in real-life than in competitions  
…and a lot more!  


I think there is a bunch of useful stuff when it comes to career progression. 

Here you can check out the raw video of the interview or read it for yourself. 

[Interview link](https://neptune.ai/blog/interview-with-head-of-ai-pawel-godula?utm_source=reddit&utm_medium=post&utm_campaign=blog-interview-with-head-of-ai-pawel-godula)  


https://reddit.com/link/fpbpcx/video/m71tpjbkt0p41/player"
Jupyter Notebooks on a machine with a GPU - why can't I get this work?,4,fpacxt,datascience,6,"Hi all,

&#x200B;

I'm hoping someone can point out what I'm doing wrong. I have searched Google and found a myriad of tutorials that are, for all intents and purposes, identical. There's a few subtle differences but nothing special. So I've followed these tutorials and tried a few things myself but I still get the same result, best summarised with:

&#x200B;

    steve@gpu:~$ docker run --gpus all nvidia/cuda:9.0-base nvidia-smi
    Thu Mar 26 11:37:34 2020       
    +-----------------------------------------------------------------------------+
    | NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
    |-------------------------------+----------------------+----------------------+
    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
    |===============================+======================+======================|
    |   0  Quadro K4000        Off  | 00000000:01:00.0 Off |                  N/A |
    | 30%   28C    P0    29W /  87W |      0MiB /  3018MiB |      0%      Default |
    +-------------------------------+----------------------+----------------------+
                                                                                   
    +-----------------------------------------------------------------------------+
    | Processes:                                                       GPU Memory |
    |  GPU       PID   Type   Process name                             Usage      |
    |=============================================================================|
    |  No running processes found                                                 |
    +-----------------------------------------------------------------------------+

Docker thinks there's a GPU but

&#x200B;

    import tensorflow as tf
    print('tensorflow version',tf.__version__)
    print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU')))
    print(tf.test.is_built_with_cuda())
    print(tf.test.is_gpu_available(
        cuda_only=False,
        min_cuda_compute_capability=None
    ))
    
    tensorflow version 2.1.0
    Num GPUs Available:  0
    True
    False

... Jupyter can't see it.   


    steve@gpu:~$ cat /etc/docker/daemon.json
    {
        ""default-runtime"": ""nvidia"",
        ""runtimes"": {
            ""nvidia"": {
                ""path"": ""nvidia-container-runtime"",
                ""runtimeArgs"": []
            }
        }
    }
    

When I launch the various containers I've tried I don't see anything that helps me diagnose a problem - rather I see the opposite. For example

    tensorflow/tensorflow:latest-gpu-py3-jupyter

Shows this in the logs

    2020-03-26 11:34:12.600560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
    pciBusID: 0000:01:00.0 name: Quadro K4000 computeCapability: 3.0

But this is the same container as the one above that returns 0. I've also tried things like 

&#x200B;

[https://github.com/iot-salzburg/gpu-jupyter.git](https://github.com/iot-salzburg/gpu-jupyter.git)

&#x200B;

Which does the same thing - installs without incident, says it's found a GPU and then the Jupyter notebook can't see it.

&#x200B;

Can anyone see what I'm missing or suggest somewhere better to post this? I know it's going to be something obvious and I'm going to feel a bit silly but I've been playing with this on and off since the UK entered its lockdown and haven't made any progress.

&#x200B;

Thanks in advance."
Another Covid-19 cases dashboard with a tab to compare cases across countries,29,fpa006,datascience,13,
"Different ARIMA models for forecasting sales of many products, or one ARIMA model for all of them.",52,fp9i8i,datascience,56,"I have sales data for many products, my task is to do an ARIMA model to forecast sales for each product. I've done a tailored ARIMA model for each product as they exhibit different patterns.

Then when I showed it to my boss, he told me its not optimal to do this, and its better to do one model for all of them. We discussed that, and I'm not convinced.  I think its intuitive that each product needs their own model. 

What do you think guys, and is there any credible resource (a paper or a good article) that discusses this?"
The importance of the data process in crating user centered technical solutions,8,fp6oh7,datascience,3,"Hi, not sure if this is the place to ask but here it goes. I'm currently writing my application to the data science (informatics) program at my school. In my essay I mentioned that I've gained a greater understanding of the data science process (collecting data, analyzing it, extracting insights from data).

The feedback I received from the advisers asks me how understanding this data process impacts the way we build a user centered technical solution.

I'm a bit stumped on what to say and would appreciate some thoughts. So far the only thing I've come up with is that it helps us break down the problem we are trying to address."
Corporate training fees?,1,fp1b24,datascience,7,"For those who have conducted in-person corporate training in analytics (think basic data cleaning and analysis using pandas in Python, or tidyverse in R): What fees did you charge and how did that vary based upon organization and class size?  Just curious as I've heard different people get training quotes all over the place."
Neuroevolution of Self-Interpretable Agents,5,foypmf,datascience,0,
Coronavirus Confusion Matrix Anywhere?,1,foxz2m,datascience,1,"I found some research papers saying accuracy was 85-90% for China, but i dont know if it is the same test for the US.

My mom is a non ICU nurse, so im really interested in false negative rate.

Thanks in advance!"
The best resources for staying up to date with all things data,9,foxecv,datascience,2,"A while back we created an internal document with the top 5 resources for our own reference which entails content from different formats, viz., *newsletters, podcasts, books, courses, communities, and conferences.* 📊

[https://iterative.ly/blog/best-resources-data-and-analytics-folks/](https://iterative.ly/blog/best-resources-data-and-analytics-folks/)

Today, we are making it public. Hope this helps! 👍"
A Template for COVID-19 Research,4,fox9t8,datascience,0,
CoVid-19 Global Meter - Live Dashboard,238,foud2l,datascience,35,
How will the pandemic affect the data science job market in the US?,15,fotjuu,datascience,29,"I'm a masters student set to graduate in December this year. Given the situation, what repercussions are expected on the job market for data science? I'm not sure as to what extent the tech industry is hit from this so I just wanted to get a clearer picture. Will there be a serious lack of jobs or will there be no affect at all?"
statsmodels vs sklearn for the linear models,3,fotjm9,datascience,14,"I just finished the topic involving the linear models. I use a couple of books and video tutorials to complement learning and I noticed that some of them use `statsmodels` to work with regressions and some `sklearn`.

My question is, which one is practiced more often in the DS field and which one would you advise mastering?

in `statsmodel` I like that you can used method *summary()* to print all the details and metrics of the regression, is there something similar for the `sklearn`? 

Also, I noticed that `sklearn` is easier for various plotting. However, I can simply use `seaborn` library.

thanks"
"We have launched a Covid-19 dashboard, for all countries!",0,forwy1,datascience,1,"Access them via [https://www.coronatracker.com/country/singapore](https://www.coronatracker.com/country/singapore) or [https://www.coronatracker.com/country/s](https://www.coronatracker.com/country/singapore)g (ISO Alpha-2)  


Just need to replace the country name or country code."
"Tools for handling some of the more common data cleaning operations (e.g. matching names when it's stored in different formats like ""John Smith"" vs ""Smith John"" vs ""Smith, John"").",1,forw59,datascience,4,"Curious about whether any of you have go-to resources when it comes to looking for methods to perform some common data-cleaning operations for you, since oftentimes this is more time-efficient than building your own solution!

It doesn't have to be the example mentioned in the title, it can be anything else you often find yourself having to clean in your day-to-day job!"
"Data teams, what do you hate about having to work remotely?",6,foqve3,datascience,24,"While my team is working hard with IT/admin to resolve access issues and setups, was wondering if my we are alone in this shitty situation"
US Corporate Debt Datasets,7,foq00c,datascience,9,"Hello All,

I’ve been looking for a good online source (preferably free) that would be able to provide a dataset(s) of all outstanding US corporate bonds (fixed rate, floating rate, convertible, zero coupon, etc). The dataset should include the issuer of the bond, issuance and maturity dates, the price, coupon rate, credit rating, etc. Does anyone know of a source that would be capable of providing something such as this? 

Thanks in advance."
White House Announces New Partnership to Unleash Supercomputing Resources to Fight COVID-19,0,foozin,datascience,8,
Part 1 of a debrief from the inspiring #datavizlive event in London last month,82,fona86,datascience,0,
"We’re hopeful that by shedding light on products with excess demand and insufficient supply, businesses can more easily focus on the things that matter most and be better stewards to the world in this time of crisis.",7,foml4d,datascience,4,
Gtfs data analysis,2,fol6ws,datascience,0,has anyone worked with gtfs data? Just like real-time bus arrival prediction ?
What Data Science Course from Coursera should I take after 365 data science.,1,fojqo9,datascience,17,"So currently 365 data science offered its courses for free and I am on track to finish them by april 15th.

The thing is Coursera is offering a pi day promotion for data science also. Could anyone reccomend me a course/specialization that I could take to further my knowledge of data science after 365 Data Science?

Here's the link for reference :

 [https://www.coursera.org/promo/pi-day-2020?ranMID=40328&ranEAID=JphA7GkNpbQ&ranSiteID=JphA7GkNpbQ-mgaS4FnZV6P83.Wmqi3Tbw&siteID=JphA7GkNpbQ-mgaS4FnZV6P83.Wmqi3Tbw&utm\_content=10&utm\_medium=partners&utm\_source=linkshare&utm\_campaign=JphA7GkNpbQ](https://www.coursera.org/promo/pi-day-2020?ranMID=40328&ranEAID=JphA7GkNpbQ&ranSiteID=JphA7GkNpbQ-mgaS4FnZV6P83.Wmqi3Tbw&siteID=JphA7GkNpbQ-mgaS4FnZV6P83.Wmqi3Tbw&utm_content=10&utm_medium=partners&utm_source=linkshare&utm_campaign=JphA7GkNpbQ)"
"Why is ML,DL,AI so hyped, have they actually solved anything big enough?",0,fof28c,datascience,10,
Should you set the intercept before doing linear regression?,0,foe48a,datascience,3," 

Is it true that you should set the y-intercept to 0 before doing linear regression if you absolutely know y = 0 when x = 0 ?

As explained in this video: [https://youtu.be/Rb8MnMEJTI4?t=278](https://youtu.be/Rb8MnMEJTI4?t=278)"
Why are most of the data science articles on Medium?,24,fobxih,datascience,25,"Just curious on why most of the articles/guides go on Medium and not their personal blogs or even GitHub pages. Medium is good but seem to be a paywalled annoyance, similar to the news websites."
All SAS e-learning is free for 30 days including the Data Science Academy,4,fo9e59,datascience,7,
Trying to maximize my usage of desk space real estate around me to work more efficiently. What things (e.g. a giant SQL/Python cheat-sheet pasted on the wall infront of you) do you keep in your proximity to improve your work more efficiently.,2,fo9bzi,datascience,1,"Probably going to be one of the more unorthodox threads to come up here!

But I went from using a single monitor to dual monitors a couple of months ago and now I'll *never* doubt the influence on your efficiency your work set-up can have!

Curious to hear about anything anyone has to say on this."
Interview question. Explain one interesting machine learning project you’ve worked recently. Focus is on solving real-world problems. And a fun project.,0,fo98hi,datascience,0,"1. Problem statement 
2. Explain the technique you’ve used
3. Constraints you’ve faced
4. Tools you’ve loved using (bonus points if you can include libraries too)
5. Solution
Include GitHub link if you wish."
Papers demonstrating application of SEM analysis,1,fo8xo0,datascience,2,"Hello experts - I have read about Structural Equation Modeling in grad school, I also seem to understand how it works and what it is used for. Can someone point me to a paper that demonstrates a real life application end to end ? I don't work in academia anymore so an open access or a public link would be really appreciated. Thank you all!"
"self made data scientist, what's your story?",0,fo8k0l,datascience,4,"hello, 

Im interseted in hearing stories about those with no background in data science or computer science becoming data scientists, how did you do it? what made you want to change your career? What were some major challenges you faced? 

Thank you for sharing"
"Would you rather have an Analyst on your team who has great Technical Skills (but bad Soft Skills), Great Soft Skills (but bad Technical Skills), or Average at Both?",4,fo84cp,datascience,11,"What do you think??

[View Poll](https://www.reddit.com/poll/fo84cp)"
Predict a lot of y's,0,fo7sd5,datascience,7,"Hi guys, I am a bit new to this stuff and looking for some help on how to tackle this problem.

I have a dataset of departments, with clients (and their needs) and staff (and their hours) for each day. I am looking for a way to predict how much (in hours) of each 'type' of staff (likely based on their position in the team), given a set of expected clients and other factors. 

As far as I can tell, to predict the expected hours for every position type, requires a seperate model for every position type. My case is that there a lot of different positions, and potentially a very large amount of models to essentially create one dataset.

What is an efficient way to tackle this? Should I automate modelling for every y is there a better way to think about this problem?"
"Imagenet prediction decoder for simpler-labels. Ex: ""French_loaf"" (Keras) -> ""baguette"" (simple)",3,fo7qpv,datascience,0,
What is this kind of viz called and what tools are used to create it on an interactive map? Does anyone have tutorials or similar examples?,2,fo6fgm,datascience,3,
"If anyone is really into keyboard shortcuts like I am I just found a guide that has a ton of them for many IDE's. Includes: Python, Tableu, Excel, SQL, R, SAS, SPSS, Matlab & Stata.",665,fo5stq,datascience,38,"Edit: my first ever award! Thanks. Also apperently Stata isn't included. 

Not sure if its been posted before or not.

[https://365datascience.com/wp-content/uploads/2020/01/Shortcuts-for-Data-Scientists-2020.pdf](https://365datascience.com/wp-content/uploads/2020/01/Shortcuts-for-Data-Scientists-2020.pdf)"
Any recommendations for learning data visualization in R?,1,fo5i77,datascience,9,"Dear fellow colleagues, 
I want to hone my data visualization skills. I searched for courses online but i couldnt find any good course that is specialized in data visualization in R. If you have any recommendations about books or online courses i would be very happy to check them out. 

Thank you all"
Big data or data engineering for NLP?,0,fo3d8f,datascience,5,"I am trying to find if  it makes sense that they often happen together: NLP, and data engineering or big data techniques (e.g. Spark, Hadoop, and Scala)

One classic example in Hadoop MapReduce is word count. I guess that doesn't count as NLP.

1. In NLP industrial positions, do natural language data often need data engineering or big data techniques, i.e. do natural language data often come as ""big data""? 

   Internet search engines likely require big data of natural language, but I guess there  are very few Internet search engine job positions.  Do most information retrieval positions also need to worry about big data? How about  other NLP applications.?

2. Natural languages are unstructured data. However, https://www.dataversity.net/natural-language-processing-big-data-powerful-combination/ said in 2014:

  > As developed as big data analytics have become, they still really only excel at managing structured information.


  Have big data or data engineering techniques evolve for NLP already? If yes, how well are  NLP aware big data or data engineering techniques received in industry?


  Is it more often to convert natural language data to structured data, and then apply big data or data engineering techniques, or to apply  NLP aware big data or data engineering techniques directly to NLP big data?

3. Some other observerations and thoughts?

Thanks."
Call to Action to the Tech Community on New Machine Readable COVID-19 Dataset | The White House,5,fnww69,datascience,2,
Using a bad forecast to make a better one,1,fnt6dv,datascience,3,"I'm working on a project where I have a bad sales forecast from another company and I have the actual orders that same company sends in. The accruacy of the forecast is about 46%. 

I'll be building a time series model for this but I'm not really sure how to incorporate the forecast into my model. The 46% accuracy is way above the no information rate so it clearly has some signal but it's just a little weird to use a forecast to build a forecast...."
"Is blockchain useful for data engineering, big data and data science?",0,fnrspz,datascience,2,
Applying Data Science to test conspiracy theories,0,fnpo97,datascience,10,Is it possible to apply Data Science to validate the cospiracy theories like COVID19 outbreak being bio weapon ?
"I participated in my First ever ""Data Science competition"" in Analytics Vidhya. There are around 10353 registered candidates. I tried my best and got 1028 Rank Overall with 0.4791 F1 score. The person who is in Number 1 position his F1 score is 0.535.",0,fnp1cb,datascience,0,
What would you advise in terms of one research on COVID-19?,1,fno46k,datascience,7,"Hi everyone,

Regarding the global crisis, COVID-19, my company as one data consultancy focusing on healthcare professionals online conversation, decides to put all commercial projects aside and therefore we start innovation now. My pitch is to find out those useful and practical experience and mistakes China had got before. I'm Chinese so no trouble to understand Chinese. But I find difficulties in framing questions I would like to answer and collecting enough data ( in this case, I'm thinking to get conversations from popular sites and social media) My aim is to provide some insights from China practically.

It's quite vague actually, I have to admit. But I would love to hear what you guys are thinking. I really want to contribute some useful things to this situation.

&#x200B;

Thanks

&#x200B;

I've found a private group for healthcare professionals ( you can understand like Facebook group) .This is because there are too many noise out there. They do regular live broadcasts for sharing knowledge. How can I use this information?"
"Seeking collaborators with expertise in: data science, advanced signal processing, machine learning, computational modeling, graph-theoretic/network analysis",0,fnnbh7,datascience,0,"I am starting a new lab this fall at Florida International University (FIU). Our lab will focus on **understanding the neurocognitive processes that allow for the emergence of cognitive control** (how the human brain/mind monitors and adapts itself overtime to achieve task goals). Moreover, we will seek to understand how this system develops across adolescence, and relations to social behavior and social anxiety. Towards this end, methods that I currently employ, include: (single-trial) ERP analyses, time-frequency analyses of EEG (power and phase relations), source-localization of EEG, traditional fMRI approaches (GLM-based), and basic computational modeling (drift-diffusion models). Our lab is currently purchasing a high-density EEG system and FIU houses an fMRI scanner.

I am **seeking collaborators** that may or may not currently work in the fields of psychology or neuroscience, but that have at least some **expertise in one or more of the following domains: data science, advanced signal processing, machine learning, computational modeling, graph-theoretic/network analysis.** *I am most interested in finding collaborators that can help generate the best science; location, status, affiliation, or degrees earned are not important.* I also intend to take on at least one PhD student this fall and welcome responses from prospective students.

The scientific goal of this collaboration will be to combine skillsets in order to test novel hypotheses regarding the human cognitive control system, its developmental trajectory across adolescence, and relations to social behavior and social anxiety. At a practical level, we would seek to produce high-impact publications and to generate pilot data for pursuing collaborative grant proposals. **Depending on the situation, initial funding may be available for potential collaborators, consultants, or contractors.**

For examples of recent studies that will inform the work in our lab, please refer to the following publications:

[https://www.sciencedirect.com/science/article/abs/pii/S1053811919303696](https://www.researchgate.net/deref/https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS1053811919303696)

[Adolescent Cognitive Control and Mediofrontal Theta Oscillat...](https://www.researchgate.net/publication/339927980_Adolescent_Cognitive_Control_and_Mediofrontal_Theta_Oscillations_Are_Disrupted_by_Neglect_Associations_with_Transdiagnostic_Risk_for_Psychopathology_in_a_Randomized_Controlled_Trial)

[https://www.sciencedirect.com/science/article/abs/pii/S1053811917304445](https://www.researchgate.net/deref/https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS1053811917304445)

[https://www.jneurosci.org/content/37/11/2895.abstract](https://www.researchgate.net/deref/https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F37%2F11%2F2895.abstract)"
UC Berkley KPI Dashboard,1,fnmo0b,datascience,3,"UC Berkley KPI Dashboard.

Link: [https://public.tableau.com/profile/shah.pankaj#!/vizhome/MOM\_wk\_11/MOM\_wk\_12](https://public.tableau.com/profile/shah.pankaj#!/vizhome/MOM_wk_11/MOM_wk_12)

Feedback Welcome."
Your thought about a beginner's first project,3,fnln7a,datascience,8,"Hi, I'm a student 2nd class in Computer Science. This is my first project using Kaggle in Titanic Competition. This is not a final project, I will continue on this. Please leave your any thoughts about it. No matter it is positive or negative, I just want to hear.

[https://www.kaggle.com/erhanyumer/erhan-yumer-titanic-eda](https://www.kaggle.com/erhanyumer/erhan-yumer-titanic-eda)"
HOSPITAL ADDRESSES,0,fnlkgs,datascience,2,Anyone know if there is a public list of hospital addresses in the USA?
New D-Tale (free pandas visualizer) features released! Easily slice your dataframes with Interactive Column Filtering,335,fnli8n,datascience,51,
"Will studying NLP open up a wide range of opportunities, compared to other domains?",11,fnkrbh,datascience,16,"Different positions may have different domain knowledge.

I was wondering if studying NLP will open up a wide range of opportunities? How is NLP compared to other domains, in terms of amount of job opportunities?

Thanks."
Free Data Science Courses from 365 Data Science until 15 April 2020,55,fnk1oc,datascience,6,
Data Augmentation for Medical Tabular data,1,fnifaq,datascience,7,"How does one do Data Augmentation for Tabular Data? I am working with a breast cancer dataset that consists of roughly 500 record, I am planning to use one of the following, to model my data: RF, XGBoost, Lasso Regression followed by one of the above.. anyways I have been also told I should look into data Augmentation to improve my model's accuracy how should I do it with my type of data? Is there any state of the art methods to do data Augmentation to tabular data?

Also how do you think of my current pipeline for my model

Feature Selection (Example lasso, elasticnet) -> Data Augmentation -> Model -> Testing

Thanks and if anything I have said didn't make much sense feel free to tell me about it"
Effects of Weight Initialization on Neural Networks,1,fnhm36,datascience,0,
Beginner project for SQL. This is a simple python script to scrape stock prices off NASDAQ API and feed it to MySQL.,759,fnh8zm,datascience,59,
How will a recession effect data science jobs?,0,fnfio8,datascience,1,"Covid-19 has caused the economy to take a nosedive and it doesnt seem to be getting anybetter, at least not within the next 3 months.

Im curious as to what everyone thoughts are for data science jobs and how they will be affected in a possible recession?"
How do open source licenses work? (Specifically GPL-3.0 and MIT),3,fndd9c,datascience,1,"I'm currently trying to figure out how open source licenses work especially in the context of open source data science tools in Python, and from what I've read, the GPL-3.0 license is supposed to be a copyleft license where derivative works would also have to be under the same license (or similar).  

However, I think I found an exception to this and I don't know if it's because of me misinterpreting the license or if it's an error on the library creators' side?  

[Pystan](https://github.com/stan-dev/pystan) is under the GPL-3.0 license, so I would think that any open source package that uses it would also need to be under the same license. However, [fbprophet](https://github.com/facebook/prophet) in Python uses Pystan and is under the less restrictive MIT license. Can someone clear this up for me so I can understand why this is the case?

Thanks."
Create Smart Maps In Python and Leaflet,0,fnd6k5,datascience,0,"If you want to, check it out below:

[https://www.udemy.com/course/create-smart-maps-in-python-and-leaflet/?referralCode=4C1B6A9A84779984DF62](https://www.udemy.com/course/create-smart-maps-in-python-and-leaflet/?referralCode=4C1B6A9A84779984DF62)

https://preview.redd.it/w27pbfypdco41.jpg?width=2496&format=pjpg&auto=webp&s=3072272588709822ccce18b5a964d06cd610fc39"
How to decide which terms to include in a linear regression?,15,fncwi5,datascience,15,"When you're fitting a linear regression, how do you decide which terms to include in the regression? As the number of variables increases, the number of possible interaction terms and polynomial terms increases exponentially, so how do you decide which ones to include which guarding against overfitting?"
Free Mathematics Courses for Data Science & Machine Learning,478,fn9414,datascience,21,"It's no secret that mathematics is the foundation of data science. Here are a selection of courses to help increase your maths skills to excel in data science, machine learning, and beyond.

https://www.kdnuggets.com/2020/02/free-mathematics-courses-data-science-machine-learning.html

By Matthew Mayo, KDnuggets.


Are you interested in learning the foundations to a successful data science career? Or are you looking to brush up on your maths, or strengthen your understanding by extending that base?

This is a selection of maths courses, collections of courses, and specializations which are freely available online, and which can help achieve your data science mathematics goals. They have been separated into the broad topics of mathematical foundations, algebra, calculus, statistics & probability, and those especially relevant to data science & machine learning.

Take a look at the list and closer inspect those which may be of interest to you. I hope you find something useful.

 
Mathematical Foundations

These courses are intended to help lay the foundation for learning more advanced maths, as well as foster the development of mathematical thinking. Descriptions come directly from the respective course websites.

Introduction to Logic, Stanford (course)
This course is an introduction to Logic from a computational perspective. It shows how to encode information in the form of logical sentences; it shows how to reason with information in this form; and it provides an overview of logic technology and its applications - in mathematics, science, engineering, business, law, and so forth.

Introduction to Mathematical Thinking, Stanford (course)
Professional mathematicians think a certain way to solve real problems, problems that can arise from the everyday world, or from science, or from within mathematics itself. The key to success in school math is to learn to think inside-the-box. In contrast, a key feature of mathematical thinking is thinking outside-the-box – a valuable ability in today’s world. This course helps to develop that crucial way of thinking.

High School Mathematics, MIT (collection of courses)
In this section we have provided a collection of mathematics courses and resources from across MIT. Some are materials that were used to teach MIT undergraduates, while others were designed specifically for high school students.

 
Algebra

These algebra courses run the gamut from introductory algebra to linear models and matrix algebra. Algebra is helpful in computation and data science generally, and encompasses some of the main concepts in powering some machine learning algorithms, including neural networks. Descriptions come directly from the respective course websites.

Algebra I, Khan Academy (course)
Course covers algebra foundations, solving equations & inequalities, working with units, linear equations & graphs, forms of linear equations, systems of equations, inequalities (systems & graphs), functions, sequences, absolute value & piecewise functions, exponents & radicals, exponential growth & decay, quadratics (multiplying & factoring), quadratic functions & equations, irrational numbers.

Algebra II, Khan Academy (course)
Course covers polynomial arithmetic, complex numbers, polynomial factorization, polynomial division, polynomial graphs, rational exponents & radicals, exponential models, logarithms, transformations of functions, equations, trigonometry, modeling, rational functions.

Linear Algebra, MIT (course)
This is a basic subject on matrix theory and linear algebra. Emphasis is given to topics that will be useful in other disciplines, including systems of equations, vector spaces, determinants, eigenvalues, similarity, and positive definite matrices.

Linear Algebra - Foundations to Frontiers, University of Texas at Austin (course)
Through short videos, exercises, visualizations, and programming assignments, you will study Vector and Matrix Operations, Linear Transformations, Solving Systems of Equations, Vector Spaces, Linear Least-Squares, and Eigenvalues and Eigenvectors. In addition, you will get a glimpse of cutting edge research on the development of linear algebra libraries, which are used throughout computational science.

Introduction to Linear Models and Matrix Algebra, Harvard (course)
In this introductory online course in data analysis, we will use matrix algebra to represent the linear models that commonly used to model differences between experimental units. We perform statistical inference on these differences. Throughout the course we will use the R programming language to perform matrix operations.

 
Calculus

These calculus courses cover topics from preparatory precalculus through to differentiation, integration, to multivariate calculus and differential equations. Calculus has broad uses, generally, and contains core concepts which power neural networks work. Descriptions come directly from the respective course websites.

Precalculus, Khan Academy (course)
Course covers complex numbers, polynomials, composite functions, trigonometry, vectors, matrices, series, conic sections, probability and combinatorics.

Calculus 1, Khan Academy (course)
Course covers limits and continuity, derivatives: definitions and basic rules, derivatives: chain rule and other advanced topics, applications of derivatives, analyzing functions, integrals, differential equations, applications of integrals.

Calculus 2, Khan Academy (course)
Course covers integrals review, integration techniques, differential equations, applications of integrals, parametric equations, polar coordinates, and vector-valued functions, series.

Multivariable calculus, Khan Academy (course)
Course covers thinking about multivariate functions, derivatives of multivariate functions, applications of multivariate derivatives, integrating multivariate functions, Green's, Stokes', and the divergence theorems.

Differential equations, Khan Academy (course)
Course covers first order differential equations, second order differential equations, Laplace transform.

Introduction to Calculus, University of Sydney (course)
The focus and themes of the Introduction to Calculus course address the most important foundations for applications of mathematics in science, engineering and commerce. The course emphasises the key ideas and historical motivation for calculus, while at the same time striking a balance between theory and application, leading to a mastery of key threshold concepts in foundational mathematics.

 
Statistics & Probability

Statistics and probability are the foundations of data science, more so than any other family of mathematical concepts. These courses will help prepare you to look at data through the statistical lens and with a critical probabilistic eye. Descriptions come directly from the respective course websites.

Statistics and probability, Khan Academy (course)
Course covers analyzing categorical data, displaying and comparing quantitative data, summarizing quantitative data, modeling data distributions, exploring bivariate numerical data, study design, probability, counting, permutations, and combinations, random variables, sampling distributions, confidence intervals, significance tests, two-sample inference for the difference between groups, inference for categorical data, advanced regression, analysis of variance

Fundamentals of Statistics, MIT (course)
Statistics is the science of turning data into insights and ultimately decisions. Behind recent advances in machine learning, data science and artificial intelligence are fundamental statistical principles. The purpose of this class is to develop and understand these core ideas on firm mathematical grounds starting from the construction of estimators and tests, as well as an analysis of their asymptotic performance

Data Science: Probability, Harvard (course)
We will introduce important concepts such as random variables, independence, Monte Carlo simulations, expected values, standard errors, and the Central Limit Theorem. These statistical concepts are fundamental to conducting statistical tests on data and understanding whether the data you are analyzing is likely occurring due to an experimental method or to chance.

Probability - The Science of Uncertainty and Data, MIT (course)
The course covers all of the basic probability concepts, including: multiple discrete or continuous random variables, expectations, and conditional distributions, laws of large numbers, the main tools of Bayesian inference methods, an introduction to random processes (Poisson processes and Markov chains)

Improving your statistical inferences, Eindhoven University of Technology (course)
First, we will discuss how to correctly interpret p-values, effect sizes, confidence intervals, Bayes Factors, and likelihood ratios, and how these statistics answer different questions you might be interested in. Then, you will learn how to design experiments where the false positive rate is controlled, and how to decide upon the sample size for your study, for example in order to achieve high statistical power. Subsequently, you will learn how to interpret evidence in the scientific literature given widespread publication bias, for example by learning about p-curve analysis. Finally, we will talk about how to do philosophy of science, theory construction, and cumulative science, including how to perform replication studies, why and how to pre-register your experiment, and how to share your results following Open Science principles.

Introduction to Probability and Data, Duke University (course)
This course introduces you to sampling and exploring data, as well as basic probability theory and Bayes' rule. You will examine various types of sampling methods, and discuss how such methods can impact the scope of inference. A variety of exploratory data analysis techniques will be covered, including numeric summary statistics and basic data visualization. You will be guided through installing and using R and RStudio (free statistical software), and will use this software for lab exercises and a final project. The concepts and techniques in this course will serve as building blocks for the inference and modeling courses in the Specialization.

Probability Theory and Mathematical Statistics, Penn State (course)
Courseware for a pair of related courses covers introduction to probability, discrete distributions, continuous distributions, bivariate distributions, ditributions of functions of random variables, estimation, hypothesis testing, nonparametric methods, bayesian methods, and more.

 
Mathematics for Data Science & Machine Learning

These are mathematics topics directly related to data science and machine learning. They may include material from courses above, and may also be more elementary than some of above as well. However, they can be useful for brushing up on material you may not have studied in a while, and which is especially pertinent to the practice of data science. Descriptions come directly from the respective course websites.

Data Science Math Skills, Duke University (course)
Data science courses contain math—no avoiding that! This course is designed to teach learners the basic math you will need in order to be successful in almost any data science math course and was created for learners who have basic math skills but may not have taken algebra or pre-calculus. Data Science Math Skills introduces the core math that data science is built upon, with no extra complexity, introducing unfamiliar ideas and math symbols one-at-a-time.

Essential Math for Machine Learning: Python Edition, Microsoft (course)
This course is not a full math curriculum; it's not designed to replace school or college math education. Instead, it focuses on the key mathematical concepts that you'll encounter in studies of machine learning. It is designed to fill the gaps for students who missed these key concepts as part of their formal education, or who need to refresh their memories after a long break from studying math.

Mathematics for Machine Learning, Imperial College London (specialization)
For a lot of higher level courses in Machine Learning and Data Science, you find you need to freshen up on the basics in mathematics - stuff you may have studied before in school or university, but which was taught in another context, or not very intuitively, such that you struggle to relate it to how it’s used in Computer Science. This specialization aims to bridge that gap, getting you up to speed in the underlying mathematics, building an intuitive understanding, and relating it to Machine Learning and Data Science."
"This corona thing is pretty lame, but this is America. I want to help out, but not by doing pseudoscience with no understanding of epidemiology. Maybe I could help manufacturers of related medical materials or help with logistics/planning, etc. using big data. Any ideas?",0,fn8elh,datascience,5,Anyone know of any such opportunities?
What areas of data do industrial data science jobs often work on?,1,fn5n91,datascience,3,"Data science can be used on all kinds of data. Different kinds of data have their own domain knowledge. From job opening perspective, I was wondering what kinds/areas of data do industrial data science jobs often work on, and what less often? For example, apology that my categorization might be off,

- any numbers 
- time series 
- Text with little or without NLP knowledge, 
- Text with NLP knowledge,
- Images with little or without computer vision knowledge
- images with computer vision knowledge
- ...

My interests are tech companies, financial companies, but not limited to.
Thanks."
job searching during COVID-19,0,fn4zoq,datascience,6,"I got my Masters in ECE from a good school 2 years ago, and I did an internship as a data scientist. After graduating I got data science offers but I ended up taking a job at a manufacturing site at a well known Fortune 100 company due to the high offer. I thought it'd be interesting to apply machine learning to a production environment. Unfortunately, only about 20% of my work deals with machine learning or data science.

Worst part is, the environment I'm in frowns upon working from home, even during this COVID-19 crisis. I really want out, and get a data science position in the next 3 month, preferably out in the West Coast but I'll take anything that's decent. I'm seriously considering quitting. I got $100k saved so I should survive for awhile. Just wonder how bad it's gonna look to future employers, and also I don't know the time frame to get a data science job in this recession... Has this virus impacted your job search so far?

Advice?
thanks"
Has anyone moved from IT to data science?,5,fn3yrh,datascience,8,I am thinking about going back to college and getting my masters in data analytics.  I will be nearly 40 when I finish the masters program.
I have the opportunity to write a research paper in one of my classes but I'm having a hard time choosing which topic would be valuable to cover. Any advice?,1,fn2ius,datascience,3,"Hello.

So in my Artificial Intelligence class I got the opportunity to write a paper (neural networks). I would like to write something beneficial and valuable not just something plain and totally useless, covered over and over again.

I'm trying to get more into this field and so far I really enjoy it. But I'm in no way a professional so I thought I'd ask for some ideas here because I of course also looked for ideas myself but so far nothing, I'd think is appropriate for this. 

What area could I cover? What would be an awesome project?"
Weekly Entering & Transitioning Thread | 22 Mar 2020 - 29 Mar 2020,4,fmyug3,datascience,99,"_Bleep Bloop_. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki. You can also search for [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).

---

I am a bot created by the r/datascience moderators. I'm open source! You can review my [source code on GitHub](https://github.com/vogt4nick/datascience-bot)."
Why use logarithm ?,1,fmyt50,datascience,9,"Hi everyone!

On the Johns Hopkins map to see the evolution of the Coronavirus ( https://coronavirus.jhu.edu/map.html ), they plot the actual number of cases and recoveries but they also plot the same graph but using the logarithm

A friend of mine told me that it's to better see ""the speed"" of how those curves evolve but I really have trouble to understand what is the reality behind

Like in the ""Actual"" plot, the yellow curve seems to be at almost 0 until mid February, yet in the ""Logarithmic"" plot it went off from the beginning
Ok the log function is more significant for lower values but in that case does it really represents the speed of its evolution?

Thanks for your attention, stay home and safe 👊"
[COVID-19] How to estimate the current number of cases for the countries that have inadequate/unreliable data?,0,fmydog,datascience,3,"Hello everyone! Any opinions on how to calculate a probabilistic estimate of number of existing cases for a country/city given the data for neighboring countries?

I live in a country in which the government is being dishonest. The tests-per-million is about 100s and therefore number of confirmed cases is very low. The government declares this as a success but IMO it's actually way more. They don't declare the location of confirmed cases or any other stats.  What's worse is that the people do not get how serious the situation is and they act nonchalantly. 

It would be great if a simple and convincing model could give estimates on actual cases."
SQL and Coding interview questions - and answers,348,fmxjxg,datascience,32,"I added technical interview questions for data science positions: SQL, coding, algorithms.

It's in the same GitHub repository, so feel free to add the answers

[https://github.com/alexeygrigorev/data-science-interviews/blob/master/technical.md](https://github.com/alexeygrigorev/data-science-interviews/blob/master/technical.md)

&#x200B;

&#x200B;

Previous list with theoretical questions: [https://www.reddit.com/r/datascience/comments/fcj5jo/data\_science\_interview\_questions\_and\_answers/](https://www.reddit.com/r/datascience/comments/fcj5jo/data_science_interview_questions_and_answers/)"
Relevance of tests in whole population.,1,fmv68f,datascience,1,"Hello.

I have a basic stat question for data scientists. I work in retail and was working on evaluating promotional campaign. We generally measure performance through comparing nom promotion and promotion period. Since I have whole details of all the transactions, does it make sense to run Wilcoxon or T test when I am not dealing with a sample?

In my case I will always have transaction details of whole customer base , so are the basic calculations like basket size, average transactions size best measures or can I still run some tests on them ( i usually also check for outliers and that's about it)."
Data science master’s degree,4,fmsg61,datascience,13,"Hello,

I was recently accepted to Rochester’s data science master’s degree and to Gatech’s analytics master’s degree. It is almost impossible for me to decide between these 2, so I thought I should ask for the opinion of my fellow redditors. Lastly, I would like to ask how difficult it will be for an international student to find work after the completion of the master’s degree and to obtain an h1b visa. 

Thank you for your help :)"
What's wrong with this calculations/app?,1,fmsfmw,datascience,3,"So someone, decided to help and make this little app, but it does a really good job of showing privilege and the simplifications that people assume. 

So based on the last post about coronavirus and the recommendation of data scientists not participating because we don't have Subject Matter Expertise, let's play a game : 

What's wrong with it? 

What's missing? 

&#x200B;

There's a few big ones that jumped out at me, curious as to what others think because I'm obviously going to miss things as well. 

&#x200B;

[https://howmuchtoiletpaper.com/](https://howmuchtoiletpaper.com/)"
Practice Interview?,0,fmq78a,datascience,6,"Hello everyone,

I have been preparing quite a lot to interview for full time positions by practicing lots of SQL, python, general product sense questions, when to use what algorithm, tradeoffs, general things about my resume, myself, etc. Bascially I am trying to leave no stone unturned when it comes to what could be asked in an interview (specifically the FB Data Science, Analyst interview, which I will be scheduling soon. I've already read the threads about this specific interview in the sub. As a disclaimer, I'm not looking for NDA info, just prep in general). A little more context about myself: I'll be graduating in June with a B.Eng in Business Informatics and have been working in a Data Science position for a business consulting agency (not USA) for a little less than a year now. 

Now I'm aware one thing is knowing about something and another is being able to communicate / demonstrate in an interview setting, so I have been looking for places to have practice interviews (websites mostly). I have found a couple (e.g. Pramp) but would love to hear this community's recommendations, what has worked for you, etc.

Also, if anyone is willing to practice interview me I have no problem with paying.

Thank you very much and stay safe!"
"For any python data scientists out there, here's an interactive dashboard demo of what you can build with very few lines of code",52,fmohpm,datascience,17,"I contribute a Python Interactive Dataviz Covid-19 Dashboard - it's open source, has very little code, true interactive features including animating timeline & plot interaction (see 'about this dashboard), John Hopkins data, updates daily - open for contribution and ideas, or happy to do a demo/tutorial article or webinar if any interest.

[https://covid19-dash.herokuapp.com](https://covid19-dash.herokuapp.com/)

https://preview.redd.it/fx15ehajw3o41.png?width=2880&format=png&auto=webp&s=d5f1d9f75320acf1908cfa78dfa8f313fa534c50"
Project Interview with only Categorical data. Need ideas to impress.,1,fmlyzw,datascience,3,"I have an interview coming up next week where I have to present findings from a large dataset on insurance claim denials. It is, however, except for monetary values, all categorical data.

I definitely want to impress, but I am worried that with basically only categorical (non-numeric) data all I can do is make basic histograms, pie charts.

What are some cool ideas for visualizations/stats that can be used for categorical data?

I use Python btw.

Edit: There, unfortunately, isn't data on claims that were accepted so I can't find rates per insurance company and stuff like that. It's only the denials."
Resources for Topological Data Analysis,6,fmko1i,datascience,1,"Hello! I am a Master's student in Data Science who has a lot of background in applied mathematics, but not so much in topology. I became interested in TDA recently, and I'm interested in using this unexpected free time to explore the field. Do you have useful resources to learn the fundamentals of the area for someone with a strong foundation in math, but not in topology? Should I start by picking up a topology book first? Thanks."
"If you could have someone walk you through any data science project—beginning to end, step by step—what would you want to learn?",2,fmk7p8,datascience,6,"For example: ""I would want to see a business use case for a recommendation engine beginning to end"", or ""I would want to build an autonomous vehicle beginning to end"", or ""I would want to build a language model like GPT-2"", etc etc."
"My boss proposes infeasible projects and doesn’t like confrontation, advice?",171,fmjmno,datascience,59,"Hey guys, so I’m working as a Data Scientist in real estate. My boss proposes projects with insanely large data he’s thrown into google big query. 

He has a very limited background in CS and I’ve had to optimize a lot of his code / ETL pipelines just to make everyone else’s life easier. He got the position as it’s a group of friends who started the company, designated himself as the head of data science.

He’s proposing ideas that, in an optimal setting with a large budget, it would be feasible. I’ve talked to him about it and he’s dismissed my concerns. 

Alarming extra concerns: 
1) he was amazed that I used terminal.
2) he doesn’t understand basic linear algebra. 

I’m concerned for my safety in the company. If I can’t fulfill my boss’ project proposals / ideas, I’ll be let go. 

Please, I’d love some advice. Thanks Gang!"
"Data Against Covid-19: ""We are a community of medical professionals, life scientists and data scientists on a quest to defeat COVID-19.""",111,fmj74a,datascience,7,
How do you peer review Data Science projects?,0,fmi3ib,datascience,0,"Hey everyone. :)

I'm Shay (written erroneously; pronounced Shy), a data science consultant out of Israel.

I've been dedicating a lot of thought to peer review in small data science teams (like the ones I use to run, and now consult to). Sure, some of it entails reviewing code, but a lot of our work products and processes are different, and require, I believe, a dedicated peer review process.

I'd love to hear your thoughts on the topic. Is peer review a regular part of the work process in your team? Have you reviewed or been reviewed by a peer? What is your approach? What do you feel is still missing? Have you encountered any structured approaches to this process that are unique to DS/ML teams - especially small ones, where 1 project = 1 data scientist?

If you're interested in my approach so far - which we have started implementing at one of my clients', and I've actually reviewed a DS project using this procedure - you are more than welcome to take a look at this blog post, and shout at me for all of my mistakes (friends link, so no paywall): 😗  
[https://medium.com/@shay.palachy/peer-reviewing-data-science-projects-7bfbc2919724?source=friends\_link&sk=914d618224f713cbcabf1f6ead3ba3d9](https://medium.com/@shay.palachy/peer-reviewing-data-science-projects-7bfbc2919724?source=friends_link&sk=914d618224f713cbcabf1f6ead3ba3d9) 

Cheers (and Coronavirus),  
[Shay](http://www.shaypalachy.com/)"
Should I avoid using higher dimension graphs?,1,fmg35z,datascience,9,"Are higher dimension graphs harder to interpret?

For example, instead of using house price vs space vs location, should I use 4 separate 2D graphs?

North: house price vs space

East: house price vs space

West: house price vs space

South: house price vs space"
Best countries to immigrate to as a Data Scientist - from Iran!,0,fmdzhr,datascience,23,"Hey Everyone,

So after a decade of work as an economic analyst, business analyst and data scientist in Iran, I have come to realize that the local economy has zero interest in transforming into a more data-driven state. Data resources are scarce and something as crucial as EDA is frowned upon out of fear that it may expose financial corruption, contradict government-provided statistics, etc. The most exciting thing that could happen in a data scientist’s life here is creating recommender systems for e-commerce platforms, the ones that have not gone under as results of sanctions anyway.

Situation is so severe that the job search term “Data Scientist” which returns tons of opportunities for other nations, offers next to nothing in Iran (Try this with LinkedIn yourselves for an impression of what I am talking about.)

I’m 32, B.Sc. in Industrial Mathematics, M.Sc. in Industrial Engineering, (specializing in Technology Foresight and Sustainable Development) both from top technology schools in Iran. I do have a fairly solid track record in quantitative business analysis/development.

This great community has always helped me make informed decisions. I would welcome any advice as to which countries offer better prospects for an aspiring data person. I do realize that I may have to start by interning at a new company overseas and I am humble enough to do just that.

Thank you!"
Best data science specialization on coursera,22,fm8hmu,datascience,25,Title says it all. Which is the best one? I’m considering the Johns Hopkins 10 course one. Thoughts folks?
I have a challenge!,0,fm64st,datascience,7,"Hello fellow Data Scientists,

I'm gonna ask broad questions to try to gather as much feedback as I can and then decide what to do. Everything is a possibility at this stage, there are no right or wrong. I have some data background but it's not relevant and that's why I'm a bit stuck with my thoughts.

**Objective:** Create kind of an Hackaton/program with a company where at the end of the day Data is transformed into relevant business insights. Those insights will be capitalized to generate possible new business models.

**Some questions about:**

**People:** 

\- Should we have several teams working with data? how many people per team, 1 or more? how can they work together - can we assign several roles like: 1 to cross data, 1 to clean the data, etc (is this stupid? lol) ?

\- Are these people data scientists only? Should we have 1 business guy per team to give a different perspective?

\- Should we have Data Scientists in the morning and then business people during the evening?

**Data:** 

\- Should we start with raw data?

\- All the teams should start with the same Data?

\- Should we try to cross data from company with some public government data or other sources?

**Program:** 

\- A morning, 12h, 24h, 2 days? How much time do we need?

\- Should we specify some avenues to explore or let them search for everything?

\- What are the things I have to take into account?

&#x200B;

I Know this is all too broad, vague, open and your answer will be ""It all depends on what you want"", but what I need here is your expertise and sensitivity. If it was you, what would you do, how and why? Do you have anything that had been done before as a good example?

Thank you so much!"
Modeling the Economic Cost of COVID-19 Under Various Scenarios (Concept) - Your Thoughts,2,fm3ft4,datascience,5,"Hey guys,

Just read this article about how there may be more targeted methods to mitigate COVID-19 than a blanket shutdown of society. Maybe re-open businesses to people less than 50 and no heightened risk to the disease once testing is up and running. [https://www.nytimes.com/2020/03/20/opinion/coronavirus-pandemic-social-distancing.html](https://www.nytimes.com/2020/03/20/opinion/coronavirus-pandemic-social-distancing.html?action=click&module=Opinion&pgtype=Homepage&fbclid=IwAR0eaGByXfSSxZuexkxqBiEDvYh9BNBpRfhd0x9iWiES80NkqeO8dXDMwMc)

I thought it could be something interesting to design an economic model of - how different approaches could play out in the larger economy. There are a lot of posts right now telling data scientists to stay in their line right now and leave it to the experts, though, so maybe I’m speaking out of turn. Thoughts?"
Portfolio Project Presentation,5,fm2u10,datascience,1,"This is kind of similar to u/Busy-Chipmunk 's recent post.

I am currently creating my website(using Github Pages) for my portfolio and I am curious how I should present my projects. My idea is to have separate pages for each project where the ""final product"" is shown at the top with some description and then layout the process I took for the project on the rest of the page. 

Is this a good idea? Should I present only the final project itself? Maybe link to another page which shows the process in a blog style?

Any suggestions are helpful, thank you."
"To All ""Data Scientists"" out there, Crowdsourcing COVID-19",972,fm17ja,datascience,182,"Recently there's massive influx of ""teams of data scientists"" looking to crowd source ideas for doing an analysis related task regarding the SARS-COV 2 or COVID-19.

I ask of you, please take into consideration data science is only useful for exploratory analysis at this point. Please take into account that current common tools in ""data science"" are ""bias reinforcers"", not great to predict on fat and long tailed distributions. The algorithms are not objective and there's epidemiologists, virologists (read data scientists) who can do a better job at this than you. Statistical analysis will eat machine learning in this task. Don't pretend to use AI, it won't work.

Don't pretend to crowd source over kaggle, your data is old and stale the moment it comes out unless the outbreak has fully ended for a month in your data. If you have a skill you also need the expertise of people IN THE FIELD OF HEALTHCARE. If your best work is overfitting some algorithm to be a kaggle ""grand master"" then please seriously consider studying decision making under risk and uncertainty and refrain from giving advice.

Machine learning is label (or bias) based, take into account that the labels could be wrong that the cleaning operations are wrong. If you really want to help, look to see if there's teams of doctors or healthcare professionals who need help. Don't create a team of non-subject-matter-expert ""data scientists"". Have people who understand biology.

I know people see this as an opportunity to become famous and build a portfolio and some others see it as an opportunity to help. If you're the type that wants to be famous, trust me you won't. You can't bring a knife (logistic regression) to a tank fight."
"Publishing, tracking and sharing data visualizations",34,fly6z5,datascience,9,"Hey Reddit, 

A few months ago, I asked a question on the forum -  [https://www.reddit.com/r/datascience/comments/ekawho/how\_do\_you\_track\_and\_share\_your\_data\_reports/](https://www.reddit.com/r/datascience/comments/ekawho/how_do_you_track_and_share_your_data_reports/)   
Based on your feedback, I and my friends have now built a free tool that can be used to publish, track, and share data visualizations via APIs from anywhere (a Jupyter notebook, a script or an application) and store them in our web application (which is also mobile friendly). The current version supports Python and R as programming languages, and Matplotlib, Ggplot2, Plotly and Bokeh as plotting libraries.   
Here is a tutorial on how to use the library with the help of an example.   
 [https://medium.com/dstackai/analyzing-the-speed-of-spread-of-covid-19-and-publishing-findings-on-dstack-ai-396cd588c867](https://medium.com/dstackai/analyzing-the-speed-of-spread-of-covid-19-and-publishing-findings-on-dstack-ai-396cd588c867) 

We think there is a lot more one can offer to improve the current process of a collaborative exploration of data visualization for teams. As basic as our current solution is, we are currently working on releasing new features such as - Organizing the charts into dashboards - User groups and permission management - Plugins for spreadsheets such as Google docs and MS Excel - Dynamic plots and dashboard that fetches data from a data source and can be scheduled to update regularly - A mobile application to access the visualizations, - On-prem options

We would love to hear about your challenges in the area of collaboration around data visualization, and receive any feedback on what we currently have."
State of the art techniques to get the most important feautures in a feature set of medical data,0,flume7,datascience,16,"I am working on a breast cancer dataset, and I have a ton of variables in my disposal, what are the state of the art techniques to get the variables that are most significant"
Personal website?,31,fls6b6,datascience,13,"This might be a silly question, but I'm very curious as to how data scientists (assuming no background in Java or HTML/CSS)  build their personal websites. Do you use platforms like SquareSpace to get the template and the domain? 

Or is there a popular, easy way of building your own website that I'm missing out on?

Also, is there a particular style/conventions that data scientists tend to follow in building their website?"
Need advice regarding on going tussle in Data Science department at office.,9,flqw28,datascience,5,"Hi,

I am working as Data Scientist for 2 years in a startup in Bangalore, including internship where most of my work had data cleaning and data wrangling profile. It has been 1.5 years working as one. Now, the current scenario due to funding and new clients has shifted towards more challenging projects. One of them is Super Resolution and OCR (Japanese, has very little literature to go through ) and Super Resolution for text images for English and Japanese (again , a challenging and subjective as per buisness problem). The thing is the management thinks that if a paper is published for super resolution it will work on our data too, plus the Data science manager is sort of ""yes sir"" guy and makes us work on simply hit and trial, as of two years one thing I am sure that Data Science is not just simply trying anything till we reach accuracy without going through in details. The learning curve has just gone down to trying tessarct, kraken etc and same goes for Super resolution, just feed the data and see it works or not. I want to tell the management that it is not worth and we need a better resource on ML and DL who can actually break it down and guide us in a more logical and systematic direction instead of just trying different paper with a dataset which is exactly opposite to ours and trying random things (frameworks, just any random paper published). Now, if I say it directly, it won't go down well with my Data Science manager and if I don't I will have to suffer doing it again and again or eventually fired because I am sure we are not progressing in any direction. What should I do?"
Excel pre req to SQL?,0,flpf4a,datascience,4,Is Excel a Pre Req to learning SQL or should I just jump into the fire and learn sql right off the bat?
"Novice Data Scientist, by Expert Front-End Developer (MERN)",0,flmzqf,datascience,0,"I see all these brilliant minds posting here about their findings, and as a novice data scientist with under 1 year of analysis and NO medical data experience, I feel useless. 

That said, if any of you have databases set up and want some way to visualize it and distribute it, I’d love to offer my help. I want to do *something* to help with this massive open-source research of the pandemic!"
Johns Hopkins CSSE,1,flkeco,datascience,3,"I was just playing around with this for fun, and figured maybe someone else would potentially find it useful:
[Link to data](https://github.com/CSSEGISandData/COVID-19). There are 3 datasets: confirmed cases, deaths, and recovered. This is updated daily.


The data I found had dates as individual columns, and I wanted to transform it so the dates were all in one column. There is without a doubt a much easier way to do this, but here is what I did if you want to use it: [PYTHON CODE](https://pastebin.com/0W2ZEk0h)


Maybe the code sucks, but points for creativity, right? Lol"
CORD-19 Dataset exploration and indexing,3,flk2h5,datascience,3,
Structural Equation Modelling is fascinating. But can data only be used if on some sort of Likert scale?,1,flk097,datascience,1,
Crowd-sourced COVID-19 Dataset Tracking Involuntary Government Restrictions (TIGR) Need Help!,5,flj5ht,datascience,1,
How can Data Science be Instrumental in Combating Corona Outbreak?,0,flivdn,datascience,0,
Waymo blog: Announcing Waymo’s Open Dataset Competitions,1,flieew,datascience,0,
Data science consultant hourly rate - US customer,1,flhlpr,datascience,7,"Hi,

Based in northern Europe, I am a data scientist with 10 years experience from energy, financial and retail. I am going to do some evening and weekend consultancy for a company in the US, where I will develop algorithms for anomaly detection, up to 8 hours a week. What is a normal hourly rate range for such a setup? I have read all from $100 to $300, but I hoped for a more narrow window. Any consultant here, or someone experienced hiring consultants? Here it is common to be around $150 for long-term projects for experienced DS no matter what the project complexity is."
Crowdsourced local COVID-19 policy databank,1,flgwjo,datascience,1,"We know what nations, states and major cities are doing, but smaller towns and communities lag behind. This is an attempt to crowdsource that information for posterity.

[https://forms.gle/bwjWRD6KKkSFLRLu8](https://forms.gle/bwjWRD6KKkSFLRLu8)"
I created a Corona Dashboard. Let me know what you guys think.,0,flguyt,datascience,5,
"I want to work with spectral audio data for music information retrieval, what toolsets should I be using? Is MySQL a good tool for storing FTTs?",1,flgt69,datascience,0,
"""Holdout Set"" on Aggregated Data",1,flex80,datascience,7,"I have a dataset similar to this:

Age | Gender | Average Conversion Rate | Number of Records
---|---|----|----
18-25 | M | 0.04 | 292
25-35 | F | 0.06 | 105


and I want to predict conversion rate. Doing a train/test/validation split doesn't work well here because dropping a ""record"" would mean dropping an entire combination of predictors. Anyone have advice on how to approach this problem? It's straightforward enough to use the ""Number of Records"" as weights but I'm cautious of overfitting."
CORD-19: The Data Science Response to COVID-19,1,flesox,datascience,1,
Open csv Ontario COVID-19 data,2,fle8u5,datascience,1,
User-Level Prediction Based on Post History,3,fle23m,datascience,5,"Im working on a deep learning project that aims to make a categorical prediction on a user-level based on their Reddit post history. So for example, if the label categories are {not_depressed, mild_depression, depressed, suicidal}, the chosen label has been assigned to a user based on the totality of their posts.

Each row of my dataset is an individual post. Some users have up to 500 posts, some have as low as 10. If I concatenate the posts together based on user, the assigned label is accurate but the text sequence length is far too big (average 5k words after cleaning and removing a lot of words). If I don't concatenate but learn based on individual posts, the text sequences are an appropriate size (avg 30 words) but then the model thinks the label is assigned on a post level.

Any tips?"
Good resource for correlation,1,fldx1w,datascience,4,"Hello, I feel like everywhere I look I find short articles about correlation but I don't feel like I have a deep understanding. Does anyone know a good resource?"
Pro-Bono Data Science help for Covid-19?,5,fldiyx,datascience,12,"Hey all,

I'm wondering if anyone knows of areas where a data scientist could help, pro-bono, with Covid-19 response in any way?  I've seen the Kaggle comp and some colleagues and I are probably going to try and get involved but was wondering if there are other areas to help.  Been reading about folks trying to work around ventilator/maks/etc. shortages with new designs/production methods, and things like that.  I figure there must be something data science-oriented folks can do (code review even?).

Cheers

UPDATE:  Hey all, I posted to r/medicine and got this link: https://www.reddit.com/r/COVIDProjects/ Probably a great place to start! I think we could continue to use this thread to circulate/post about data science oriented Covid-19 projects. If folks also think of things they haven't seen yet and want help, post here.

One idea I had was developing R-Shiny/Flask code that cities/counties could plug in their own case data + local shapefile and run that portable code to create a useful tracking/viz tool? I.e a locality oriented JHU type thing, but open-source?

UPDATE 2: https://coronavirusarmy.org/ seems like it could be a good spot too!"
"Intermediate SQL Series going over Joins, Unions, Case Statements, Data Types and more - Hope it helps!",15,flcxag,datascience,4,"Hey everyone - I just created the first of my Intermediate SQL Series videos. I go over joins and some use cases on how to use them. I would love for you to check it out and give me any feedback on it. 

I have almost all of them recorded already and will be uploading them each week. The topics include Joins, Unions, Case Statements, Updating/Deleting Data, Partition By, Data Types, Aliasing, Views, Having Clause, GetDate(), and Primary vs Foreign Key. 

After that I will be doing an Advanced Series as well.

I hope this is helpful! Please let me know what you think! 

Link:
https://youtu.be/9URM1_2S0ho"
Does anyone have a viable method for forecasting out sales during COVID?,4,flbsgq,datascience,3," 

My business is scrambling to find the best way to forecast sales to get a best/worst case scenario for the covid sales trends.

Does anyone have a better methodology than just using the excel forecast method since the beginning of the spike, or using run rates?

Really appreciate the help! Hope everyone is staying safe."
Impact of COVID-19 quarantines on demand forecasting,8,flbr0q,datascience,13,"Hello everyone,  
As many countries are quarantining their population and closing non-necessary stores, which means a sudden drop in demand, one would expect this demand to jump as soon as the quarantine is over. 

What can be done so the algorithms anticipate this rebound of the demand and predicts an accurate trend ?

I would gladly discuss and try to challenge any thought on the subject :)"
Rookie Data Science Mistake Invalidates a Dozen Medical Studies,518,flbqyp,datascience,52,"Spam bot caught this one but I think it's worth sharing anyway.  A data science team tried to recreate study results using a publicly available data set, and couldn't.  Turns out the original data had been cleaned incorrectly, leading to the same sample data points being added to both the test and training set, and thus models with very high predictors.

https://towardsdatascience.com/rookie-data-science-mistake-invalidates-a-dozen-medical-studies-8cc076420abc"
"How do I become proficient in the data warehouse/engineer side of things, while currently being a data analyst?",7,fl9y7e,datascience,10,"I’ve come across a good number of ‘Data Analyst’ positions that require not only the analytics part in regards to data, but also building the infrastructure of the databases. Is there a basic level of proficiency I can get to that will allow me to at least know the foundations of the data engineering part? Is it as difficult as I think it is? Especially as someone who’d be self-learning this part. Anyone care to list some of the technical softwares that are needed? Starting from like the most basic of requirements to get started (say, in a small company/start up just to get their database warehouse started) 

Thank you in advance~"
Big Data Research Project,2,fl9gc4,datascience,0,"Firstly, sorry if this is inappropriate for this subreddit, please remove this post if it is not allowed.

I am a university researcher for IE University in Madrid and my research team is working on a paper that is investigating the use of Big Data in organizations. We need data science professionals to fill out a 25-question survey. All responses will be shown in an aggregated format with no identification of the company or individual involved. These responses will only be used for academic purposes.

If there are any professional data scientists working on big data projects in this subreddit, please can you spare 5 minutes to fill out our survey? Please, only people with relevant work experience should respond, this is not for students or people who work in other fields.

Thank-you in advance, the insights will be of great value in our work.

[https://docs.google.com/forms/d/e/1FAIpQLSe4OGSoxCDZzuBcGPQusaqsEiZoXZXLDW7A3kLLjVdVp7fYQA/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSe4OGSoxCDZzuBcGPQusaqsEiZoXZXLDW7A3kLLjVdVp7fYQA/viewform?usp=sf_link)"
Natural Language Processing APIs for Python,20,fl63qt,datascience,1,
[P] Machine Learning for Coronavirus Dataset List and Literature Review,2,fl2jlx,datascience,2,"Seeing as there are many new datasets and papers beginning to come up about coronavirus. I created a [Github repository](https://github.com/isaacmg/ai-virus) to keep track of all coronavirus related research. Additionally, I wrote an [article](https://towardsdatascience.com/machine-learning-methods-to-aid-in-coronavirus-response-70df8bfc7861) summarizing recent literature"
COVID-19 Data Hub - Daily updated data sets and visualization by Tableau,31,fl259m,datascience,4,"I just received an email from Tableau sharing their Covid-19 data hub. It contains their dashboard, but more importantly, they are making their daily updated data sets freely available. I am not affiliated with them, but thought it was worth sharing.

[https://www.tableau.com/covid-19-coronavirus-data-resources](https://www.tableau.com/covid-19-coronavirus-data-resources)"
Introducing MIDAS: A New Baseline for Anomaly Detection in Graphs,89,fl20af,datascience,19,
[Projects] Creating a Project that Predicts Instagram Likes (R project),2,fky8t4,datascience,3,"Hey guys, I run a medium size Instagram page (8k followers) and I post NBA analysis through data. 

I figure that since I am all about data and analytics, why don't I create an algorithm that will predict how many likes a post will get. The purpose of the project is for me to learn and apply something new on R and that I will be able to improve the quality of my page.

The problem is that I do not know where to start. I am familiar with R at a very begginer level. I can make GGPlot graphs and I can make simple Multiple Linear Regression models while using Step-wise regressions for feature selection. However, I am a quick learner and I have an extended break and I am under quarantine so I think its worth my time to learn how to make such a project. My question is where do I start adn what should I look into learning?

PS this is what my posts look like if thats of any relevance \[I have like 630 posts\]

&#x200B;

[The pictures are higher quality but I zoomed out to get a good picture](https://preview.redd.it/m0tymka38in41.png?width=470&format=png&auto=webp&s=db455c766d0b04e2309938baf1160fd9937ce4bc)

Thank you :)"
Digital Marketing Analytics,1,fkuukl,datascience,2,"Wanted to know the best resources (online/books) to learn more about digital marketing and online advertising, along with applications of analytics in this domain.

Thanks!"
My quick-start COVID-19 plotting notebook - feel free to copy & modify,77,fkudxs,datascience,4,
Working from raw source data from a filepath containing spaces using make and Makefiles,2,fksdx3,datascience,0,"I have a repository that uses python scripts and a Makefile. I want to have a setup procedure that
allows them to easily set up an environment and copy in the necessary data files from our server.

The problem with including the source data files in the Makefile is that the company server uses 
spaces in the drive name, which make doesn't like very much, so I can list those files as dependencies
for the target output file.

My current Makefile basically does only the following:

```
.PHONY : all
all : output.csv

.PHONY : copy_data_to_local_folder
copy_data_to_local_folder :
	python copyfile.py ""V:\\Server Path\\With Spaces\\Inputs 1.csv"" local/inputs1.csv
	python copyfile.py ""V:\\Server Path\\With Spaces\\Inputs 2.csv"" local/inputs2.csv

output.csv : combine_data.R local/inputs1.csv local/inputs2.csv
	Rscript $^ $@
```

The `copy_data_to_local_folder` part is just to get the data to the local directory, but it isn't included 
in the DAG leading to the production of `output.csv` (i.e. `all : output.csv copy_data_to_local_folder`) or else
the target would need to run everytime.

My solution ideas are the following, but I'm not sure what's best practice:

1. **Use a different make tool.** I could use `Luigi` in Python or `Drake` in R, but I would prefer to keep 
the tool somewhat more generalized.

2. **Run a setup script to copy in files.** I assume there would be a way to run the file copying scripts
as part of the environment setup, but I am unfamiliar with how to do this.

I am not sure about the best way to do this. I want to be able to share the code with a co-worker and have them
be able to get up and running on their system without too much messing around to configure. Is there a best
practice for this situation?"
How can you find out if it’s possible to access your shopping data through an API via your online shopping account?,0,fkrnid,datascience,0,Apologies if this is the wrong place to ask!
Corona Virus Search Terms,1,fkrezm,datascience,5,"Working on a project (for my job, not another pop-science medium post) where I'm trying to isolate records with free text that relates to covid-19. 

I started to put the following list together, and am interested if there are any other isolating terms. Here's what I have so far:

* cv
* virus
* corona
* covid
* outbreak
* pandemic
* endemic
* pandemic
* epidemic
* shutdown
* quarantine
* social dist
* covd

&#x200B;

Any other big ones?"
I wrote a python package to make the Cord-19 challenge easier!,241,fkqtb1,datascience,11,
An r/datascience equivalent that's female-heavy,0,fkq1ek,datascience,32,"Just wondering if theres any other subs or communities around data Science that are a little more female dominated. not that r/datascience is necessarily bad or unhelpful, its just that its more refreshing being in a community that can relate to you a lot more.

would love to hear from the ladies on here!

edit: nice to be reminded that i can always count on boys on reddit to spew unsolicited anti-women in tech sage advice in PMs lol..."
RPA tools for automatic login into a website and extract data in an excel file?,2,fkn5xl,datascience,2,"I am looking for an RPA tool that automatically logins into the tableau server and copies the new data uploaded there and pastes it into an existing excel file or google sheets.

Any suggestions??"
Python For Java For Data Science and Developers,0,fkjh60,datascience,0,
Websocket — Retrieve Live Data,2,fkizoh,datascience,4,"Have you been wondering is there a way to collect live data from stock, cryptocurrency or betting websites?

Or thinking how these websites are able to update the data live?

If you want to interested in one of the questions above, this article is for you.

In this article, I will help you to understand the technology and give you one practical case to scrape live data.

Link: [https://towardsdatascience.com/websocket-retrieve-live-data-f539b1d9db1e?source=friends\_link&sk=f6a66783003a234236ea3cf0cdab4407](https://towardsdatascience.com/websocket-retrieve-live-data-f539b1d9db1e?source=friends_link&sk=f6a66783003a234236ea3cf0cdab4407)

Leave a comment below if you have anything to add on!"
"A fiasco in the making? As the coronavirus pandemic takes hold, we are making decisions without reliable data",7,fkiyj1,datascience,2,
All Cambridge University textbooks are free in HTML format until the end of May,565,fkg06u,datascience,80,
Discussion Question: Did Covid-19 Break your Model(s) and why?,12,fkecmh,datascience,7,"ML/AI models are, in general, susceptible to breaking when a significant regime shift occurs and training inputs are no longer representative of production inputs.

Has your model broken (taken on unacceptable prediction error) with the societal and cultural impacts of Covid-19?

My models in hydrology are as far as I know unaffected, but to those who work in say finance or retail for example,  how have your models fared against Covid-19? Let's start a discussion."
Shinyapp for COVID-19 cases in each U.S. State,2,fkcy2a,datascience,11,
Validating models for individual behavior using aggregate results,2,fkc07b,datascience,3,"Hi - is there a name for the process of building/validating a model of individual behavior when you only have aggregate data available for the response variable (but do have individual-level data for the predictor variables)? I've tried googling various things and can't get anything to pop up. I'm hoping to find a book or two on the subject.

My particular use-case is: I have lots of variables for voters - age, sex, zip code, etc., I would like to predict if they will vote Democrat or Republican but I only have precinct-level results (precincts vary in size from 2 registered voters to 2,880, but most are around 1,000; I have 8900 precincts). In my mind, a good model would cause my predictions for individuals to create similar results to the actual precinct results when aggregated.

A second, related question - what is generally considered best practice when using census or similar aggregated data as a predictor variable - for instance, if I have the median income for a census block is it ok to simply assign this to an individual living in that census block? This seems a little simplistic, so I was wondering if there are any good resources, particularly books on the subject. 

Thank you!"
White House & Partners Launch COVID-19 AI Open Research Dataset Challenge on Kaggle,319,fkb2nh,datascience,37,"In response to the COVID-19 pandemic, the White House on Monday joined a number of research groups to announce the release of the COVID-19 Open Research Dataset (CORD-19) of scholarly literature about COVID-19, SARS-CoV-2, and the Coronavirus group. The release came with an urgent call to action to the world’s AI experts to “develop new text and data mining techniques that can help the science community answer high-priority scientific questions related to COVID-19.”

[Read more](https://medium.com/syncedreview/white-house-partners-launch-covid-19-ai-open-research-dataset-challenge-on-kaggle-4c5b936faab1)"
Covid data by county?,2,fk9idp,datascience,4,"Does anyone know where I can find confirmed case data that includes the county (and preferably lat/long)?

I was using JHU github, but they recently changed from reporting by county to reporting by state"
Best way to present/show time series multi-column data?,3,fk7hr8,datascience,2,"Hi everyone, 

I basically have a dozen time points (columns) with a few hundred rows (features).  
Per usual, some features rise and fall together, while others might stay consistent, or be affected in other ways at different times points.

I'm trying to find the best way to 'show' and 'see' which features seem to be related to others rising and falling. A network of sorts. Features X1,X2,X3 drop, and the more they drop, the more features Y1,Y2 rise for example.

Currently I'm taking the change between time points and manually grouping them together, but I'd like a more 'automatic' and ideally '3d' way of seeing a 'network' of changes branching out. (Maybe a group of changes in time stamp 1 result in changes in time stamp 2, etc).

I'm just wondering if anyone knows of a standard way, or maybe a library that does/shows this?

It would be cool to be able to find 'if we remove features A,B, then feature Y should not go up'.

&#x200B;

What I'm currently doing:

Currently my method is really gross and not friendly to visualize. I have the changes between time points. Then I group them into 'increases a lot, increase a little, doesn't change, goes down, goes down a lot'. So 5 branches. Which then branch off into 5 more... and so on and so forth for each time point. I imagine there has to be a significantly cleaner, less noisy, and more 'interactive'/'visual' way to do this.

&#x200B;

Cheers!"
Help with packages/method for modeling spread of ideas?,0,fk74j8,datascience,1,"I am looking to model scaling out a project my team has worked on for the past year. Basically, we want to see based on our current structure how the project will scale when we move into a larger organization. Sorry for the vagueness, I am not sure how to explain this without giving too much detail on the work. I'll list the goals below to try to provide more clarity.

I want to know:

* The spread of idea adoption based on current rates
* Capacity constraints based on current team structure
* If we add more members to our team, will that help with capacity/how much?

I am welcome to suggestions, but for more specifics we would have to talk in PM.

Thanks in advance!"
Resource for common business related DS problems?,2,fk6hll,datascience,0,"Recently, I've had a string of interviews about what's the best model or method to answer a specific business problem. 

Last summer, when applying for internships, the bulk of the questions were about my model knowledge (what's the gradient for this?, what's the hyperparameter here do? What assumptions does this model make?) Perhaps these questions are only typical of intern level positions. I ended up getting an awesome internship related to NLP. And the mindset I walked away with was - know your models inside and out; that's what separates the good candidates from the bad. Now I'm thinking at the employee (not intern) level, it's assumed that you already know all this stuff and can further use them to a company's benefit. It sounds obvious in retrospect, but I'm still fumbling to find a winning study strategy from this point on.

However, now the questions are a bit more like:

""What's the probability that a customer will purchase this exact product last month given online transaction history?"" or ""model the impact of discount percentage on sales volume and recommend the optimal discount per product."" or ""predict customer churn given transaction history.""

I completely understand that these are the questions that data scientists are supposed to be answering in industry. But I feel like a fool; I spent all my time learning the ""ins and outs"" of various models and not nearly enough time orienting these models around common business problems. Actually, coming from a military background, I'm largely unfamiliar with the problems that businesses need to address, with the exception of logistics. 

Can anyone link some resources/tutorials? (ie this problem is typically handled by xyz preprocessing and feature engineering steps, these models are most often used, and the critical metrics are a,b,c)"
"Resources for learning numpy, pandas, etc. (applying deep learning is goal)",157,fk1xuv,datascience,49,"Hi :-)

So i worked through the first half of my first python book (Python Crashcourse  from Eric Matthes) and I am currently in a section there about introduction to data science.

I wanted to know what resources you recommend next for learning about numpy, pandas, matplotlib and machine learning stuff? (I had bought hands on machine learning in the past but I want/should learn the other mentioned libraries first I guess).

I found the 'Python Datascience Handbook' from Jake VanderPlas (which got good reviews) but it's from 2016 so I am unsure whether it isn't already a little too old? 

So what resources/courses or books would you recommend next after finishing my current book?

My background: I am a medicine student and plan on doing a docotoral thesis about/ with applying deep learning in pathology/ computer vision (I need to learn programming but there will also be way more experienced people than me with programming/machine learning/math etc.).

Hope you can help :-D! 
- Alex

Edit: Didnt expect so many replies that quickly, thank you very much! :-)"
Testing REST APIs with Newman,2,fk1o7p,datascience,0,
Fun/Trivia: Could the drug LSD help visualise convolutions in your visual cortex by exposing them to more of the deeper layers?,0,fk1cx0,datascience,2,"Just a random thought I had.. Research shows that on psychedelics neural pathways are activated that normally aren't and parts of your brain that normally don't speak to eachother are now connected. 

Anecdotally on psychedelics, especially LSD, one can see patterns being emphasized or certain aspects of sound and sight being emphasized. For example, sharp and colored edges, or higher contrast, or very small delays between sounds that your brain normally stitches together. 

I wonder if the increase in neural pathways being activated might be responsible for some of the earlier layers in the network to be leaked into consciousness, which I assume would be near the end of the neural network..

PS.. I have little knowledge of neuroscience, just a thought experiment I had while tripping"
YouTube/Video recommendation on Model building in Data Science Case studies or Projects,2,fk1081,datascience,1,"Hey fellas,

I'm looking for a YouTube series on Model building that includes -

1. Data pre-processing, thorough, focusing more on the code part and less on feature engineering and dimensionality reduction etc.

2. EDA with Matplotlib and Seaborn, leaning more towards how I can best make use of these two packages, different charts and graphs, formatting and the likes, less focus on trying to make sense of data and get insights. Again, I want the focus to be on Coding part

3. Model building from Scratch. I am familiar with the concepts and math but I need more practice on hands-on implementation of end-to-end pipeline.

The perfect series would be a coding marathon on a case study or a project where we build a linear/non-linear model from sctach. But again, I'm not looking for videos where they're just presenting their code and walking through their logic, I am looking for something where we build the model step by step.

Any recommendations?"
The Robust Guide on Python for Data Science,0,fjz1rv,datascience,1,
Interpretability of Time Series Forecast,3,fjyaiw,datascience,5,"Hi,

Just posting because I feel really lost -- manager asks me to put together a sales forecast (they have none), and she tells me she wants to use the forecast in conjunction subject matter experts (marketing) for providing a monthly/quarterly forecast. I clean some data up and use Prophet to provide a forecast, but today during the meeting she tells me that it isn't 'explainable' in any way. The forecast does extremely well, except for the last day of each month where there is usually a huge spike, but when you forecast to the monthly/quarterly level, it performs extremely well. She wants me to put together a forecast using a combination of average opp size/average time to close/pipeline to produce a forecast, which I honestly have very little faith in. We aren't tracking a lot of really basic things (like a snapshot of sales pipeline for example, so simple pipeline analysis is basically out the window), and she seems to think all of this can be done in tableau/excel and 'statistics, which is odd because I told her I was just going to run a time series model weeks ago.' I kind of don't know what to do other than follow her suggestions, despite the fact that I think it will be fairly far off the mark. I don't know how to explain why this method would probably result in failure without coming off across as 'difficult'. Difficult because my boss is a MBA type that is completely clueless about statistics.

Thanks."
is there any coronavirus data by US city?,6,fjvm1j,datascience,1,Everything I see is by country or US state. Is there nothing that shows by US city or county?
"Are ""AI Developers"" similar to ""Machine Learning Engineers""?",0,fjv61z,datascience,16,"I know the job descriptions are always the best way to identify a job's role, but ""in general"", are there any differences between the two roles?

If not, maybe we should start calling ""Machine Learning Engineers"" as ""AI Developers"" since many people still think MLE's do predominantly machine learning and nothing else

A title change may help clarify the need for software development skills in addition to AI/ML skills in those roles

What do you guys think? (This is just a discussion post)"
Question - Coronavirus Short-Term Impact on Demand and Supply of Data Scientists in the US?,7,fjsy2x,datascience,7,"I'm about to start actively looking and it occurred to me that

1. The stock market crashing probably isn't great for data science hiring.  Although maybe the positions currently open were budgeted for and the real impacts will start being felt a few months from now?
2.  Cornoavirus is probably impacting international travel, reducing the supply of data scientists to the US.  However, maybe the additional supply per month isn't really that high anyway so it doesn't matter?

If anyone with inside knowledge on the data science job market would care to chime in, I would be eternally grateful for your opinions on how coronavirus has impacted the data science job market, and will impact over the next few months."
CORD19 data challenge,1,fjs6f4,datascience,0," Kaggle is sponsoring a $1,000 per task award to the winner who is identified as best meeting the evaluation criteria. Each task’s winner may elect to receive this award as a charitable donation to COVID-19 relief/research efforts or as a monetary payment. 

[https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/discussion/135826](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/discussion/135826)"
COVID-19 in Italy STATS,0,fjs4vj,datascience,1," I found this GitHub repo with COVID-19 statistics that are being updated and to the extent that I understand it is official (I do not know Italian, only google translate)  
If you want maybe try to find some useful thing in the data and share the information  
 [https://github.com/pcm-dpc](https://github.com/pcm-dpc)"
How to a find leakage for image classification problems?,1,fjoz0z,datascience,9,"I work on an image classification project. 

For some reasons my models fit too well and quite fast on relatively small amount of data.

(1000k images on pretrained on imagenet resnext)

I got suspicious and decided to check models with GradCam and I saw that for most of the images GraDcam pointed roughly at the same place, a spot close to upper right corner. 

I have checked for watermarks and everything but got nothing. 

Do you have any ideas what can it be? How do you deal with such problems?"
"""I am not a software developer"" and other lies you tell yourself",327,fjo3at,datascience,87,
Automating the data collection process,0,fjmt8h,datascience,8,"Guys I am an intern for an analytics and software company and today we were given this problem to solve:-

Our client from the UK uploads his transaction data daily onto the Tableau server. We log in from our end and download the data for the last date and add it to our file and we then run our analysis. The client uploads data to a lot of different files on the server and we manually have to check each file and get the new updated data using ctrl+c and paste to our sheets on which then we run statistical models in R and Python.

The company wants to automate this process of logging in each time and checking all the files manually on the tableau server. 

I have no clue how to even approach this problem. Any suggestions?"
External Geospatial Data Sources: Their types and use cases “,1,fjik7j,datascience,0," 

>“Do you have some external data sources that we can add in our analysis?”

A question like us from our clients isn’t uncommon or alien to us. Hence, we compiled a list of external data sources, their types and use cases. Do note that this is not an exhaustive list and we plan of adding to this as we go along. Link: [https://blog.locale.ai/external-geospatial-data-types-and-use-cases/](https://blog.locale.ai/external-geospatial-data-types-and-use-cases/)"
Corona virus data. No social distancing vs 75% social distancing. Credit to @Harry_Stevens,3,fja5v6,datascience,4,"https://imgur.com/a/P5RyUT8



Credit: https://www.washingtonpost.com/graphics/2020/world/corona-simulator/"
How to use Jupyter Notebooks in 2020 (Part 2: Ecosystem growth),225,fj9y80,datascience,21,
Should bias always be zero when using scikit-learn to create a linear regression model?,3,fj9nic,datascience,12,"I read somewhere that bias should always be zero for linear regression models. However, using the Iris dataset, I split my data into training and testing and then used scikit-learn's [`LinearRegression.fit`](https://LinearRegression.fit)`()` on the training data.   


I calculated all my error metrics (which I can't interpret) using the scikit-learn's `metrics` module. I couldn't find a metric that calculated bias, but I read that bias is just the mean error/residual, so I calculated it like this: 

    regressor = LinearRegression()
    regressor.fit(x_train, y_train)
    y_pred = regressor.predict(y_test)
    bias = np.mean(y_test - y_pred)
    >>> -0.06822953408834274

So, my bias isn't zero. Have I done something wrong?"
What approach is commonly taken to go from data aggregation to real-time dashboard?,6,fj98r5,datascience,9,"I am doing research in the smart cities domain. We use IoT devices to collect data, and then send it to a DB (torn between using MongoDB and Cassandra at the moment). Our end goal is to create a real-time dashboard. We're trying to display dynamic results on the dashboard, such as the temperature of an area during a specified date range. Another example is watching the luminosity of an area change in near real time.  


My question is: After the data is in the DB, what is the common approach for creating a real-time dashboard?   


Do you analyze the DB data beforehand, store the results back into the DB (as new tables/collections), and then pull those results from the DB to the webapp?  


OR, do you run the data through an analytics engine like Spark while it's in transit to the webapp? In this case, my understanding is the webapp's backend would run queries to get a bunch of data that's then filtered down by the analysis tool. The filtered data is then sent to the frontend."
How important is a graduate education?,12,fj6ot0,datascience,12,"I'm close to graduation from a BS in Mathematics. Datascience is something that seems interesting to me, and I think I have a good foundation for attempting to break into it at some point down the line. 

I was able to learn a lot of graduate level mathematics and statistics during my undergrad, so I was wondering if I should be thinking about graduate school or learning things on my own. 

Do you think it would be worth it with my background?"
Hashtags related to the coronavirus,2,fj6l7v,datascience,2,Just trying to do a hashtag analysis of the coronavirus for research. Anyone know what the most viral ones were since the outbreak? Not looking for geographic specificity necessarily.
Springb0ard Data Science Career Track,0,fj64mk,datascience,8,Hi! Has anyone taken this course? I was really interested but it is a very big investment how and I am not sure if this is worth it. I don't have a lot of experience with Python and I think this would be a great opportunity for mentorship. I am a Junior in Statistics and have experience with R SAS. Lmk if you have taken it and what you think of it!
What do you think about Knime?,1,fj5euo,datascience,6,"I am a Data Science student and, for one of my courses, my professor decided to focus the exam around Knime (a not too simple ML project). For my brief, albeit intense, experience, I have loathed it: it is not particularly efficient, crashes way too many times and lacks some functionality, for which I have to resort to use Python nodes. 

But maybe I am wrong and, coming from a purely Python and C++ background, I cannot see the benefits. If some of you, more experiences than me, could share their experience, maybe I could reevaluate my views. Cheers."
Sharing a Data Scientist Interview Case Study,144,fj5dtk,datascience,20,
Modelling discount effect on sales volume,1,fj2zx8,datascience,0,"Most of my data science experience has been in the realms of NLP, recommender systems, and network analysis. I'm quite unfamiliar with using DS techniques directly for business goals; so I volunteered for a project to help me master some fundamentals. 

I have sales data for 5 products, the discount %, and the dates effective. Assume that there are many, many rows covering every product, the month effective, and the discount percentage.

For example:

    [
    (product_1, 15%, April 2019),
    (product_2, 10%, June 2019),
    (product_3, 20%, October 2019)
    ]

What are some strategies for modelling the effectiveness of discounts on products?

Because there are so many variables, I do not think that A/B testing is appropriate here. I've considered marginalizing date out, and building one  linear regression model for each product where discount is the independent var and sales volume is the dependent variable. 

However, I feel that this question is deceptively easy; perhaps it's actually an optimization problem where we're estimating the best discount price to maximize sales. For example, a $100 product might sell 4 units with 20% off and 5 units with 25% off. But without knowing the cost per item to the business, this isn't a perfect approach either. 

Thoughts?"
Need some advice for my first data science internship,0,fj22pr,datascience,3,"My first ever data science internship starts on may this year at a big company.

I'm a CS-freshman and I'm familiar with statistics and probability theory and I've taken calculus I and II.

I have my own data science project that I created with python. I have some experience with cleaning and munging one dataset from Kaggle. I'm only familiar with linear and logistic regression when it comes to machine learning.

I have no practical experience with SQL and I've never performed data scraping.

What are your advice on how to start preparing for my internship as data scientist trainee? Should I take some MOOC's or read some related books? If so, what are the most essential for this kind of a job?"
which field in data science has the most scope and is highly paid?,0,fj1s0w,datascience,6,
Weekly Entering & Transitioning Thread | 15 Mar 2020 - 22 Mar 2020,8,fj0b5m,datascience,67,"_Bleep Bloop_. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki. You can also search for [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).

---

I am a bot created by the r/datascience moderators. I'm open source! You can review my [source code on GitHub](https://github.com/vogt4nick/datascience-bot)."
What are some good Data Science master degrees in Europe,72,fiykbr,datascience,51,"Basically, as the time says, however which degrees whose tution fees are less than 5000€/Year. I recently have been checking universities in Germany but I am curious what do you guys think


Abit of a background about me, I am 22 year Computer engineering student from Egypt, I will finish my Bachelor's degree this june, but since Data Science is not as huge as it is in the US and Europe. I thought I would get a masters degree, and save me the effort of trying to apply to jobs abroad, plus have a much stronger academic background in data science."
Need a dataset for a research topic. [Ideas Request],0,fiwdbt,datascience,3,"I have a project for my MS in Data Analytics and I cant come up with a topic for the life of me.  Biggest kicker is it cant be too massive because I really only have a month to work on this, which in reality is probably 40 hours.  Im hoping for a simple enough multiple linear regression, random forest, or logistic regression. Could also be anova type analysis.  Could be anything really I just dont want to go into anything too fancy that will take 80+ hours.

I have to be able to come up with some business use case for this research, but I can probably come up with that for anything.  Ultimately it just has to be useful.

I wanted to analyze gender pay gap... but cant find find anything with # of children or number of years in the workforce or really anything significant to work off of on an individual basis.

Then I wanted to do child abuse, but the datasets are insane.. like 10000 fields insane... and you are aupposed to use fancy weights and software because of the study design.  So thats out.

Other topics that arent allowed are employee attrition, customer churn, and most banking/credit topics.  

Thanks!"
COVID19 and water usage,13,fivgli,datascience,12,"First off, my many apologies if this is not the correct sub reddit in which to post this. I'm new at reddit. have mercy.

I was thinking that, with all the warnings due to COVID19 to wash hands at least 20 seconds, assuming a significant number of people above the norm are following that advice, there has to be an excessive amount of water usage than normal. Perhaps there are already stats on it? (My advice is to wet hands, turn water off, soap up, lather, then rinse.)

Anyway...any thoughts?"
Is it a bad idea to try to predict the stock market with linear regression?,1,fiu6iq,datascience,25," Reasons being the underlying theoretical function that generates the stock price is constantly changing due to human behavior so your model will only be accurate for a short amount of time, unlike the relation of height vs age where the fluctuation is limited by biological restrictions."
r/LearnCybersecurity (New Subreddit),2,fitnaf,datascience,0,
Question about ARIMA and VAR modelling,6,fisq0r,datascience,7,"Dear readers,

I'm currently in my last year in Computer science, for a last project we must apply an ARIMA and a VAR model on our received data.

We have 21 data points for 200+ companies with 3 variables of intrest, my question was is it even possible to make such models? 

The goal of the model is to do forecasting. The only examples I have found about these models applied is with simple time data (which would be good for us, if we only had one company and not 200).

Sorry if it's abit vague"
From economics to data science,110,fisj71,datascience,36,"So I'm about to graduate with a bachelor's degree in economics, but the last fall I developed a huge interest in data science (mainly because of econometrics) so as my classes are canceled for 2 weeks + 2 weeks of online lectures I want to dive deeper into the field of data science.

I'm in processes of creating my curriculum which I plan to follow till the end of the summer and please help me with suggestions and feedback.

**Video Courses:**

* Udemy ML A-Z (\~ 1.5 hours per day)

**Math with Textbook:**

* Linear Algebra - Youtube videos + linear algebra done right textbook (I've never taken it at my uni as it wasn't required by my major)  \~ 30 minutes per day
* ITSL textbook - (I'm comfortable with general linear models and time series which was covered through my econometrics courses) \~ 1 hour per day

**General** P**ractice:**

* Dataquest Data Scientists track (doing 1-2 missions per day) \~ 1-1.5 hours per day

What you would suggest adding/removing/replacing?"
How do you create your own Data Science blog,0,fiqmiu,datascience,4,"I’ve wanted to create my own blog for some time. I intend to create posts about what I’m currently busy in Data Science, as algorithms, datasets, etc.

The thing is that I’m pretty good when it’s come to programming and algorithms but I have no clue how to set up a blog. Most websites out there just explain how to do a « normal » blog but I’d like to know if there exists a way to easily create a blog where I can add codes, dynamic images, codes again, etc.

What kind of blog do you use for your Data Science activities?"
Thinkpad T430 vs X1 Carbon 7,0,fip3ri,datascience,7," 

Thoughts on:

Thinkpad T430: i7-3840QM 4 cores, 16gb ram, nvs5400m, 1080p AND X1 Carbon 7: i7-10710U 6 cores, 16gb ram, 1080p ?

I will be using the laptop for prototyping ML and Data Analysis using Python and PowerBi.

Thank you"
What is the recommended partition size for linux?,0,fip10w,datascience,5,"Hi, I want to set up a Ubuntu Linux virtual machine via Parallels Desktop for Mac. What is the recommended partition size for doing Data Science work?"
Identifying Bot Commenters on Reddit using Benford's Law,1,fimrm9,datascience,5,
Are there laws like the three laws of robotics to help Data-Scientists govern their behaviour?,0,filhj6,datascience,4,"I realise the topic is complex and can easily lead to (over) simplification. But something like:

First law: Information about people shall not be used to harm individuals or groups. Neither through active use, nor through inactivity. 

Second law: Information about people shall not be stored without them being aware of it? 

Third law: Information about people shall not be transferred without them being aware of it?"
Is there a website like leetcode but for data scientist?,43,fil03b,datascience,11,Hi as you all know leetcode is a website for software engineers where they have interview questions from Fang and can practice their skills. Is there a similar website for data scientist
How do you quantify fun in games?,0,fijj1f,datascience,7,"I am working on a personal assignment where I am trying to bucket casual games on app store in a 3x3 matrix of fun vs profitability. Profitability could be divided into high, medium, low, based on ads served on the game, and in-game purchases. But how would you quantify fun? I guess how engaging the game is would decide how fun the game is, but would it be as simple as dividing it into high-medium-low, same as profitability?

Waiting eagerly for your thoughts."
Australian Career Guide advice,0,fif4uv,datascience,3,"Australian currently studying CS & DS at UWA (Perth). Had a horrible first 2 years (5 subjects failed, horrible WAM & GPA) due to personal problems and now taking an extra year to graduate. Thinking of doing a Masters of Data Science program at either Monash or USyd. 

Was wondering whether this is a bad career option? Would it be better for me to go for a grad position for a few years then do my Masters?

I’m also really new to the idea of Machine learning and careers of that sort. If I want to pursue a ML eng career, would it be a requirement to have a SWE background? 

I’m overall not 100% sure how to pursue this career path and choose a proper Big Data job, as I’ve read most companies parade many jobs as Data Science. Also things in Australia could be very different to the US, so I was wondering if anyone else had anymore tips specifically for Australians."
Open COVID-19 Dataset,366,fieuqo,datascience,83,"I was frustrated with the maintenance issues in the dataset maintained by [Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19) so I created an alternative crowd-sourced dataset here: https://github.com/open-covid-19/data

The data is committed directly to the repo in time-series format as a CSV file, then it gets aggregated and pushed automatically in CSV and JSON formats.

If anyone knows of any better datasets, please point them out! worldometers.info appears to have pretty good data but I can't find how to get it for my own analysis.

Edit: the dataset has changed a bit since I first posted this, now I just take the ECDC data from [their portal](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide), aggregate it, and add country-level coordinates for each datapoint.

Edit 2: if you want to play with the data, you can load the sample Notebooks directly from Google Colab here: https://colab.research.google.com/github/open-covid-19/data/

Edit 3: I have renamed the dataset from ""aggregate.csv"" / ""aggregate.json"" to ""world.csv"" / ""world.json"". Sorry for the breaking change, I will try not to make any other breaking changes moving forward."
[Survey] What Data Science course do you want to learn next?,0,fidcqe,datascience,0,"Hi again - I am taking a quick 30 sec. survey from a random sample set of data science learners to understand their learning expectations. 

If you are interested, please feel free to fill your choice of course and also pl. feel free to circulate within your group/network. (survey is not mandatory - Pl. fill only if you are interested). 

Thanks in advance for your feedback!

[https://docs.google.com/forms/d/1wRmmrlIyanpwxbb0-heheI-vCGV4LyMXnapm\_9DgOvI](https://docs.google.com/forms/d/1wRmmrlIyanpwxbb0-heheI-vCGV4LyMXnapm_9DgOvI/edit)"
How would you preprocess features like these?,0,fibnxh,datascience,2,"The label is a probability that an event will happen and the features are past events that could or not be correlated to the label. A huge number of zeros in the features is due to filling NANs with 0. My goal here is more or less understand those dispersions and if I should remove or filter those data points for a regressor to perform well.

The data is highly imbalanced, with many more labels equal to zero than not, but still is a honest representation of reality.

Any ideas or important steps to take given the number of zeros, imbalance or distribution will help.

&#x200B;

https://preview.redd.it/mf7i2zrwvjm41.png?width=1416&format=png&auto=webp&s=e0c68503f6a56e2d52b7a122b13efd3fcb0747a1

https://preview.redd.it/yis0myhwvjm41.png?width=1416&format=png&auto=webp&s=10c9d50d4a0ad12dec163978300f82985b8188f9

https://preview.redd.it/a2g4u1awvjm41.png?width=1378&format=png&auto=webp&s=2d4ed7927214f1fafa5300c1196859b4dadfa35a

https://preview.redd.it/9wzdkyyvvjm41.png?width=1374&format=png&auto=webp&s=47b76af6dd50f3feec52b249b8353d33941ac19b"
Ten Research Challenge Areas in Data Science,1,fib8u1,datascience,0,
Day in the Life of a Data Analyst [video],4,fiadpd,datascience,0,"Follow me for a day in my life as a Data Analyst! I know this is the Data Science subreddit. I am actually on my Data Science team at work and do some Data Science work, but have the title of Data Analyst. I have been meaning to make this video for a while so I’m glad to finally have it finished. Hope you enjoy it! 

Link:
https://youtu.be/qzZU6LAtIig"
Is there something like Project Euler but for machine learning specifically?,181,fia7n5,datascience,21,"Hello all, I've really enjoyed solving the problems on https://projecteuler.net/ recently for personal pleasure and to learn more about mathematics/algorithms. 

For those unfamiliar with Project Euler it has many different mathematical problems many of which are unsolvable by brute force with a programming language. It forces you to think about things in the most efficient way possible and find solutions which are not obvious at first. After you solve the problem you can view a forum thread for that specific problem in which other people post their code for their solutions. It's a lot of fun seeing how your algorithm compares to others and learning ways which your algorithm can be improved. 

I was just wondering if something similar to this exists for machine learning specifically? I'm hoping to try out some different machine learning models in a non-competitive relaxed environment and also have ability to see how others solved the same problem. It would also be great if my progress was tracked and there are achievements (Just like Project Euler!)."
Validation/test set confusion,0,fi97sl,datascience,1,"I just finished up coding a Nueral Network for a project and I am having some confusion. I have a 3 segmented partition {train, validation, test/hold-out.

How should I be using my validation set exactly? I thought I should be using this as a stopping criteria for training...and then use the test set to get a predictive accuracy. Or should I be using validation set to tune number of nodes/layers after allowing the model to fit with the training data alone? 

I have been reading a lot on this today and Hve thoroughly confused myself."
Data science in Recessionary periods,19,fi7q2t,datascience,22,"Some professions in some sectors do OK during recessionary periods. 

- For example if you're an engineer working for a public utility company delivering water and power (because people always need water and electricity). 

- People in healthcare industries also do OK (people always get sick). 

- If you work for a bank, as long as you're front office (revenue generating) and not middle office or back office (cost centers), your jobs will be save.

**What about data scientists?**

We know the recession is coming and it will be pretty bad. Central banks have run out of ammo since interest rates are so low. The only cheap tricks they have is doing QE's so we don't know how long this recession will last. Learning from Japan, it's highly possible we will go bad for a really long time. 

Since data science as a profession is a new thing and since most of the time data scientists is non-revenue generating, what do you guys think will happen in this upcoming recession/depression?

What are your takes on the following professions in different industries:

- data scientists (R&D)

- data engineers

- data analysts (aka: data scientists type A, or FAANG type data scientists)

- BI

- machine learning engineers

I can start: 

If you're any of the above within healthcare, you will surely be OK (data scientists have worked in healthcare sectors for a long time, and they're called statisticians). If you're in retail, perhaps you better have enough emergency funds.

**Edit:** I'd like to take the discussion a step further. An organization will keep you around as long as your value is greater than your costs. 

So my next question is:**What would you need in terms of skills, knowledge, ability, etc so that your value is higher than your costs (so that your organization will keep you)?**"
Data science and the Corona virus,15,fi765b,datascience,15,Do you guys know of any project/s that needs help with data science or software development that can help in any way with the Corona virus?
Are there benchmarks for the tf-idf statistic?,2,fi6ng3,datascience,0,
Companies: All Your Data Are Belong to Us,0,fi5c6z,datascience,0,
Internship Opportunities for 11th Grade Students,0,fi5806,datascience,8,"Hey, I’m currently a senior  year student in India. I’m looking to intern in the domain of data science / Machine Learning from 15th April onwards. 

My previous experience consists of various online courses, and a paid internship as a data scientist at NIBE AB that I did over the course of my junior year summer. PM me for more info!

Best,
M"
Searching for a data/process/workflow 3D visualization tool with ability to connect with a database,2,fi55i4,datascience,6,"Hello there,

as title says is there a visualization tool in 3D space which for workflows or processes which I can connect to databases (like oracle)?"
Plotting with Python - Matplotlib OOP interface - any good guides to this?,9,fi3i46,datascience,12,"

I'm looking for a decent guide on using Matplotlib with the OOP interface,
and the only issue is that as i've not really used it much previously, and
some tutorials seem to be a mixture of the ""matlab"" style and OOP style.

Pretty simple request - but if anyone who uses Matplotlib regularly with OOP
syntax could suggest a decent tutorial to go through that'd be appreciated."
"NVIDIA's GTC 2020 - The World's Biggest AI & Deep Learning Conference - Best of all, registration for GTC Digital is free*",21,fi260i,datascience,2,
Eat the News: Extract Article Text from News Feeds Around the Globe,0,fi1vjh,datascience,0,
List something you 've learned on the job,3,fhybn3,datascience,12,"Can you guys list something you learned on the job but not during your BSc, MSc or PhD (education in general)? I am curious to see what industry ""does"" to data scientists.

I ll start first:

1. Accuracy of the model has to be reasonable but don't spend too much time iterating. Shipping it on time is more important
2. I spend more time cleaning / prepping data than training models"
Data Science & Analytics Job Market in Germany,0,fhx72l,datascience,0,
An example of why communication skills matter more than technical skills,45,fhx2ml,datascience,15,"By using simple stats, nice charts and good story telling this guy has probably helped the fight against Coronavirus more that Google with its Deepmind https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca"
Data base design a useful class?,1,fhwtjp,datascience,2,"Guys, I have an option of taking a data base design class next semester? Do you think it's a good class to take if I want to get into the field of data science/ analytics. Here are some of the topics that will be covered in the class:

Students learn a systematic approach to database development using entity-relationship models, normalisation and relational database design. Students will use this approach to identify and define business information requirements, create entity relationship models and transform the requirements into an initial database design.

1. Explain systems integration
   1. Define the term systems integration
   2. Define the term systems integration
   3. Describe various systems development modeling tools
   4. Explain how these tools support the problem solving process
2. Summarize the process of database development
   1. Define key terms
   2. Explain the purpose (benefits) of database design
   3. Discuss the evolution of database design
   4. Describe the phases of database design
3. Analyze user information requirements
   1. Demonstrate importance of effective interviewing skills in the gathering of user requirements
   2. Demonstrate the ability to produce accurate and comprehensive documentation
   3. Utilize facilitation techniques to seek information from data users
   4. Identify business rules which underlie entity relationships
   5. Formulate a data dictionary with all appropriate components
4. Transform business information requirements to an entity relationship model
   1. Describe the benefits of data modeling
   2. Distinguish between popular notation conventions
   3. Identify and model entities
   4. Distinguish between attributes and entities
   5. Identify attributes (composite, multivalued and attribute domains)
   6. Assign unique identifiers to entities
   7. Describe the various types of possible relationships between entities
   8. Analyze and model relationships
   9. Normalize Data Models
   10. Resolve M:M Relationships
   11. Model Hierarchical Data and Recursive Relationships
   12. Model Roles with Relationships
   13. Model Entity Supertypes and Subtypes
   14. Model Exclusive Relationships
   15. Model Data Over Time
   16. Model complex Relationships
5. Convert ER diagrams to relational tables
   1. Apply basic conversion rules
   2. Map simple entities to tables
   3. Map Attributes to Columns
   4. Map unique identifiers to primary keys
   5. Map relationships to foreign keys
   6. Choose arc options
   7. Choose subtype options
6. Normalize tables in a relational database
   1. Define each of the five normal forms
   2. Maximize application maintainability by applying the principles of normalization
   3. Recognize Unnormalized Data
   4. Convert to first, second, and third normal Form
   5. Understand the fourth and fifth normal form
   6. Discuss normalizing during Data Modeling
7. Perform advanced database design functions
   1. Recognize when to generate artificial keys
   2. Understand the issues involved in specifying foreign keys and indexes
   3. Describe how referential integrity related to business data needs
   4. Specify referential integrity
   5. Design indexes
   6. Establish views
   7. Denormalize the database design"
fixing pandas df output on macos terminal/iterm2,1,fhwr9y,datascience,3,"Hi, When displaying a pandas dataframe using df.to_string(), it seems like the terminal doesn't look at the size of the window and use that to determine how much space it has to display the results. As a result, it ends up looking like a blob of text compared to the gnome terminal on ubuntu which formats it properly. Does anyone know how to display the output properly? Using to_string(), as I want a display of all columns. Thanks!"
How big data or data science can be used in political relations?,0,fhvawg,datascience,1,"I got entrance to Phd in political sciences (international relations). I just want to to know how big data or data science can be used in analyzing international relations. For example relations between two states, analyzing conflicts like ethnic conflicts or civil wars.

Or do you have any sources for me to get more information?

Thanks"
Do a lot of companies do 100% online interviews now?,1,fhtjjt,datascience,3,"So that you don't even have to travel on-site, even for the ""final"" interview?

Also, do you think this virus thing will crush the job market for data science in the coming month?

&#x200B;

thanks"
How “capable” were you in your first ever Data Analyst/Scientist position?,5,fhti6p,datascience,7,"Although I know that even the most advanced DA/DS utilizes Google and other resources on a daily basis, I’m wondering how efficient or capable you guys were in general in your first ever position. Was your educational background enough to have you perform the daily tasks of your position without any handholding (aside from necessary guidance to understand the company’s standards and best practices)? Or was there a good amount of “coaching” from either teammates or your direct supervisor to get into the groove of things?"
I created a very basic model in Google Sheets of the Coronavirus outbreak in the US until March 9,0,fhti32,datascience,2,
Data science stack question,1,fhsyu3,datascience,2,Do big companies use Azure Devops or Gitlab CI?
Creating a discord channel for those interested in becoming a data analyst. Will do weekly data visualisation projects with peer to peer code reviews.,567,fhsxau,datascience,94,
If you'd recommend one ML book what it would be?,1,fhrq3d,datascience,5,"as a headline says. Just if you have to pick one, doesn't matter if it's an introduction or for more experienced users. What is that one book you'd recommend?"
A random idea for tracking Coronavirus,0,fhrdtf,datascience,4,"Testing is a huge problem in the US because there's no testing in the US. Tracking is impossible in any direct sense. 

If you could access data related to general number of flu cases or something similar, you could potentially detect anomalies. Especially if you had very localized data. I'd guess that if it's not being tested, it's just being misdiagnosed/recorded as something else. Like if someone goes to the hospital with flu like symptoms, they probably just write it down as the closest thing matching the symptoms. I would hypothesize if that Coronavirus is spreading in areas served by specific hospitals, you may be able to see it as peaks in similiar illnesses. 


I don't know the signal to noise ratio though and if any data is available at all. I have some data science experience but none of the access to such information. I haven't been able to find a public source either.

It's also possible there could be other potential ways to get some signal, like social media or something like that. All ideas are welcome.

Edit: There's also other people probably thinking about this as well. I'm not aware of who they are though."
Hortonworks blog post: airline delays.,2,fhr989,datascience,0,"I am looking for an archived version of the hortonworks blog on predicting airline delays. I know it is quite old, but it is somewhat famous for walking through the experiment end to end. I want to get a feel for thought processes, rather than tools and technology. I've heard this is a good resource for that. Unfortunately it looks like their blog is gone after their merger with Cloudera.

To that end, any other good publications that might substitute are welcome, as long as they focus on scientific thought and are end-to-end. "
Do you think his series of courses is worth taking,0,fhpzjb,datascience,3,"I'm a software developer professionally but I am interested into transitioning into a career in data science.

My company has a pretty decent training budget and my manager suggested I go find some training in the field.

One of the post secondary schools in my city has the following program: https://www.nait.ca/coned/data-science. It is 6 weekend courses with 84 hours of classroom time. Do you think the content sounds relevant, and would that plus 9 years as a software developer (no computer science degree, just a 2 year diploma from a trade school) make me hirable?"
Classifier suspiciously always gets 99%,1,fhoa5x,datascience,5,"I am training classifiers and no matter what model I try I get very high Accuracy & precision scores.

Suspiciously high scores on the train and test sets that do not work as well on unseens data.

I can also seemingly change the accuracy to whatever I want it to be by tuning parameters.

Is this expected?

How do I proceed?"
Masters opinions,12,fhns3i,datascience,12,"Hi! I’m 49 yrs old. Worked in finance 24 years and got bored.
I have been accepted at:

Msc of applied data science at University of Canterbury (New Zealand)

Msc Artificial Intelligence and applications at University of Strathclyde (Scotland)

Any insights on which program could be better for me will be greatly appreciated.

Thanks!"
should I get a PhD in computer vision?,0,fhnrnz,datascience,2,"I am applying to do a computer vision masters at the university of surrey UK ([**MSc Computer Vision, Robotics and Machine Learning**](https://www.surrey.ac.uk/postgraduate/computer-vision-robotics-and-machine-learning-msc-2018)). Postmasters, I am considering a PhD in the subject. I was wondering.

1. how hard is a PhD? 
2. what is the attrition rate? 
3. how is life after completing a computer vision PhD?

Thank you"
ML in Portfolio Optimisation & Backtest Overfitting (Python),6,fhn3zs,datascience,0,"# ML in Portfolio Optimisation & Backtest Overfitting

We have just released [MlFinLab](https://github.com/hudson-and-thames/mlfinlab) version 0.7.0 which now includes the following:

## Portfolio Optimisation:

We expand on the family of Hierarchical Risk Parity optimizers by including the HERC and HCAA algorithms by Thomas Raffinot.

1. [Raffinot, Thomas, The Hierarchical Equal Risk Contribution Portfolio (August 23, 2018)](https://ssrn.com/abstract=3237540)
2. [Raffinot, Thomas, Hierarchical Clustering Based Asset Allocation (May 2017)](https://ssrn.com/abstract=2840729)
3. [Python implementation](https://mlfinlab.readthedocs.io/en/latest/implementations/portfolio_optimisation.html#hierarchical-clustering-asset-allocation-hcaa)

## Backtest Statistics

In order to fight backtest overfitting we have [implemented](https://mlfinlab.readthedocs.io/en/latest/implementations/backtest_statistics.html) the following:

* Probabilistic Sharpe Ratio
* Deflated Sharpe Ratio
* Minimum Track Record Length

**The Sharpe Ratio Efficient Frontier** *by* David H. Bailey *and* Marcos Lopez de Prado [available here](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1821643). *It provides a deeper understanding of Sharpe ratios implemented and minimum track record length.*

A big thank you to [Aditya Vyas](https://www.linkedin.com/in/aditya1702/) and [Illya Barziy](https://www.linkedin.com/in/illya-barziy-ba9292b1/), respectively."
IBM Data Science Professional Certificate,4,fhlef2,datascience,12,"Hi,I am 17 years old and I am looking forward to studying data science,I figured to better convince universities I am ambitious and certain of my decision and for the love of it I have decided to take some online specilization first in python and then I saw that IBM made it's online specializations free for the first month so I decided to enroll in one,but it's really not well made the links don't work the lectures are all over the place with bad explanations and the value is just not there,I have already finished 4 courses out of the 9,I feel bad leaving it because it's nice to have it for my resume or something but it's honestly a waste of time.What should I do ? If you have any advice on my journey to learning the and preparing to be a data scientist please do tell.

Thank you in advance."
Has anyone here completed the UC San Diego Edx Micro Masters Program in Data Science?,5,fhkir1,datascience,3,"I am particularly interested in the third-course, Machine Learning Fundamentals. Does this class have as much math as the previous course, Probability and Statistics in Data Science using Python, which I am nearly finished with?  




I have enjoyed the Probability and Statistics course. However, the advertised Effort: 10–12 hours per week, has been a considerable underestimation due to my need to refresh my calculus skills, it’s been 20 years! I have done quite well in the course and am confident it will translate to an A. With that said, I won’t have the same time to dedicate Machine Learning Fundamentals this spring, if it requires as much catching up on the side. I am not worried about the programming. I volunteer as a coding club teacher (python/data science course) for middle and high school students, which includes projects using SciKit Learn, Karas, and Tensor Flow.




Thanks!



PS I am happy to answer any questions about the first two courses, if anyone is interested."
TensorFlow Developer Certificate - TensorFlow,7,fhk92x,datascience,3,
Is LOOCV really high variance?,5,fhiwir,datascience,3,"In *Elements of Statistical Learning*, the authors write

>What value should we choose for K? With K = N [LOOCV], the cross-validation estimator is approximately unbiased for the true (expected) prediction er- ror, but can have high variance because the N “training sets” are so similar to one another. The computational burden is also considerable, requiring N applications of the learning method.

Computational burden is becoming less and less of an obstacle, which leaves variability as a reason not to perform LOOCV.  I've realized that ESL doesn't provide any references for this claim, and I'm ashamed to say I've just accepted it by virtue of having names like Hastie and Tibshirani on the cover.  There aren't even any simulations to substantiate the claim!

A colleague and I had a disagreement on CV scheme, which lead to me being shown [this](https://stats.stackexchange.com/questions/61783/bias-and-variance-in-leave-one-out-vs-k-fold-cross-validation/252031#252031) thread on Cross Validated. Seems like (at least from the simulations provided) that LOOCV can be provide unbiased estimates with comparable variability to K-Fold, flying in the face of ESL.

Does anyone know where the rationale for LOOCV being high variance came from, or know of simulations that show it to be high variance? Is this just one of those things we believe because other people believed it?"
When to use ARIMA model vs linear regression (or any kind of regression),3,fhio7d,datascience,7,"I am trying to forecast time series of product sales, I started approaching the problem by implementing the ARIMA model, I iterated over all the possibilities of the models parameters (p, d, q) and picked the one with least RMSE, problem is the forecast is not as good as I wanted it to be, so I started studying other ways of prediction, like regression.

After plotting my data in a cumulative plot, I noticed that most of the time series I had are fairly linear, so probably I can fit a linear regression model on them.

What should I use in my case, ARIMA model or linear regression, and what does ARIMA model has to offer than regression does not, for it to compensate for being more complicated.

Here is a screenshot of my ARIMA forecast, and cumulative plot:

[373 is the RMSE of the time series forecast, blue is prediction, red is test data](https://preview.redd.it/2y5cyczem9m41.png?width=1338&format=png&auto=webp&s=39e427c77d9a1636167af79dfa04ceb65e9ef15f)"
UK Data Science & Analytics Job Market,8,fhfddh,datascience,4,
Created my first time series chart using Plotly with foreign exchange dataset. Dataset obtained from Kaggle,275,fhf63o,datascience,20,
Implementing statistical test neural networks,1,fhe0nd,datascience,1,I am starting to work on a project where I have to compare the output of standard statistical test such as Chi square test to a neural network that emulates the same test. The idea is to build a neural network from scratch. Is this an acceptable path or should I just try to build a network with library like keras? I am looking for help and see if anyone has any ideas to share.
"Nordic Probabilistic AI School (ProbAI) — June 8-12, 2020",6,fhdzlu,datascience,3,"You are welcome to apply for the Nordic Probabilistic AI School (ProbAI) 2020 being held on June 8-12 in **Trondheim (Norway)**.

[**APPLY NOW**](https://probabilistic.ai/?utm_source=reddit_datascience) — The application deadline is ~~March 26~~ **April 2**, but we recommend an early application.

**UPDATE (March 17):** Currently, we have no plans of cancelling the ProbAI school. With our benevolent [cancellation policy](https://probabilistic.ai/application/?utm_source=reddit_datascience), there is negligible risk in applying and eventually registering to ProbAI 2020.

**UPDATE (March 20):** The application deadline has been extended to April 2.

## About ProbAI 2020

The mission of the 2nd Nordic Probabilistic AI School (ProbAI) remains unchanged. We aim to serve state-of-the-art expertise in probabilistic machine learning and artificial intelligence to the public, students, academia and industry.

Particularly, our objective is to bring an intermediate to advanced level summer school with a focus on probabilistic machine learning. We cover topics such as probabilistic models, deep generative models, latent variable models, inference with sampling and variational approximations, and probabilistic programming and tools.

The ProbAI 2020 is organized by the [Norwegian Open AI Lab](https://www.ntnu.edu/ailab) and hosted by the [Norwegian University of Science and Technology](https://www.ntnu.edu/) (NTNU) in Trondheim.

## UPDATE: COVID-19

**Currently, we have no plans of cancelling the Nordic Probabilistic AI School.**

Please be assured that we are closely monitoring the situation around the 2019 novel coronavirus (COVID-19), and we are following the advice of local, national and international health authorities.

Should the status change, we will inform you through all available communication channels.

## UPDATE: Cancellation Policy

**There is negligible risk in applying and eventually registering to ProbAI 2020.**

* The registration fee will be fully refunded in the following cases:
   * If ProbAI 2020 cannot be held.
   * If registration cancelled until May 7.
   * If registration cancelled due to your inability to participate as a result of governmental restrictions related to COVID-19.

**Recommendation:** After an eventual registration, we highly recommend arranging travel insurance also covering a trip cancellation.

## Program

Together with the intentionally small team of invited lecturers, we hope to provide an efficient and quality knowledge transfer through:

* **carefully designed curriculum**,
* **tight cooperation** between our lecturers,
* a mix of **theoretical lectures** and some **hands-on tutorials**,
* extra time for participants with our **teaching assistants** at hand,
* an **innovative lecture room** ([R2](https://roundme.com/tour/214005/view/589158/)) that allows for a close collaboration between the students and lecturers.

## Keynote and Talks

* [Max Welling](https://staff.fnwi.uva.nl/m.welling/) (University of Amsterdam) — Keynote
* [Evrim Acar Ataman](https://scholar.google.com/citations?user=eQKaErAAAAAJ) (Simula Research Lab) — Tensor Factorizations for Physical, Chemical, and Biological Systems
* [Atılım Güneş Baydin](https://scholar.google.com/citations?user=GWBSOj4AAAAJ) (University of Oxford) — Probabilistic Programming, Machine Learning, and Physics
* [Christos Dimitrakakis](https://scholar.google.com/citations?user=9Kw4t_kAAAAJ) (University of Oslo / Chalmers) — TBA: Bayesian Reinforcement Learning or Bayesian Fairness
* [Keith L. Downing](https://www.ntnu.edu/employees/keithd) (NTNU) — Bio-Inspired AI
* [Mihaela Rosca](https://scholar.google.com/citations?user=MxkDwD0AAAAJ) (DeepMind) — VAE/GAN

## Lectures

* [Wilker Aziz](https://scholar.google.com/citations?user=phgBJXYAAAAJ) (University of Amsterdam) — Deep Generative Models
* [Arto Klami](https://scholar.google.com/citations?user=v8PeLGgAAAAJ) (University of Helsinki) — Variational Inference and Optimization
* [Andrés R. Masegosa](https://scholar.google.no/citations?user=J1zoY7AAAAAJ) (University of Almería) — Probabilistic Programming and Variational Inference
* [Didrik Nielsen](https://scholar.google.com/citations?user=-sbw1JIAAAAJ) (Technical University of Denmark) — Normalizing Flows and PixelCNN
* [Thomas Dyhre Nielsen](https://scholar.google.com/citations?user=6fWF0CgAAAAJ) (Aalborg University) — Probabilistic Programming and Variational Inference
* [Francisco Ruiz](https://scholar.google.com/citations?user=khgtYMgAAAAJ) (DeepMind) — Variational Inference with Implicit and Semi-Implicit Distributions
* [Antonio Salmerón](https://scholar.google.com/citations?user=41enG0oAAAAJ) (University of Almería) — Probabilistic Modeling
* [Çağatay Yıldız](https://scholar.google.fi/citations?user=dNloPBUAAAAJ&hl=en) (Aalto University) — ODE2VAE

*More to be announced.*

## Registration

The registration fee includes all courses, coffee breaks, lunches and banquet.

* Students (including PhD) → 2500 NOK \~ 225 EUR
* Academia → 5000 NOK \~ 450 EUR
* Industry → 10000 NOK \~ 900 EUR

We can offer only a limited number of **scholarships** aimed for applicants from developing countries and under-represented groups.

## Contact

* Email: [hello@probabilistic.ai](mailto:hello@probabilistic.ai)
* Website: [https://probabilistic.ai](https://probabilistic.ai/?utm_source=reddit_datascience)
* Twitter: [https://twitter.com/probabilisticai/](https://twitter.com/probabilisticai/)
* Facebook: [https://www.facebook.com/probabilisticai/](https://www.facebook.com/probabilisticai/)

The organizing team: Heri Ramampiaro, Helge Langseth, Tárik S. Salem, Eliezer de Souza da Silva, Marianne Lyseng, Ludvig Killingberg."
Machine Learning Project - Data Science Movie Recommendation System Project in R !!,4,fhdk48,datascience,1,
Advanced Pandas (PandasVault) previously removed from r/learnpython because of moderator difficulties but a great resource nonetheless.,4,fhcg12,datascience,1,"Here is the post I saw. [https://www.reddit.com/r/learnpython/comments/fg9tqg/advanced\_pandas\_10\_github\_repo\_learn\_with\_more/All](https://www.reddit.com/r/learnpython/comments/fg9tqg/advanced_pandas_10_github_repo_learn_with_more/All) 

The functions have been compared and tested with alternatives, only the fastest equivalent functions have been developed and included in this package. 

The package has more than 20 wrapped functions and 100 snippets. Adapted for the Pandas 1.0 release.

\-- [https://github.com/firmai/pandasvault/blob/master/README.md](https://github.com/firmai/pandasvault/blob/master/README.md) (Readme)

\-- [https://colab.research.google.com/drive/1TRKHPGfQnE2yw6\_VPBJZ3nZ8lIPQYiuP](https://colab.research.google.com/drive/1TRKHPGfQnE2yw6_VPBJZ3nZ8lIPQYiuP) (Colab)"
Top 5 Reasons To Use R language For Data Science,4,fhbewh,datascience,6,
How do you prevent overfitting when building a model?,5,fh7d1z,datascience,13,"I was asked this question in an interview, and gave what I thought was a solid answer, but the interviewer was looking for something different.  How would you all answer this question?"
Using PIL to Resize non-image Files?,1,fh711l,datascience,0,"I am working on a research project involving brain wave data. The goal is to classify (1,0) each ""image."" The problem is essentially an image classification problem, where I could use a CNN, but it's not clean at all like most CNN examples online. The files that I have are tsv's (100+ trials per participant with a 1, 0 label on each), and I have stacked them all into one pickle file with each having the participant ID and trial ID attached.

I want to feed them through a CNN, but almost examples online deal with equal-sized images. My data aren't of equal size, and they aren't images. I'm wanting to use PIL to make each file the same size, but is PIL even the correct way of doing so since I don't have image files?"
Is 2-3 hours of studying per day enough?,0,fh6x6w,datascience,5,"Hi,

I am 35 yr old aspiring Data Analyst from the UK and currently working through DataQuest's 'Data Analyst with Python Path'.  I've spent around 30 hours into the platform in the past couple of weeks.

I have no background in Data Analysis (I only have a diploma in accountancy and degree in Psychology) with my past employment being mostly in sales, debt collection and complaint handling.

Every day I'm putting in 2-3 hours into DataQuest and despite feeling like I am making some progress, it's feels slow (even though I am going through the material quicker than DataQuest's projected timescales) and my knowledge of the topics fickle.

**Is 2-3 hours per day enough for someone serious in breaking into Data Analytics?**

I'm currently between employment contracts and so I have LOTS of time on my hands.

If I'm honest, I feel like I am slacking. However, because all the material is new and challenging (DataQuest known for it's difficulty), I don't think I can do much more than this per day without resenting the learning project.

**Do I need to man up and do more or is there something I can do passively each day to reinforce topics I've already covered in DQ? Like read theoretical books or watch videos.**

Thanks!

Beresford"
Categorical or numerical for yes/no classification modeling?,3,fh6ekk,datascience,1,"Building some classification models in R (rattle) and my target is a binary yes/no variable.  About 15 of my variables are numeric and about 5 (including my target) are categorical. Is there any benefit in transforming my target yes/no variable to numerical?   Better to leave as categorical?   Probably using SVM, Random Forest, Boost and Net Neural modeling to compare for best accuracy (and other results).  Untimely trying to predict most Yes’ while limiting Type II errors as best as possible."
"Favorite ""engineering notebook tools"" for DS/ML?",3,fh660d,datascience,0,"I want to improve my notebook practices for engineering/data science/machine learning. I've used very simple text editors or notes software in the past, but would like to get more organized. What are your favorite tools?

Emacs + org mode seems very popular, I'm uncertain how easy and quick it is to use day-to-day (to write down meeting minutes, insert graphs, etc.). Using Jupyter notebooks solely is hard to search/index. 

I'd like the input from the data science/machine learning community. I primarily use MATLAB/Python and Jupyter notebooks, which make it extremely easy to share results ans graphs with non-technical colleagues. 

Thanks!"
Question about Accomplishments at Work,6,fh1phc,datascience,10,"Hi All,

I'm currently about 7 months into my first DS role with a large corporation. I have been learning a ton including big data technologies, engineering, new software, and new languages. This has been great for my development and really improved my skills and I'm very grateful for it (and my manager!).

However, I feel as that I don't actually have any ""accomplishments"" in terms of modelling and deployment. Our company is late to the data analytics/science scene and we are running a new DS shop. We can never fully complete a project and implement anything as whatever new thing is keeping an executive up at night trumps whatever our current project is. Multiple projects have been pushed to the side in my time here even ones with actual cost savings.

For example, I was able to develop a scoring engine for my first project here that would result in 5-8m in savings a month. Our VP was excited by this number but was too uncomfortable/unfamiliar with data science and machine learning to let us implement it. We tried explaining everything to him as best as we could but to no avail. We can easily do this with docker and other tools with a little bit of help with the IT group. I'm not saying everyone is like this but it seems as though you're limiting what we were hired to do. 

So many projects come in and then get pushed off that we can't even get halfway through one of them. However, I have developed a cool ML engineering pipeline for our projects which we all use which I'm very proud of, but with regards to models and actual deployment, I have nothing.

My manager has said it takes time to get DS shops up and running in unfamiliar places but I feel like I won't have anything to show for on a resume other than the pipeline/new things I've learned (which I'm not discounting at all). I guess I'm really trying to get at the fact that we can save time/money by implement models but it's like we'll never get there.

Like I mentioned though, my mentor here has been more than great to me and what I've learned so far will benefit me for years to come. I just wish we would be able to finish out projects and get stuff implemented for the business.

Any feedback or advice from the community would be greatly appreciated!

Thank you!"
Searches of data science topics,400,fh1dg7,datascience,87,
"What is the role of R / Python in a world with Tableau/SAC/DOMO, etc…",0,fgzurm,datascience,24,"Obviously, I am very new to the DS world, and trying to figure out where to spend my time learning. As I struggle through learning R, I question if my time would be better spent learning my company’s own analysis software (FWIW, I work for a (giant) software company, and have been here for the past 20 years).

So, in a world where I can create a chart by dragging/dropping fields, or run a statistical analysis by highlighting a few columns and pressing a button, what is the advantage of learning R or Python?

Is it akin to how some people are just married to the command line, and others prefer a GUI, or is there more to it than that?

Sorry if this is a boneheaded question…as you can tell I’m still wrapping my head around some of this stuff."
Any interest in a Slack group?,4,fgzism,datascience,2,"There are a few different branches of data science (NLP, medical data science) and analytics (business intelligence, etc) communities on reddit and it might be nice to set up a Slack space so different people can have discussions or share ideas or start projects? 


I'd just be concerned about splitting the discussion topics away from the subreddits but thought I'd throw the idea out there

Edit: On second thought, I forgot Slack has limitations on message history if you don't pay for the service..."
How do I compute this percentage from the available data? Is this a linear regression? Data science project.,0,fgvgij,datascience,8,"I just came up with a data science-y project idea but I need help with the math side of it.

I will take studies that have found a correlation between cannabis use in undeveloped brains and decreased cognitive capacity and for the sake of this example I will input 2 variables: average frequency of consumption and quantity consumed. I will take this through a python script and I will output a mathematical function that connects two percentages: the probability (first percentage) X% that you will be Y% less capable than the average non-smoker person in either short-term memory, attention span, etc.

The problem is I know literally no statistics so I'm kinda struggling with the math side. Is this what you'd call a linear regression? What is the actual algorithm for outputting this mathematical function? I first thought I would have to just do some sort of arithmetic mean but it got more complicated when you had more values. For example I can have this data set (a bigger sample would give more accuracy but I'm gonna give a sample of 3 so this example is easier)

Let f be the average frequency of use in days: how much days do they wait in between smoke sessions

Let q be the average quantity they consume in each session (in grams or whatever unit of measure, doesn't matter).

User 1: f = 7, q = 1

User 2: f = 14, q = 1.2

User 3: f = 3, q = 0.5

Each user will also have a variable representing how much less capable they are than the average person on a certain mental task. In reality I'm probably gonna have a list of variables for each user so I compute a separate mathematical function for each mental ability (memory, attention span, etc.) but for the sake of this example let's say they have just one more variable representing how worse they are from the average person at attention span. Let it be a.

User 1: a = 0.2 (20%)

User 2: a = 0.1

User 3: a = 0.3

Now I have to use all this data to compute a mathematical function f : S -> [0;1], S = {f, q, p | f, q are from R+, p is from [0;1] } which takes in the percentage of probability that the output is gonna happen as well as f and q and outputs the percentage decrease in attention span from the normal person (basically a). Now that I think of it, it should work in reverse too, inputting the percentage decrease and outputting the probability that will happen so this function also has to be *bijective*. Actually it's not bijective per se, because I just reverse a and p. I add a in the domain set ""S"" and take out p in the output. Anyway...

Now what I need help with is computing the larger function that takes in two variables and outputs the function f. And that larger function is fed before two *lists* of variables to have the proper data. That will be the script I will write. I'm stumped, because it's taking in three lists of variables and outputs 2. If it was just two outputting 1 it would be easier, for example:

User 1: f = 7, a = 0.3

User 2: f = 14, a = 0.1

User 3: f = 3, a = 0.5

It's way easier to do it now, having to output just a. If I input 7, 14 or 3 I know what I'm going to get. If I output anything else between 3 and 14 I just have to find out the relation between the two closest variables. From 14 to 7, f halved and a tripled. This would mean that (most likely) if f quarters then a would be multiplied by 1.5, if f is divided by 3 a would be multiplied by 4.5 etc. That's for any variable between 14 and 7. Between 3 and 7 I do the same with the other data. Is this a correct approach? Either way if you also have to add the output p besides the output a I'm stuck. Then you also add the input q and I'm even more stuck. 

So what do I have to do ?

I know how to compute derivatives and to work with matrices and determinants in case that is needed."
"Anyone know of any simple deduping projects using Apache Arrow, Parquet etc?",2,fgv9sc,datascience,9,"Looking for something minimal, imagining this as the first layer of an append-only system where you make the compromise to store only never-before-seen records (within a partition say). You lose information about ""flip-flops"" but this is a good compromise in most polling/scraping entrypoints to a persistent data-acrrual system.  


Not a whole lot conceptually but would be nice to know if folks are doing this and a minimal even log viewer on top.  


I am also interested if anyone is doing something like this on IPFS or Orbit-db. I don't know that start all yet, but the possibility of sharing data pulling across trusted peers is extremely interesting for obvious reasons."
What is the closest Python equivalent of R's dbplyr?,120,fgusho,datascience,60,"Most people who use R for data science are familiar with its [dplyr](https://dplyr.tidyverse.org/) package. [Dbplyr](https://db.rstudio.com/dplyr/) allows users to work with remote data stored in databases as if it was in-memory data. Basically, it translates dplyr verbs into SQL queries. Crucially, it has two enormous advantages over simply sending out SQL queries through a connection:

&#x200B;

>The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database, not in R. When working with databases, dplyr tries to be as lazy as possible:  
>  
>It never pulls data into R unless you explicitly ask for it.  
>  
>It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step.

&#x200B;

I'm looking for a similar package for Python. So far, I've found two packages which do something akin to the ""verb-to-SQL"" translation of dbplyr: [Blaze](https://github.com/blaze/blaze) and [Ibis](https://github.com/ibis-project/ibis) (I've actually found them through [this r/datascience post](https://www.reddit.com/r/datascience/comments/7w0ap8/the_dplyr_r_package_has_an_explain_function_that/)). Blaze appears to have been more popular than Ibis, but seems to have gone almost completely stale some years ago, while Ibis is in active development. I haven't yet been able to figure out if they offer the same ""laziness"" of dbplyr, so if anyone could clear that out for me, it would be greatly appreciated. Between Blaze and Ibis, which one would you recommend? Additionally, if anyone knows of some better alternative that I haven't mentioned, please share it."
Coursera Pi Day Promo - Data Science Specialization and Certs at $3.14,35,fgtvff,datascience,17,"Hey everyone, heres a quick heads up, Coursera is running Pi day promo. Select Data Science specialization and certs available at just $3.14 for the first month. 
Consider looking at the [participating programs](https://www.google.com/amp/s/onlinecoursesgalore.com/coursera-pi-day-promo/amp/)"
How is the Assisted Modeling feature of Alteryx?,3,fgq7bc,datascience,3,"I think it's currently in Beta - looks interesting but wanted to hear from others,b if it's really useful or more of a half-working gimmick? And if there are any other competitive solutions out there?"
When to not choose the highest accuracy model,0,fgocu7,datascience,19,"Hi all,

I've come across a small dilemma in my work while creating a churn prediction model.

So the idea is that I'm trying to perform a binary classification to predict churn (0 = churn, 1 = no churn). The model is trained on data of churned observations and non-churned observations. I've managed to build models with extensive hyper-parameter tuning that can achieve \~95-98% testing accuracy. 

The problem is that if a model is always right in this case it would be unusable - it will correctly predict all unchurned observations as unchurned, and all churned observations as churned. So to see unchurned observations at-risk of churning, a less accurate model (in terms of recall) may be more useful.

My question: Are there reasons you would pick a less accurate model outside of computation cost, and interpretability? Would it be sensible to choose a less accurate model here?"
Recommendations for a good course that involves using python?,0,fgnejb,datascience,2,Hi I am looking to complete a data science course that uses python and not R. I know the JHU courserea certification is popular but the problem is it uses R. Is there a similar certification or course that uses python and is highly recommend or valuable like the JHU certification. Thanks for reading looking forward to your replies!!
Book/Videos that demonstrates business side of data science,13,fgla91,datascience,21,"Sorry if the question is vague, I am new to this field

Recently developed RFM and CLV functions from retail dataset, and it motivated me to seek other valuable information that can be derived from transactions/purchases

Any recommendations where to get  the mentioned knowledge would be very much appreciated"
"March 25, Free Talk with AI/ML Legend Michael I. Jordan: ""The Decision-Making Side of Machine Learning: Computational, Inferential, and Economic Perspectives""",9,fgl94c,datascience,0,"March 25, join Michael I. Jordan, one of the most influential people in the history of machine learning, statistics, and artificial intelligence, for the free ACM TechTalk, ""[The Decision-Making Side of Machine Learning: Computational, Inferential, and Economic Perspectives](https://webinars.on24.com/acm/jordan?partnerref=red).""

Much of the recent focus in ML has been on the pattern-recognition side of the field. This talk will focus instead on the decision-making side, where many fundamental challenges remain. Some are statistical in nature, including the challenges associated with multiple decision-making, and some are algorithmic, including the challenge of coordinated decision-making on distributed platforms. Others are economic, involving learning systems that must cope with scarcity and competition. Jordan will present recent progress on each of these fronts."
Does anyone have the data for the average age of deaths from the recent outbreak?,2,fgkq4w,datascience,2,"(The other flairs would not work)

I see all types of data but not this (I dont need any rate of anything just this data) I appreciate your help if you could.

Im referring to Come Open Virus Identify Data nine teen 

(I asked the same question in askreddit but it was immediately downvote out of sight for reason I dont understand so im hoping not saying he who should not be name will give me better chance)

Thank you."
understanding propensity score matching,2,fgkfu2,datascience,16,"so my layman's term of propensity score matching is that it allows you to do an 'apples to apples' comparison.

So for example, if I have 2 groups of people:

last year: 100 of 200 people who buy,  
this year: 200 of 500 people who buy.

if I want to compare the customers from this year and last year, I can use propensity scoring and it'll match customers from this year and last year so I can do better comparison. So for example, if this year, there is a very very unique person, I may want to throw that person out for comparison.

reading the match package in R, the first step is to do a logistic regression to get the probability of buying. My confusion is that they keep referring that 'probability' to propensity.

Is propensity just another word for probability? if so, why are we matching by propensity? shouldn't we match by features? i,e race to race, gender to gender, etc.

I dont think I follow the logic of how matching by probability creates the 'apples to apples' comparison."
Describing a long tail distribution,1,fgjp32,datascience,6,"I am having trouble finding a good way to fit a long tail dataset to a distribution. 
I would like to do something like have a mean, median and std put into a function and have it generate random points modeled in this way. Any libraries or tricks anyone can suggest?"
Who Won Super Tuesday's Media Coverage. Based On Data,3,fgjl24,datascience,0,
Resources for learning about Data Management/Governance? DMBOK?,1,fgijff,datascience,4,"Hi,

I'm changing industry to a Data Management/Governance role with no prior experience in MDM or DG

Ive been looking at resources online, books, podcasts etc. To see what I can learn before I start my new role. 

Ive stumbled across the DAMA-DMBOK book, and was wondering if anybody had read it and would they recommend it? I see it referred to as the  ""bible"" for DG

Or are there other things that I should be looking at?

Apologies if this is the wrong subreddit & thanks for your time!"
After apocalyps: What are your data analytics skills needed for?,0,fggbc3,datascience,4,... be it after the plague or the nuclear war.
Detecting patterns and abnormalities - how to start?,1,fge50x,datascience,5,"I'd like to find repetitive patterns and abnormalities of customers in fictional shops.

I have some given information, but it's not limited to these and I'd like to be able to add more parameters later.

Currently I've:

* Date and
* Time of entering
* Amount of time the client spent inside
* Weather
* Type of shop
* Gender

I could create a chart and visualize information like:

* People spend more time in super markets than in boutiques
* Super markets are crowded from 15:00 to 16:00
* Boutiques are crowded on sales
* People spend more time inside when it's raining
* ...

But I would like to do it the smart way, using something like PyTorch or Tensorflow and let them detect it automatically, so I don't have to look at the charts and figure it out myself. :)

**Questions**

1. Is it possible to feed a model with these information and get the report by the mentioned libraries?
2. If yes, how? I appreciate every advice. 
3. If I'm on the wrong path, which approach do you recommend?

Thank you!"
Would you consider moving from a Data Science role to Business Intelligence role for a big leap in company prestige?,2,fga1im,datascience,6,
How to better explain my regression project in interviews?,6,fg9do8,datascience,11,"I had a project where I was finding race differences between diagnostic errors in a hospital that I was working at (not what I was looking at but I want to maintain some anonymity)
So for example a patient would get a diagnostic error if a doctor said they had a cold but then later it turned out they had the flu or something
 
I made a logistic regression (had an diagnostic error vs didnt have an error) and added variables such as gender,number of visits, ect with each row being a specific patient in the last 2 years or so

I chose to do a regression because after researching online, it was reccomend that I do one to hold all factors equal since the hospital was majority white like 70% 

I was explaining this project to the hiring manager and she was asking stuff about model validation and over fitting of the model. 

I'm not sure what I should have said. I think those questions, especially the one about over fitting should really have only applied if I'm trying to predict future diagnostic errors. 

I was only doing a regression to control for other demographic variables. I'm gonna be honest I didnt do much model validation because I was under the impression that that's mainly necessary for predictive modeling which this wasn't. 

What should I have said? Am I wrong and that even though this project wasn't predictive modeling, I still should have done validation? 

Should I have done a completely different analysis to answer the question from the start?"
How do you make a credit scorecard?,1,fg7xgf,datascience,6,"I am in a Junior Data Analyst in a small financial technology startup. They tasked me to build a credit scorecard for risk management team using pass 2 years disbursement data, the features of data may contain: Age, Salary, Occupation, Marital Status, Live Province, Class (Good/Bad). 

I have been building the Random Forest model for predicting either the applicants will be labeled with Good or Bad. But I still confused and clueless about building a scorecard. Is there any suggestion for me?"
It’s never too early,2739,fg73za,datascience,57,
"I have a binary time series problem that has multiple ""datasets"". How do I model it?",1,fg4nyh,datascience,10,"Hi!

Sorry for the title.

I have a dataset that has multiple observations from different entities. Something like having cars with their features in a timeseries and Im trying to predict the probability of it breaking sometime in the future.

An LSTM would be able to do something like that, right? My question is wouldn't the different cars sort of relate to each other once I build the input for the LSTM?  Should I add a column like the make or brand to differentiate them?

Maybe the timestamps are close enough to each other and I'd guess this wouldn't be good for the model.

Any thoughts?


Thanks!"
Academic articles using data science,0,fg2bf0,datascience,6,"As an introduction to data science one of my Computer Science modules is asking for me to review an academic paper/article that uses an available data set to come to a conclusion. The article needs to come from a 'reliable' source and the data set needs to be publicly available. 

  
Does anyone have some good suggestions I could take a look at?"
How to measure progress towards a goal for groups with different number of members?,0,fg1wxs,datascience,10,"Hello,

I am trying to come up with a fair way to measure two groups of different sizes progressing towards the same goal.  
I have Group1 with 1000 members and Group2 with 200 members. Each member has to complete a survey that will be open for 20 days. Obviously, group2 has fewer members and reaching 100% participation will take less time than group2.   
I was thinking of measuring the pace of the progress towards 100% participation rather than the actual time it takes to hit 100%. For Example: the projected pace for Group1 is 50 members/day (1000 members/20 days), while the projected pace for group2 is 10 members per day.  Who is more successful will then be determined by the actual average daily pace (number of members completing survey) as a percentage of the group's target pace. If group1 finishes in 19 days, their actual average daily pace will be 52.5 or 105% of their projected pace.   
Does this seem like a fair way to measure which group is on-track? Is there another way to ""handicap"" group2?  
I am open to consider other approaches as well."
Python Package to easily extract/filter/visualize latest Coronavirus information,0,fg1nlr,datascience,1,
Pyhton Bokeh: pass date how x_axis value,0,fg17lp,datascience,2,"Hi, i've a csv dataset, and this table i've a datetime value of this type: **( Month/Day/Year) a example (03/07/2020) so i want to use this date how value of the x\_axis beacause i want to see how a value change on time, how can do it with bokeh?**"
When to use statistical tests?,98,ffyqns,datascience,33,"Hello all, I'm wondering when do you want to use statistical tests in your data analysis and feature engineering?

The most recent project I'm working on I used a Chi-squared test for categorical variables and ANOVA for some numerical categories versus my target categorical variable (musical genre).

To be honest though, I'm not fully clear on when or why I should use these tests."
What is the difference between Data Engineer and Data Scientists?,0,ffx812,datascience,7,"I am a junior at a university and was applying for internship over the summer. I applied at a startup near my school and was offered a position of data engineer intern. I am not familiar on the difference. Can anyone tell me the major differences. What should I brush up on to prepare for the internship? 

Thanks in advance."
Including percentage as predictor in logistic regression,0,ffwx9k,datascience,2,"Hi,  
I have a dataset of companies, and I know for each company what percentage of their revenue came from which region. (e.g: company A has total revenue 100K, 40K in USA, 60K in europe. Company B has 1 million revenue, 900K in USA, 100K in europe, etc..).  
I also know for each company if it is succesful or not.

I now want to see if moving from EU to USA (or vice versa) has some effect on the succes of a company. That is, so maybe companies with high revenue share in a specific region tend to be more succesful.

I was thinking of calculating the revenue % for each company and adding that as a feature. However, a logistic regression will probably just tell me that increasing USA revenue % and Europe revenue % increases likelihood of being succesful (because it increases revenue). This is of course not what we want, because we can not just increase USA revenue % without decreasing Europe %. So somehow, I can not include both in my model.

How could I solve this issue?"
Need guidance regarding how to do data science/market research assignments,0,ffvj7c,datascience,15,"So, I interviewed at this company and cleared the first round without any problem.

Round 2: They give me an assignment and 2 days time, I do the assignment, submit it and since then I have not heard from them. (More than 3 weeks)

I am posting the assignment files and the solution which I gave them. Can anyone please tell me what I did wrong and what could be improved here?

This is 2nd company which has not contacted me after giving me an assignment so I am definitely missing something. Thanks.

Links to data and assignment:

Dashboard and Test - My work

Candidate Test and Survey Linked to Data - Files they gave me

[http://www.mediafire.com/folder/12kn1e0h51nisfb,s1lxvexu79v0vo4,mb4v4xd04eyklgx,pqe5k8c56doc462/shared](http://www.mediafire.com/folder/12kn1e0h51nisfb,s1lxvexu79v0vo4,mb4v4xd04eyklgx,pqe5k8c56doc462/shared)"
Good course(s) on analysis of time series?,10,ffus4f,datascience,8,"Hi,  


Looking into learning more about the analysis of time series.  
Are there any good sources you can advice (f.e. free or paid Mooc such as [this one from Udemy](https://www.udemy.com/course/python-for-time-series-data-analysis/))?   

I've got decent working knowledge Python, databases (mssql, postgres, ...), algorithms and basic machine learning.

edit: spelling"
Learning resources for data structures and algorithms,0,fftidh,datascience,3,"Hey!

Found out that my role is pivoting from statistical work into more of a data engineer type role. I'm excited about this but feel like I'm quite far behind in knowledge!

Does anyone have any resources for data structures and algorithms? Preferably in python / scala.

Any other learning resources for data engineering appreciated as well :)"
How to measure the effect of promotion on sales?,1,ffs8ce,datascience,12,"I have this database with four features including date (6 months, daily), codes of product and stores in separate columns and the sales quantity as well as return in the same column. I'm being asked to model the effect of promotion on sales. Promotion start and end dates aren't coded and I'm trying to figure it out by grouping the store/product and resampling the date column weekly. Then I see these aggressive ups and downs when I aggregate with mean which I can guess are the promotional dates. The graphs aren't as much telling when it is aggregated with sum but mean paints a clear picture. There are 5 or 6 promotional weeks happening over 6 months.

How should I go over this task to measure the effect of promotion on sales?"
Data Engineer VS Data Scientist,0,ffozl7,datascience,5,"In general, which role pays best and by how much? How much does this depend on the industry/company? What are the long term prospects/growth potential of each role?

Would you say it is easier to switch from Data Engineering to Data Science than vice versa?

I'm mainly referring to people starting out in their career, may or may not have a Masters, definitely without PhD's."
Must know concepts in DS,12,ffna17,datascience,6,"So my background in econometrics and I'm comfortable with the regressions and time series. But I noticed that clustering is often used in DS. Besides that, what are must-know concepts that are often utilized in DS? And even for clustering, there were soooo many algorithms and approaches; what are the main ones? if you have any good book to suggest please do"
best tool to practice SQL with?,7,ffjmk5,datascience,14,"I'm thinking about downloading MySQL for my Windows machine. I just need a tool to practice SQL on a toy database without the unnecessary stuff and steep learning curve. This is to prepare for interviews.

thanks"
Best AB testing resources?,6,fficfd,datascience,2,"I know the Udacity course (summarized [here](https://towardsdatascience.com/a-summary-of-udacity-a-b-testing-course-9ecc32dedbb1)). It really is as good as they say. But now I need more..

&#x200B;

What other blogs, courses etc.. does everyone recommend? Unofficial Google DS blog is good too."
Transition from Software Engineer to Data/ML Engineer,7,ffg02r,datascience,3,"Hello Experts,

I  recently got an admit from UPenn Data Science for Fall 20. Currently,  I’m working as a Senior Software Engineer at Oracle in India. Given that  there’s a solid 4 to 5 months till the classes begin, I want to be well  prepared for the hustle during college. As I am coming from pure  Applications background, I have little to no experience in core Data  Science. I really want to utilize this extra time to familiarize myself  with the Data Science environment, learn all the pre-requisites and  prepare for Data Science Internships.

My  Background: Intermediate experience in Python (pandas & sklearn)  and I have done couple of Andrew NG courses on Deep Learning. But, I  have never worked on any kind of practical application of the courses  that I have learnt. It has always been theoretical.

Any kind of tips, suggestions will be really helpful!

Thanks in advance!"
Need some advice and insight,3,ffg014,datascience,0,"I've recently been offered the position of Associate data scientist at AB InBev. I'm a chemical engineering undergrad with a minor in Computer Science, but I've done a bit of self learning and caught up with my competition. Two things I'd like to know
1. Can anyone share stuff they have heard or experienced about the work culture and the sort of lives data scientists at AB InBev lead. 
2. Since most of what I've learnt is bits and pieces everywhere, I don't have a very cohesive foundation. Eg. I skipped out on trees, random forests, segmentation and tried my hand at neural nets. Can you suggest accelerated programs where I can build a strong foundation before I start work."
AWS vs GCP,1,fffcxe,datascience,2,"I'm working on a project to deploy a web application. I need to store about 40GB of data, use GPU to train an ML model.

I  know nothing about the cloud service providers, so I'm going to be starting from scratch. If you were in my shoes, which would choose AWS  or GCP?"
"In what ways, if any, does philosophy or spirituality/religion relate to your approach to data science?",0,ffetja,datascience,10,Edit: I understand downvoting to a degree. But would those viewing this question inappropriate consider data science as their guiding philosophical approach since the other terms are so apparently abhorrent?
Does anybody know from which carrier paths come data scientists around the world come?,0,ffej7w,datascience,2,"I'm working with Datascience Fem, a community working with Women in Datascience from Stanford University. We are currently looking for population studies that identify the fields from with people are coming into this area of work. 

Does anybody have idea where to find this kind of studies/ statistics?"
Generating network graphs with prescribed structural properties,2,ffeg3a,datascience,1,"I'm familiar with using graph theory and network analysis to **describe** properties of networks, but I'm wondering if anyone has experience generating and evaluating networks with **prescribed** structural properties, ideally from a set of parameters. My goal is not just to minimize things like the number of orphaned nodes, but also to dictate properties like the average degree of nodes with specific attributes. I'd be grateful for any insight on how best to go about doing this. My inclination would be to randomly reassign edges and then evaluate, but this seems like a horribly inefficient way to go about doing this. :)

Thanks in advance for any suggestions!"
What are your favorite Jupyter extensions?,5,ffcyad,datascience,10,"Jupyter installation seems quite bare bone by default. I've figured people prefer different set of extensions (vim shortcuts, automatic line numbers, conda environments) and would like to know what extensions you use and why.

I use it in quite lightweight:

\- vim bindings

\- [nb\_conda\_kernels](https://github.com/Anaconda-Platform/nb_conda_kernels).

&#x200B;

Thanks for sharing!"
Weekly Entering & Transitioning Thread | 08 Mar 2020 - 15 Mar 2020,6,ffbmhr,datascience,91,"_Bleep Bloop_. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki. You can also search for [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).

---

I am a bot created by the r/datascience moderators. I'm open source! You can review my [source code on GitHub](https://github.com/vogt4nick/datascience-bot)."
Which Data visualization technology do you use when it comes to building websites,0,ffbcmn,datascience,4,"I am working on this problem, which is basically determining the spread of Flu, which technology would you rather use if you want to have your visualizations on a website for users to view. I thought about things like D3.js or maybe PowerBI but I haven't experienced much with any of those platforms which one would you guys recommend"
How to create this volatility chart for S&P 500?,5,ffahrv,datascience,4,"I have recently come across [an article showing the S&P 500 volatility](https://www.capitalspectator.com/should-you-react-to-the-surge-in-stock-market-volatility/#more-13749), based on 30-day rolling window. The chart suggests that the current level of volatility is somewhere near 30%.

I tried to re-create the chart but I failed to receive the same result. (The link to my code can be found [here](https://pastebin.com/rKKbChCG).) My chart seems to have the same as the one in the article but the Y axes are really different. While my chart peaks somewhere around 5%, the chart in the article tops near 80% level.

What did I do wrong? What am I missing? Thank you very much."
What data science electives one should always take?,0,ff8yiu,datascience,2,I'm asking because I want to know when choices become really hard. What elective subjects builds basic for other subjects.
How to analyze personal digital diary entries for the last 8 years?,0,ff8rtw,datascience,4,"I have 8 years of personal diary entries and notes (each time stamped) and would like to person useful analysis on it but unsure how.

One idea is to run a sentiment analysis to see whether there’s positive/negative trends in my attitude/mood.

I would like to keep all data local. Any suggestions on how to do so?"
I got a job!!,1017,ff81cd,datascience,110,"After 20+interviews, 3 onsites, tons of heartbreak, feelings of failure, tears, disappointment and support and love from everyone around me I DID IT and I’m going to be a machine learning engineer. 

This subreddit provided me with a wealth of information and I’m so excited to start working. What advice would you give to someone just starting a new job? 

I’ll have to wear many hats, data visualization, machine learning, database development and opportunities to work on C# software development and UI dev too. Thanks for any advice!!"
Working with a Large Dataset in Python,6,ff4lah,datascience,13,"Hi all,

I am pretty new to data science, and I am working with a dataset that has close to 20 million rows. What is the best way of doing data analysis on such a large dataset? Most of the actions I do with the dataset results in memory issues. Should I only look at a small portion of the dataset? Any advice will be appreciated. Thanks in advance!

Edit 1: Grammar fixes"
What do you use to move data from notebook to notebook?,6,ff4evi,datascience,12,"In complex projects, especially in research, there can be many notebooks (Jupyter or otherwise) used for data cleaning, munging, feature engineering and analysis.

Some of you may be in the position of having a dedicated person employed for data cleaning and other boring stuff, but for many, especially PhD students these kinds of activities is bread and butter and take much more time than the actual model development - especially when integrating complex data from multiple sources.

Onto the question - for those of you who work with (Jupyter) notebooks, how do you move the data around, keeping it tidy and reproducible?

Do you use pickle? Do you store it in plain/gzipped files? Do you use HDF (and if yes, what is your field?) A dedicated storage disk accessible from both HPC and your interactive computing environment? A set of non-SQL databases maybe?"
"About to enroll in UCSD Data Science and Visualization Boot Camp, worth it??",0,ff3gq7,datascience,4,
Coding interview prep,1,ff327w,datascience,0,
Honest question: Is there a real difference between data science/ml and econometrics?,92,ff1zzr,datascience,55,"After looking through a couple lectures and books, undergrad econometrics seems to be stricter in regards of proving causation, whereas DS just describes data."
How could we (DataScience) help? (COVID19),0,ff13jv,datascience,7,"I see lots of good posts about analysing the data - but can we as a community do more?

I'm even thinking is there a way we can come up with an idea of how to use DataScience that helps prevent the spread of the panic? 

For example, we could use time series forecasting to try and assist a company distribute it's inventory more effectively.

Or, maybe we could stream anomaly detection algorithms on Twitter geocoded tweets to alert local hot spots of panic.

Any crazy ideas out there?"
Web Scraping Google from iPhone POV,1,ff122p,datascience,3,"Hey guys, I'm currently working on a scraper that requires me to scrape a google search but from an iPhone's (or any phone for that matter) point of view. Is there any way to do this? I'm writing it in python"
Is a STAR-format based resume the right approach in describing data science experience?,16,ff0ce2,datascience,12,"I am personally a fan of the [STAR format](https://www.zipjob.com/blog/star-method-resume/) for interviews or for my resume. 

For example, instead of saying something like: 

>I built an anomaly detection model using isolation forests to identify click fraud, thus saving $100M a year

I would frame it using the STAR approach:

>Click-Fraud Detection: Online ad platforms earn revenue when users click on an affiliated ad placed in a website, sharing part of the revenue with the website owner. Fraudulent users try to subvert this model, by building automated programs that mimic a genuine click from a genuine user.  
>  
>I worked with a major Australian ad platform in developing a click-fraud detection model. I used an Isolation Forest model, leveraging features like click-velocity of user, time-of-day, User's IP etc, in order to identify a fraudulent user before they have caused too much damage.  
>  
>The model achieved a positive predictive value of 70%, resulting in savings of $100M a year.

My questions:

1. Is this too verbose a format? Some of my reasons for this format:
   1. It's easy to wrongly assume people are familiar with the problem or even the industry. In the above example, exposition about what click-fraud is seems unnecessary. That is a toy example chosen for ease of understanding. Some industries, like Finance or Healthcare, have some very dense jargon which will never make sense to someone not intimately familiar with the industry.
   2. An ML project involves a lot of steps. This lets me flesh out a very high level summary of what happened. For instance, reading what I have written, it's easy to understand what the data sort-of looked like due to the examples of the features.
2. How do I manage content overload?
   1. Due to a large number of projects, the 2 pages now look extremely wordy.
   2. I have little hope that a recruiter would take the 5 minutes necessary to read and understand my experience. Due to the verbose format, ""ML jargon-density"" is very low. My fear is that the recruiter would eye-ball the 2 pages, see very few ""keywords"" like ""Random Forest"" or ""LSTM"" and would reject the resume.

In summary, I now face a weird choice. 

If I go ahead with the STAR format, I have a resume which is easy-to-understand (at least if it's done right), but the word count is high and there's a good chance an overworked recruiter will skim and decide against going forward. 

If I go with a more one-liner approach, the keyword-density definitely increases. This means that the skimming recruiter will catch a lot of ML-specific jargon. However, it's unlikely they would really understand what the problem was and what my solution did.

I would love to hear your take on this dilemma."
How do I transition from Data Analyst to Data Scientist?,0,fezb78,datascience,9,"I’ve been at my current job for about a year. My job duties look something like this: 50% Data manipulation (formatting/calculating) in SAS and MS SQL Server (sometimes I get to do ETL, but very rarely), 25% troubleshooting data anomalies (communicating with data sources), 25% building/editing Tableau dashboards. I am taking online classes on Python, and plan to take classes on R. 

I know from HR that my companies career path for my role is something like this: Associate Data Analyst —> Data Analyst —> Senior Data Analyst —> Data Scientist etc. I’ve talked to our “Senior Data Analysts” and they don’t know any R or Python or SQL, they use SAS, SPSS, VBA and Tableau only. They’re more on the BI side I think. 

We have a separate “Modeling and PA” team, and I want to make a transition to that, because that’s where the “real” data science happens, at least imo. Eventually I want to work with ML and PA myself. 

I guess my question boils down to this: besides learning R and Python (and how to use them for my purposes), as well as getting more industry knowledge, what should I do to progress my career? Should I ask for more “data sciency” projects where I can actually apply stuff I learn. 

Thanks!"
Rookie advice please!,0,feyxb3,datascience,9,"Sorry for the boring post, but I’m at a critical point in my life and I feel like your advice could help me. I finish University this month (Manchester, UK) and will have a First Class Honours Degree in BSC Criminology with Quantitative Methods. I’ve consistently achieved 85% and higher across all units, and have achieved the highest results across the year in my major (statistical data analysis). I’m very confident in SPSS & Excel.

I’m currently looking for a graduate data job. I’ve applied for 5 this week and have one interview. However all of the jobs I’m looking at require competence in R, Python, PowerBI, Tableau, Stata, SQL etc etc... I’m trying to train myself in more programmes however I obviously can’t learn all of them at once.

What areas would you advise someone in my position to channel their energy into first and foremost??? I would appreciate any advice from when you broke into the data world, or anything to avoid etc. 

Thank you in advance!"
Tools for Spatial Analysis,16,feyv76,datascience,6,"I am a college student about to start an internship at a company that does transportation. So, as you might imagine I want to do well at this internship and learn a lot about Data Science. So my question is what are your guys best advice to learn how to perform Spatial Analysis? In addition what tools might you guys use? Anything else I should know about spatial analysis?"
Travel Destinations Dataset,2,fex1gz,datascience,0,"Any pointers to a dataset / website with structured content on Travel Destinations? I am looking for  data  like weather, 'things the destinations are known for',  popularity, travel season, 'things to do there' etc.. 

Granted, Wiki has this information, albeit in a rather unstructured way, meaning they have paragraphs  under a heading, which may or may not exist for another destination. 

Think about  making your own TripAdvisor which gives you a lot of information about a particular destination. How would you go about collecting all that information, if you did not have the resources to hire a content team or did not want to go the 'scraping' route.

I need this information for about 1500 destinations.

Any pointers appreciated. Much thanks !"
Classify items into nonspecific 'Other' category,2,fevs7x,datascience,6,"I have a multilabel classification problem that looks pretty straightforward but I noticed that we have a requirement to classify non-classifiable items into an 'Other' category. The data thus has been labeled with the relevant labels and then those that are unclassifiable are all 'Other'. 

I think the multilabel classification part for the classifiable labels should be straight forward, but I am wondering what I should do with the 'Other' category. Because its nothing more than a dumping ground for nonclassifiable data, its nothing I specifically want to predict against and additionally, the features would be non predictive for this label since there is nothing holding the records for this label together. 

I was thinking of excluding the 'Other' class from my training data and then if I dont see high enough probabilities for any one class, place in 'Other'

Is this a good approach? I am wondering whats the best way to proceed with this problem?"
Can anyone suggest a good program for me to get a refresher. IRL in Denver would be best but I'm not avers to online,0,fet45t,datascience,0,"Hoping to get some recommendations on data science programs.

So I'm out of grad school by about six years. My stats and ML knowledge was sufficient back then. Current job that I love is all data and no science. I've gotten really good at data work and have picked up a lot of useful technical proficiency. But now I'm so far removed from the math I think it would be a huge hindrance in finding another job.

I'm hoping to find a program that would refresh that skillset. Something I coukd put on a resume would be optimal. In person as well. But something that gets the job done is most important.

Any thoughts?"
Life itself is a datascience! Constantly predicting the next move,0,fereer,datascience,1,
"Should you do feature engineering first, hyper-parameter tuning first, or both at the same time?",7,fequa5,datascience,13,"I am currently using RF models, and I am not sure if I should just set the max depth to a very large number that allows all features to be analyzed or is there a better way to do it?"
In what order should I learn the following data science tools?,1,feqori,datascience,4,"\-Hadoop + Spark + Hive

\-Azure Data Factory + Data Flow

\-SQL

\-Python

Also for background: I am a computer science graduate so I have some basic SQL knowledge. I never had to learn python but im confident in my ability to pick it up quick. The other two, no idea."
Need help finding data,1,feq8xe,datascience,4,"Hi I don’t know if this is the right place to post this, but I really need help finding data for a school project. I am trying to find a correlation between high school drop out rates and minor (below age of 18) employment rates. I have been looking for two days now and can’t seem to find any data on the information I’m looking for. Any help will be appreciated. Thank you in advance for your help!"
"Finally, I have completed the course ""Data Science for Everyone"" in Datacamp. #datascientists #datacamp #datascience #course",0,fep7ne,datascience,1,
I woefully underestimated the amount of SQL I need to write. Looking for intermediate-advanced tutorials.,314,feopi4,datascience,66,"Pretty much the title. I know some SQL, but I'm not very solid at it. I wrote my first self join with a CASE WHEN in the join condition today and felt pretty proud, but looking at some of my teammates, it's pretty obvious my SQL skill could use some improvement. As much as I love pandas, if I can do a fair amount of data-prep up front, I'd prefer that (and it keeps our DBAs employed).

One of my teammates took a SQL query that another department wrote and sped it up by an order of magnitude (45 minutes to about 4 minutes) by pulling data into four different temporary tables and joining on those. That's the sort of insight I'm looking to build.

Any recommendations on tutorials? I'm looking for some intermediate SQL resources, preferably geared toward teaching you *when* you'd want to use certain techniques. I went through [select star sql](https://selectstarsql.com/) and found it great for an introduction, but I'd really like to start making some higher-order connections."
Is UIUC’s MCS-DS program sufficient preparation for Data Scientist roles in big companies?,0,femb0d,datascience,4,"I know UIUC has a top 5 CS program and will prepare you to work at any big tech company, but I don’t know how much this excellence transfers to data science. The MCS-DS is a master of computer science where you take courses that revolve around data science

The program is https://cs.illinois.edu/academics/graduate/professional-master-computer-science/online-master-computer-science-data-science

Anyone have any anecdotes or insight? 
Would this prepare you for a role as a DS at day lyft, facebook, or amazon?"
Interested in Data Science career.,14,fem75f,datascience,4,"Hey everyone! I’m a third year Industrial and Management Engineering student at RPI in Upstate NY, and was interested in potentially going into the data science/consulting industry. IE is a major that can put you in a wide variety of fields, but I was wondering how “viable” it is for an IE to go into data science? I am also going to do my Masters in Applied Math once I’m done with undergrad since it’ll only take a year and my school will allow me to keep my financial aid package during that extra year. Would you say Applied Math would be a good start to a data science career?

I have experience with Excel, Python, R, and MATLAB. I want to learn SQL and will be learning JMP this summer during an internship I have. I’m pretty bad at writing code from scratch as my first experience with coding didn’t come until my second semester of college. But I am decent at modifying code and understanding others code. How important would you say coding is in Data Science? 

My last part will be more about data science in general. Are there any skills/courses you think would be beneficial for me to take? I also really want to get into the airline/transportation industry, so would say that Data Science is common in those industries?

Sorry for the wall of text and questions. Just a confused college kid trying to figure it all out. 

Thanks!"
Post-Mortem Python Plotting,5,feljvj,datascience,2,
running a regression in Spark: R vs. Scala vs. Python,4,fekc75,datascience,5,"I'm doing data engineering, creating ETLs in EMR Spark. I've done some ML in school but not in production. My manager is doing actual modeling but doesn't deal with EMR directly herself. 

I suggested to her that we should try running in our EMR Spark infrastructure. So she said to go ahead and set it up. From an operational/setup perspective, do you have any preferences between R, Python, and Scala? 

The whole point is to take advantage of the infrastructure since we pay for it, and then we could run some regressions that would take too long to run on a laptop. We actually pay a vendor to run models with 500+ dependent variables."
Time Series Datasets,8,fejoca,datascience,7,"Any interesting time series datasets about? Have to pick one for college to analyse, was wondering if there's anywhere to find animal populations in certain areas maybe? Something outside the usual finance time series would be nice."
Use software for data-related work?,0,fefnpa,datascience,6,"Software such as Alteryx or Tableau can do data analysis, visualization and predictive modeling, does anyone here use them or an alternative instead of a programming language for data-related work?

I'm asking because I don't understand why would people use such software when you already have a more powerful tool like Python or R, which are also free.

I guess software provides a user friendly UI (vs coding environment), and maybe a less steep learning curve, other than that I don't see the benefit of using software vs programming language.

Any Thoughts?"
Data Science Groups/Meetups Near Philadelphia,0,fefibt,datascience,1,Does anyone know of any data science-oriented meetups around or near Philadelphia? I would love to network and learn from anyone who is local
"I’ve made this LIVE Interactive dashboard to track COVID19, any suggestions are welcome",498,fedkoa,datascience,37,
Analysis is going to bring in millions of pounds to business - Can I ask for additional compensation?,4,fed4o1,datascience,25,"Hi all,

* The context:
   * My analysis has found thousands of business opportunities which are co-funded by the government. In short, this means that the company which I am working for (start-up, capital of £5mln) is very likely to receive upwards of £12mln in funding. This is only possible because of the datasets and scripts I have developed over the past 18 months. My work allows the company to screen entire UK for projects which are eligible for government co-funding. Without it, the targeting system would be limited to ""Oh, we've heard..."" and ""Somebody told us about..."".
* The question:
   * What can I get out of it? It's brilliant that the business is going to make a bank using my work but it doesn't mean anything for me. Unless I ask for something. So what sort of appropirate compensation would be reasonable to ask for? A flat bonus? £100 per successfully co-funded project (Average project brings in £200,000 in funding so £100 would be 0.5%) or something else altogether?"
